{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of weather impacted flight delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data collection section takes time, you can skip it until the reproducibility section, as the data collected is already present in the technical work repository in csv format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect flight data from BTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collect BTS flight data, go to the following web page:https://transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr\n",
    "\n",
    "Download the data by ticking the boxes below:\n",
    "\n",
    "FlightDate; Tail_Number; Flight_Number_Reporting_Airline; Origin; Dest; CRSDepTime;\n",
    "DepTime; DepDelay; DepDel15; TaxiOut; WheelsOff; WheelsOn; TaxiIn; CRSArrTime; ArrTime;\n",
    "ArrDelay; ArrDel15; Cancelled; CancellationCode; Diverted; CRSElapsedTime; ActualElapsedTime;\t\t\n",
    "AirTime; Distance; CarrierDelay; WeatherDelay; NASDelay; SecurityDelay; LateAircraftDelay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_jfk_flight_data(year1, year2, directory, filename):\n",
    "    \"\"\"\n",
    "    Merge flight data for JFK airport from several CSV files into a DataFrame and save it as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        year1 (int): The start year of flight data collection.\n",
    "        year2 (int): The end year of flight data collection.\n",
    "        directory (str): Path to directory containing all flight data CSV files.\n",
    "        filename (str): Filename where the merged flight data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # List for storing DataFrames\n",
    "    dataframes_list = []\n",
    "\n",
    "    # List of months\n",
    "    months = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"JUN\",\"JUL\",\"AUG\",\"SEP\",\"OCT\",\"NOV\",\"DEC\"]\n",
    "\n",
    "    # Loop for each year and month\n",
    "    for year in range(year1, year2+1):\n",
    "        \n",
    "        # Flight data from years during COVID-19 are not merged\n",
    "        if year in (2019, 2020):\n",
    "            continue\n",
    "        \n",
    "        for month in months:\n",
    "            # Name of CSV file to be uploaded\n",
    "            Flight_Data_filename = os.path.join(directory, f\"T_ONTIME_REPORTING_{month}{year}.csv\")\n",
    "            \n",
    "            if os.path.exists(Flight_Data_filename):\n",
    "                # Upload the CSV file\n",
    "                df_flight = pd.read_csv(Flight_Data_filename)\n",
    "\n",
    "                # Filter for JFK airport\n",
    "                df_jfk = df_flight[df_flight['ORIGIN'] == 'JFK']\n",
    "\n",
    "                # Add to main DataFrame\n",
    "                dataframes_list.append(df_jfk)\n",
    "            \n",
    "            else:\n",
    "                print(f\"File not found : {Flight_Data_filename}\")\n",
    "                \n",
    "    if dataframes_list:\n",
    "        \n",
    "        # Combine all DataFrames\n",
    "        df_combined = pd.concat(dataframes_list, ignore_index=True)\n",
    "\n",
    "        # Save the combined DataFrame as a CSV file\n",
    "        df_combined.to_csv(filename, index=False)\n",
    "\n",
    "        print(\"The combined data was successfully saved.\")\n",
    "    else:\n",
    "        print(\"No files were found and processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jfk_flight_data(2010,2023,\"Chandrakumar_s419255_Data_MScCSTE\",\"JFK_Flight_Data_2010_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect weather data from Weather Underground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used for converting units of measurement for variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahrenheit_to_celsius(f):\n",
    "    \"\"\"\n",
    "    Converts the temperature from Fahrenheit to Celsius.\n",
    "    \n",
    "    Args:\n",
    "        f (int): Temperature in Fahrenheit.\n",
    "    \n",
    "    Returns:\n",
    "        int: Temperature converted to Celsius.\n",
    "    \"\"\"\n",
    "    if f == 0:\n",
    "        return 0\n",
    "    return round((f - 32) * 5.0 / 9.0) \n",
    "\n",
    "def inches_to_mm(inches):\n",
    "    \"\"\"\n",
    "    Converts inches to millimetres.\n",
    "\n",
    "    Args:\n",
    "        inches (float): Measurement in inches.\n",
    "\n",
    "    Returns:\n",
    "        int: Measurement in millimetres and rounded.\n",
    "    \"\"\"\n",
    "    return round(inches * 25.4)\n",
    "\n",
    "def inches_mercury_to_hpa(inches):\n",
    "    \"\"\"\n",
    "    Converts pressure from inches of mercury to hectopascals.\n",
    "\n",
    "    Args:\n",
    "        inches (float): Pressure in inches of mercury.\n",
    "\n",
    "    Returns:\n",
    "        float: Pressure in hectopascals and rounded.\n",
    "    \"\"\"\n",
    "    return round(inches * 33.8639, 2)\n",
    "\n",
    "def mph_to_kmh(mph):\n",
    "    \"\"\"\n",
    "    Converts speed from miles per hour to kilometers per hour.\n",
    "\n",
    "    Args:\n",
    "        mph (float): Speed in miles per hour.\n",
    "\n",
    "    Returns:\n",
    "        int: Speed in kilometers per hour and rounded.\n",
    "    \"\"\"\n",
    "    return round(mph * 1.609344)\n",
    "\n",
    "def weather_data_into_dataframe(data, date):\n",
    "    \"\"\"\n",
    "    Converts raw weather data into a structured DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data (list of lists): Raw weather data where each sublist represents a row of data.\n",
    "        date (str): The date in YYYY-MM-DD format related to the data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with processed weather data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define DataFrame column headers\n",
    "    headers = [\"DateTime\", \"Temperature (°C)\", \"Dew Point (°C)\", \"Humidity (%)\", \"Wind\", \n",
    "               \"Wind Speed (km/h)\", \"Wind Gust (km/h)\", \"Pressure (hPa)\", \"Precip. (mm)\", \"Condition\"]\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "    # Remove data unit symbols from all data\n",
    "    df['Temperature (°C)'] = df['Temperature (°C)'].str.replace('°F', '').astype(int)  \n",
    "    df['Dew Point (°C)'] = df['Dew Point (°C)'].str.replace('°F', '').astype(int)      \n",
    "    df['Humidity (%)'] = df['Humidity (%)'].str.replace('°%', '').astype(int)        \n",
    "    df['Wind Speed (km/h)'] = df['Wind Speed (km/h)'].str.replace('°mph', '').astype(float)  \n",
    "    df['Wind Gust (km/h)'] = df['Wind Gust (km/h)'].str.replace('°mph', '').astype(float)    \n",
    "    df['Pressure (hPa)'] = df['Pressure (hPa)'].str.replace('°in', '').astype(float)  \n",
    "    df['Precip. (mm)'] = df['Precip. (mm)'].str.replace('°in', '').astype(float)     \n",
    "\n",
    "    # Apply conversion functions to data columns\n",
    "    df[\"Temperature (°C)\"] = df[\"Temperature (°C)\"].apply(fahrenheit_to_celsius) \n",
    "    df[\"Dew Point (°C)\"] = df[\"Dew Point (°C)\"].apply(fahrenheit_to_celsius)      \n",
    "    df[\"Wind Speed (km/h)\"] = df[\"Wind Speed (km/h)\"].apply(mph_to_kmh)          \n",
    "    df[\"Wind Gust (km/h)\"] = df[\"Wind Gust (km/h)\"].apply(mph_to_kmh)          \n",
    "    df[\"Pressure (hPa)\"] = df[\"Pressure (hPa)\"].apply(inches_mercury_to_hpa)    \n",
    "    df[\"Precip. (mm)\"] = df[\"Precip. (mm)\"].apply(inches_to_mm)                  \n",
    "\n",
    "    # For weather data collected for one day, it is possible to have the data for the day before or after.\n",
    "\n",
    "    observation_date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Create a list to store adjusted datetimes\n",
    "    dates = []\n",
    "    current_date = observation_date\n",
    "    day_transition = 0\n",
    "    \n",
    "    # Iterate on the data to adjust the datetimes\n",
    "    for i, time in enumerate(df[\"DateTime\"]):\n",
    "        \n",
    "        if i == 0 and \"PM\" in time:\n",
    "            # If the first entry contains PM, adjust to the previous date\n",
    "            current_date -= timedelta(days=1)\n",
    "\n",
    "        elif day_transition == 0 and \"AM\" in time:\n",
    "            # If the time value contains AM for the first entry or for just\n",
    "            # after the first entry, reset the date to the current date.\n",
    "            day_transition = 1\n",
    "            current_date = observation_date\n",
    "\n",
    "        elif day_transition == 1 and \"AM\" in time and \"PM\" in df[\"DateTime\"][i - 1]:\n",
    "            # If we change from PM to AM, adjust the date by one day\n",
    "            current_date += timedelta(days=1)\n",
    "\n",
    "        # Add corrected datetimes to the list\n",
    "        dates.append(current_date.strftime(\"%Y-%m-%d\") + \" \" + time)\n",
    "\n",
    "    # Update the DateTime column with the new values\n",
    "    df[\"DateTime\"] = pd.to_datetime(dates)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection of weather data for a specific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weather_data_for_date(date):\n",
    "    \"\"\"\n",
    "    Collects weather data for a specific date from the Weather Underground site.\n",
    "    \n",
    "    Args:\n",
    "        date (str): Date in YYYY-MM-DD format.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the weather data for the specific date.\n",
    "    \"\"\"\n",
    "    \n",
    "    # URL to collect weather data for the specified date\n",
    "    url = 'https://www.wunderground.com/history/daily/us/ny/new-york-city/KJFK/date/' + date\n",
    "    #print(url)\n",
    "    \n",
    "    # Configuration of selenium package objects to access the page via the URL\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    \n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the weather data table to appear\n",
    "    wait = WebDriverWait(driver, 60)\n",
    "    table = wait.until(EC.presence_of_element_located((By.XPATH, \"//table[contains(@class, 'mat-table cdk-table mat-sort ng-star-inserted')]\")))\n",
    "\n",
    "    rows = []\n",
    "    table_rows = table.find_elements(By.XPATH, \".//tbody/tr[contains(@class,'mat-row cdk-row ng-star-inserted')]\")\n",
    "\n",
    "    # Extraction of weather data from each row of the table\n",
    "    for table_row in table_rows:\n",
    "        data = []\n",
    "        table_columns = table_row.find_elements(By.XPATH, \".//td\")\n",
    "        for table_column in table_columns:\n",
    "            value = table_column.get_attribute('textContent')\n",
    "            data.append(value)\n",
    "        rows.append(data)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    # Converting weather data into DataFrame\n",
    "    df = weather_data_into_dataframe(rows, date)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection of weather data for a specific month and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_weather_data(month, year):\n",
    "    \"\"\"\n",
    "    Collects weather data for a specific month and year.\n",
    "    \n",
    "    Args:\n",
    "        month (int): Month for which weather data is to be collected.\n",
    "        year (int): Year for which weather data is to be collected.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame:  A DataFrame containing the weather data for the specific month and year.\n",
    "    \"\"\"\n",
    "    # List of months\n",
    "    months = [\"JAN\", \"FEB\", \"MAR\", \"APR\", \"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\", \"NOV\", \"DEC\"]\n",
    "\n",
    "    # Define the start and end dates for each month\n",
    "    start_date = datetime(year, month, 1)\n",
    "    \n",
    "    if month == 12:\n",
    "        end_date = datetime(year + 1, 1, 1) - timedelta(days=1)\n",
    "    else:\n",
    "        end_date = datetime(year, month + 1, 1) - timedelta(days=1)\n",
    "        \n",
    "    # Store all dates for the month\n",
    "    dates = [(start_date + timedelta(days=i)).strftime('%Y-%m-%d') for i in range((end_date - start_date).days + 1)]\n",
    "\n",
    "    weather_data = []\n",
    "    \n",
    "    # Collect weather data for each date using multithreading to speed up the process\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:  \n",
    "        futures = [executor.submit(collect_weather_data_for_date, date) for date in dates]\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            df_weather = future.result()\n",
    "            if not df_weather.empty:\n",
    "                weather_data.append(df_weather)\n",
    "\n",
    "    # Combine the weather data for each day of the month in a DataFrame\n",
    "    df_weather_month = pd.concat(weather_data, ignore_index=True)\n",
    "    df_weather_month = df_weather_month.sort_values(by=\"DateTime\")\n",
    "    \n",
    "    # Save weather data in a CSV file\n",
    "    output_filename = f'Chandrakumar_s419255_Data_MScCSTE/WEATHER_DATA_KJFK_{months[month-1]}{year}.csv'\n",
    "    df_weather_month.to_csv(output_filename, index=False)\n",
    "    \n",
    "    print(f'Data for {year}-{month:02} saved in {output_filename}')\n",
    "    \n",
    "    return df_weather_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution of weather data collection \n",
    "years = range(2009, 2010) # Year values can be changed\n",
    "dataframe = []\n",
    "\n",
    "for year in years:\n",
    "    # Weather data from years during COVID-19 are not collected\n",
    "    if year in (2019, 2020):\n",
    "        continue \n",
    "    \n",
    "    for i in range(12, 13): # Month values can be changed\n",
    "        dataframe.append(collect_weather_data(i, year))\n",
    "\n",
    "# It is better to collect weather data 6 months at a time to prevent the code from crashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_jfk_weather_data(year1, year2, directory, filename):\n",
    "    \"\"\"\n",
    "    Merge weather data for JFK airport from several CSV files into a DataFrame and save it as a CSV file.\n",
    "\n",
    "    Args:\n",
    "        year1 (int): The start year of weather data collection.\n",
    "        year2 (int): The end year of weather data collection.\n",
    "        directory (str): Path to directory containing all weather data CSV files.\n",
    "        filename (str): Filename where the merged weather data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # List for storing DataFrames\n",
    "    dataframes_list = []\n",
    "\n",
    "    # List of months\n",
    "    months = [\"JAN\",\"FEB\",\"MAR\",\"APR\",\"MAY\",\"JUN\",\"JUL\",\"AUG\",\"SEP\",\"OCT\",\"NOV\",\"DEC\"]\n",
    "\n",
    "    # Loop for each year and month\n",
    "    for year in range(year1, year2+1):\n",
    "        \n",
    "        # Weather data from years during COVID-19 are not merged\n",
    "        if year in (2019, 2020):\n",
    "            continue\n",
    "        \n",
    "        for month in months:\n",
    "            # Name of CSV file to be uploaded\n",
    "            Weather_Data_filename = os.path.join(directory, f\"WEATHER_DATA_KJFK_{month}{year}.csv\")\n",
    "            \n",
    "            if os.path.exists(Weather_Data_filename):\n",
    "                # Upload the CSV file\n",
    "                df_weather = pd.read_csv(Weather_Data_filename)\n",
    "\n",
    "                # Add to main DataFrame\n",
    "                dataframes_list.append(df_weather)\n",
    "            \n",
    "            else:\n",
    "                print(f\"File not found : {Weather_Data_filename}\")\n",
    "                \n",
    "    if dataframes_list:\n",
    "        \n",
    "        # Combine all DataFrames\n",
    "        df_combined = pd.concat(dataframes_list, ignore_index=True)\n",
    "\n",
    "        # Save the combined DataFrame as a CSV file\n",
    "        df_combined.to_csv(filename, index=False)\n",
    "\n",
    "        print(\"The combined data was successfully saved.\")\n",
    "    else:\n",
    "        print(\"No files were found and processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jfk_weather_data(2009,2023,\"Chandrakumar_s419255_Data_MScCSTE\",\"JFK_Weather_Data_2010_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging flight and weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_time_format(val):\n",
    "    \"\"\"\n",
    "    Converts a Time value into HH:MM format.\n",
    "    \n",
    "    Args:\n",
    "        val (float): Time value in military format or NaN.\n",
    "    \n",
    "    Returns:\n",
    "        str: Time in HH:MM format or None if the value is NaN.\n",
    "    \"\"\"\n",
    "    # Check if the value is NaN\n",
    "    if pd.isnull(val):\n",
    "        return None\n",
    "    \n",
    "    hours = int(val) // 100\n",
    "    minutes = int(val) % 100\n",
    "\n",
    "    # If the hours are equal to 24, set them to 0\n",
    "    if hours == 24:\n",
    "        hours = 0\n",
    "\n",
    "    # Format Time in HH:MM using two digits for hours and minutes\n",
    "    return f\"{hours:02d}:{minutes:02d}\"\n",
    "\n",
    "def convert_to_datetime(date, time):\n",
    "    \"\"\"\n",
    "    Combines a date and a time.\n",
    "    \n",
    "    Args:\n",
    "        date (str): Date value into YYYY-MM-DD format.\n",
    "        time (str): Time value into HH:MM format or None.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Timestamp: Datetime object corresponding to the time and date combination.\n",
    "    \"\"\"\n",
    "    # Check if the value is NaN\n",
    "    if pd.isnull(time):\n",
    "        return None\n",
    "    \n",
    "    # Combine date and time\n",
    "    return pd.to_datetime(f\"{date} {time}\")\n",
    "\n",
    "def merge_flight_weather_data(filename1, filename2, timing):\n",
    "    \"\"\"\n",
    "    Merges flight data with weather data into a DataFrame and save it as a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        filename1 (str): Path to CSV file containing flight data.\n",
    "        filename2 (str): Path to CSV file containing weather data.\n",
    "        timing (int): Timing of weather data collected before the scheduled flight departure.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: a DataFrame merged with flight data and associated weather data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if the files exist\n",
    "    if os.path.exists(filename1) and os.path.exists(filename2):\n",
    "        \n",
    "        df_flight = pd.read_csv(filename1)\n",
    "        df_flight['FL_DATE'] = pd.to_datetime(df_flight['FL_DATE']).dt.date\n",
    "        \n",
    "        # Convert time to HH:MM format\n",
    "        df_flight['CRS_DEP_TIME_1'] = df_flight.apply(lambda row: convert_to_time_format(row['CRS_DEP_TIME']), axis=1)\n",
    "\n",
    "        df_weather = pd.read_csv(filename2)\n",
    "\n",
    "        # Create or convert a datetime column for flight and weather data\n",
    "        df_flight[\"FlightDateTime\"] = df_flight.apply(lambda row: convert_to_datetime(row['FL_DATE'], row['CRS_DEP_TIME_1']), axis=1)\n",
    "        df_weather[\"DateTime\"] = pd.to_datetime(df_weather[\"DateTime\"])\n",
    "        \n",
    "        df_flight[f\"FlightDateTime_minus_{timing}h\"] = df_flight[\"FlightDateTime\"] - pd.Timedelta(hours=timing)\n",
    "\n",
    "        # Sort DataFrames by datetime\n",
    "        df_flight = df_flight.sort_values(f\"FlightDateTime_minus_{timing}h\")\n",
    "        df_weather = df_weather.sort_values('DateTime')\n",
    "\n",
    "        # Merge flight and weather data according to the given timing\n",
    "        if timing == 0:\n",
    "            # No tolerance required\n",
    "            flight_weather_data = pd.merge_asof(df_flight, df_weather, left_on=f\"FlightDateTime_minus_{timing}h\", \n",
    "                                                right_on='DateTime', direction='backward')\n",
    "        else:\n",
    "            # With tolerance\n",
    "            flight_weather_data = pd.merge_asof(df_flight, df_weather, left_on=f\"FlightDateTime_minus_{timing}h\", \n",
    "                                                right_on='DateTime', direction='backward',tolerance=pd.Timedelta(hours=timing))\n",
    "\n",
    "        # Deletes columns used just for merging\n",
    "        flight_weather_data.drop(columns=[\"FlightDateTime\", f\"FlightDateTime_minus_{timing}h\", \"DateTime\",\"CRS_DEP_TIME_1\"], inplace=True)\n",
    "        \n",
    "        output_file = f\"JFK_Flight_Weather_Data_2010_2023_{timing}h.csv\"\n",
    "        flight_weather_data.to_csv(output_file, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"JFK_Flight_Data_2010_2023.csv\"\n",
    "filename2 = \"JFK_Weather_Data_2010_2023.csv\"\n",
    "timings = [0,2,4,8,16,24,48]\n",
    "\n",
    "for timing in timings:  \n",
    "    merge_flight_weather_data(filename1, filename2, timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed random seed for reproducibility of results\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "print(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells in the Jupiter Notebook file must be run in chronological order to ensure reproducible results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The timing of the weather data can be changed (0h, 2h, 4h, 8h, 16h, 24h or 48h before flight departure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing = 0\n",
    "# timing = 2\n",
    "# timing = 4\n",
    "# timing = 8 \n",
    "# timing = 16\n",
    "# timing = 24\n",
    "# timing = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"JFK_Flight_Weather_Data_2010_2023_{timing}h.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace military times 2400.0 with 0.0 to indicate midnight\n",
    "for column in [\"DEP_TIME\",\"WHEELS_OFF\",\"WHEELS_ON\",\"CRS_ARR_TIME\",\"ARR_TIME\"]:\n",
    "    df.loc[df[column] == 2400.0, column] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a summary of the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of missing values for each column in the DataFrame\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only flights that are not diverted or cancelled\n",
    "df = df[(df['DIVERTED'] == 0) & (df['CANCELLED'] == 0)].reset_index(drop=True)\n",
    "\n",
    "# Keep only rows where the Condition column contains no missing values\n",
    "df = df[df[\"Condition\"].notna()].reset_index(drop=True)\n",
    "\n",
    "# Remove unnecessary columns from the DataFrame\n",
    "df = df.drop(['DIVERTED','CANCELLED','CANCELLATION_CODE'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing values with specific ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values by 0 for the columns associated with the departure/arrival delay, \n",
    "# as it can be seen that the missing values are present when the scheduled departure/arrival time \n",
    "# is the same as the actual departure/arrival time.\n",
    "for column in ['ARR_DELAY','ARR_DEL15','DEP_DELAY','DEP_DEL15']:\n",
    "    df.loc[df[column].isna(), column] = 0.0\n",
    "\n",
    "# Replace missing values with 0 for delay columns, as missing values are present when flights \n",
    "# arrive on time.\n",
    "for column in ['CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY','LATE_AIRCRAFT_DELAY']:\n",
    "    df.loc[df['ARR_DEL15'] == 0.0, column] = 0.0\n",
    "\n",
    "# Replace the missing values by CALM for the Wind column, as the missing values are present\n",
    "# when the wind speed or wind gust is equal to 0.\n",
    "df.loc[df[\"Wind\"].isna(), \"Wind\"] = \"CALM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert DataFrame object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified DataFrame columns to string format\n",
    "df['ORIGIN'] = df['ORIGIN'].convert_dtypes()\n",
    "df['DEST'] = df['DEST'].convert_dtypes()\n",
    "df['OP_UNIQUE_CARRIER'] = df['OP_UNIQUE_CARRIER'].convert_dtypes()\n",
    "df['Wind'] = df['Wind'].convert_dtypes()\n",
    "df['Condition'] = df['Condition'].convert_dtypes()\n",
    "df['TAIL_NUM'] = df['TAIL_NUM'].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FL_DATE column in the DataFrame to datetime format\n",
    "df['FL_DATE'] = pd.to_datetime(df['FL_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target variable creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the STATUS column to 0 to indicate that the flight is on-time\n",
    "df['STATUS'] = 0 \n",
    "\n",
    "# Sets the STATUS column to 1 for delayed flights with no weather delay.\n",
    "df.loc[(df['WEATHER_DELAY'] == 0.0) & (df['ARR_DEL15'] == 1.0), 'STATUS'] = 1 \n",
    "\n",
    "# Sets the STATUS column to 2 for flights delayed due to weather conditions\n",
    "df.loc[(df['WEATHER_DELAY'] > 0.0) & (df['ARR_DEL15'] == 1.0), 'STATUS'] = 2 \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['FL_DATE','DEST', 'CRS_DEP_TIME']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of different flight categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = df[\"STATUS\"].value_counts()\n",
    "\n",
    "status = {0: 'on-time', 1: 'delayed (non-weather)', 2: 'delayed (weather)'}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(distribution.index, distribution.values, color=['blue', 'orange', 'red'], width=0.4)\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel('Flight Category', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Number of flights', fontweight='bold', fontsize=14)\n",
    "\n",
    "# Define grid \n",
    "plt.grid(axis='y', linestyle='', alpha=0.7)\n",
    "\n",
    "# Define tick labels for the x-axis and y-axis\n",
    "plt.xticks(ticks=distribution.index, labels=[status[i] for i in distribution.index], rotation=0, fontsize=12)\n",
    "plt.yticks(fontsize=13)\n",
    "y_ticks = plt.gca().get_yticks()\n",
    "plt.gca().set_yticklabels([f'{int(y)}' for y in y_ticks])\n",
    "\n",
    "# Add values above the bars\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center', fontsize=11)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the number of samples for each type of delay\n",
    "carrier_delay = (df['CARRIER_DELAY'] > 0).sum()\n",
    "security_delay = (df['SECURITY_DELAY'] > 0).sum()\n",
    "weather_delay = (df['WEATHER_DELAY'] > 0).sum()\n",
    "late_aircraft_delay = (df['LATE_AIRCRAFT_DELAY'] > 0).sum()\n",
    "NAS_delay = (df['NAS_DELAY'] > 0).sum()\n",
    "\n",
    "# Creation of the DataFrame for delays\n",
    "delay = pd.DataFrame({'Delay Type': ['Air carrier', 'Security', 'Weather', 'Late-arriving aircraft', 'NAS'],\n",
    "    'Count': [carrier_delay, security_delay, weather_delay, late_aircraft_delay, NAS_delay]})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = sns.barplot(x='Delay Type', y='Count', data=delay)\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel('Type of delay', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Number of flights', fontweight='bold', fontsize=14)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "# Define grid \n",
    "plt.grid(axis='y', linestyle='', alpha=0.7)\n",
    "\n",
    "# Adding values above the bars    \n",
    "for bar in bars.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center', fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of arrival flight delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['ARR_DELAY'], bins=50)\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel('Arrival delay (minutes)', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Number of flights', fontweight='bold', fontsize=14)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='DISTANCE', y='ARR_DELAY', data=df)\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel('Distance', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Arrival delay (minutes)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of weather delays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Temperature (°C)', 'Dew Point (°C)', 'Humidity (%)','Wind', 'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)','Precip. (mm)']\n",
    "for column in columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.scatterplot(x=df[column], y=df['WEATHER_DELAY'])\n",
    "\n",
    "    # Axis configuration\n",
    "    plt.xlabel(column, fontweight='bold', fontsize=14)\n",
    "    plt.ylabel('Weather Delays (minutes)', fontweight='bold', fontsize=14)\n",
    "    plt.xticks(fontsize=13)\n",
    "    plt.yticks(fontsize=13)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influence of the weather on flight delays with weather score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_temperature(temp):\n",
    "    \"\"\"\n",
    "    Classifies temperatures with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of temperature on flight delays.\n",
    "\n",
    "    Args:\n",
    "        temp (int): Temperature in degrees Celsius.\n",
    "\n",
    "    Returns:\n",
    "        int: Temperature score\n",
    "    \"\"\"\n",
    "    if 10 <= temp <= 20:\n",
    "        return 0\n",
    "    elif 0 <= temp < 10 or 20 < temp <= 30:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def classify_dew_point(dp):\n",
    "    \"\"\"\n",
    "    Classifies dew point with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of dew point on flight delays.\n",
    "\n",
    "    Args:\n",
    "        dp (int): Dew point in degrees Celsius.\n",
    "\n",
    "    Returns:\n",
    "        int: Dew point score\n",
    "    \"\"\"\n",
    "    if 10 <= dp <= 20:\n",
    "        return 0\n",
    "    elif 0 <= dp < 10 or 20 < dp <= 25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def classify_humidity(hum):\n",
    "    \"\"\"\n",
    "    Classifies humidity with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of humidity on flight delays.\n",
    "\n",
    "    Args:\n",
    "        hum (int): Humidity in percent.\n",
    "\n",
    "    Returns:\n",
    "        int: Humidity score\n",
    "    \"\"\"\n",
    "    if 40 <= hum <= 60:\n",
    "        return 0\n",
    "    elif 30 <= hum < 40 or 60 < hum <= 70:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def classify_wind_speed(ws):\n",
    "    \"\"\"\n",
    "    Classifies wind speed with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of wind speed on flight delays.\n",
    "\n",
    "    Args:\n",
    "        ws (int): Wind speed in km/h.\n",
    "\n",
    "    Returns:\n",
    "        int: Wind speed score \n",
    "    \"\"\"\n",
    "    if ws < 10:\n",
    "        return 0\n",
    "    elif 10 <= ws <= 20:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def classify_wind_gust(wg):\n",
    "    \"\"\"\n",
    "    Classifies wind gust with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of wind gust on flight delays.\n",
    "\n",
    "    Args:\n",
    "        wg (int): Wind gust in km/h.\n",
    "\n",
    "    Returns:\n",
    "        int: Wind gust score \n",
    "    \"\"\"\n",
    "    if 20 < wg < 30:\n",
    "        return 0\n",
    "    elif 10 <= wg < 20 or 30 < wg <= 40:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def classify_pressure(press):\n",
    "    \"\"\"\n",
    "    Classifies pressure with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of pressure on flight delays.\n",
    "\n",
    "    Args:\n",
    "        press (float): Pressure in hpa.\n",
    "\n",
    "    Returns:\n",
    "        int: Pressure score \n",
    "    \"\"\"\n",
    "    if 1012 <= press <= 1015:\n",
    "        return 0\n",
    "    elif 1000 <= press < 1012 or 1015 < press <= 1025:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def classify_precip(precip):\n",
    "    \"\"\"\n",
    "    Classifies precipation with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of precipation on flight delays.\n",
    "\n",
    "    Args:\n",
    "        precip (int): Precipation in mm.\n",
    "\n",
    "    Returns:\n",
    "        int: Precipation score \n",
    "    \"\"\"\n",
    "    if precip == 0:\n",
    "        return 0\n",
    "    elif 0 < precip <= 10:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def classify_condition(cond):\n",
    "    \"\"\"\n",
    "    Classifies weather condition with a score according to their influence on flight delays.\n",
    "    The higher the score, the greater the influence of weather condition on flight delays.\n",
    "\n",
    "    Args:\n",
    "        cond (string): Weather condition.\n",
    "\n",
    "    Returns:\n",
    "        int: Weather condition score \n",
    "    \"\"\"\n",
    "    if cond in ['Fair', 'Fair / Windy', 'Partly Cloudy', 'Partly Cloudy / Windy']:\n",
    "        return 0\n",
    "    \n",
    "    elif cond in ['Mostly Cloudy', 'Mostly Cloudy / Windy']:\n",
    "        return 1\n",
    "    \n",
    "    elif cond in ['Cloudy', 'Cloudy / Windy']:\n",
    "        return 2\n",
    "    \n",
    "    elif cond in ['Light Rain', 'Light Rain / Windy', 'Light Drizzle', 'Light Drizzle / Windy', \n",
    "                  'Drizzle', 'Haze', 'Mist', 'Smoke', 'Patches of Fog']:\n",
    "        return 3\n",
    "    \n",
    "    elif cond in ['Rain', 'Rain / Windy']:\n",
    "        return 4\n",
    "    \n",
    "    elif cond in ['Light Snow', 'Light Snow / Windy', 'Light Freezing Rain', 'Light Freezing Drizzle',\n",
    "                  'Light Sleet', 'Rain and Sleet','Drizzle and Fog', 'Fog', 'Fog / Windy', 'Patches of Fog / Windy', \n",
    "                  'Shallow Fog', 'Snow and Sleet', 'Snow and Sleet / Windy', 'Haze / Windy', 'Mist / Windy', \n",
    "                  'Smoke / Windy']:\n",
    "        return 5\n",
    "    \n",
    "    elif cond in ['Snow', 'Snow / Windy', 'Light Snow and Sleet', 'Light Snow and Sleet / Windy',\n",
    "                  'Wintry Mix', 'Wintry Mix / Windy', 'Rain and Snow', 'Rain and Snow / Windy',\n",
    "                  'Unknown Precipitation', 'Sleet', 'Sleet / Windy', 'Blowing Snow / Windy','Blowing Snow']:\n",
    "        return 6\n",
    "\n",
    "    elif cond in ['Heavy Rain', 'Heavy Rain / Windy', 'Squalls / Windy', 'Heavy Drizzle', 'Rain / Freezing Rain', \n",
    "                  'Snow / Freezing Rain', 'Light Snow / Freezing Rain','Heavy Snow', 'Heavy Snow / Windy', \n",
    "                  'Thunder in the Vicinity', 'Rain / Freezing Rain / Windy']:\n",
    "        return 7\n",
    "    \n",
    "    elif cond in ['Light Rain with Thunder', 'Heavy T-Storm','Heavy T-Storm / Windy', 'T-Storm', 'T-Storm / Windy', \n",
    "                  'Thunder', 'Thunder / Windy','Thunder and Hail / Windy']:\n",
    "        return 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the weather score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weather_score(row):\n",
    "    \"\"\"\n",
    "    Calculates a score based on various weather conditions.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row in the DataFrame containing the weather data for a flight.\n",
    "    \n",
    "    Returns:\n",
    "        float: Normalised score for weather based on several criteria.\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "\n",
    "    # Application of coefficients according to the importance of the scores\n",
    "    score += (classify_temperature(row['Temperature (°C)'])/2) * 2 \n",
    "    score += (classify_dew_point(row['Dew Point (°C)'])/2) * 2 \n",
    "    score += (classify_humidity(row['Humidity (%)'])/2) * 4.5 \n",
    "    score += (classify_wind_speed(row['Wind Speed (km/h)'])/2) * 3 \n",
    "    score += (classify_wind_gust(row['Wind Gust (km/h)'])/2) * 4 \n",
    "    score += (classify_pressure(row['Pressure (hPa)'])/2) * 3 \n",
    "    score += (classify_precip(row['Precip. (mm)'])/2) * 4 \n",
    "    score += (classify_condition(row['Condition'])/8) * 5 \n",
    "\n",
    "    # Global weather score normalisation\n",
    "    return score/27.5\n",
    "\n",
    "df['Weather_Score'] = df.apply(calculate_weather_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bins = [i/10 for i in range(0, 11)]\n",
    "number, bin, bars = plt.hist([df[df['STATUS'] == 2]['Weather_Score']], bins=bins)\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel('Weather Score', fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Number of Flights Delayed \\n Due to Weather', fontweight='bold', fontsize=14)\n",
    "plt.xticks([i/10 for i in range(0, 11)], fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "# Define grid\n",
    "plt.grid(True, linestyle='', alpha=0.7)\n",
    "\n",
    "# Adding values above the bars    \n",
    "for bar in bars.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval, int(yval), va='bottom', ha='center', fontsize=11)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.scatterplot(x=df[\"Weather_Score\"], y=df['WEATHER_DELAY'])\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel(\"Weather_Score\", fontweight='bold', fontsize=14)\n",
    "plt.ylabel('Weather Delays (minutes)', fontweight='bold', fontsize=14)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    \"\"\"\n",
    "    Encodes categorical and string columns using Label Encoding.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing columns to encode.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with encoded columns.\n",
    "    \"\"\"\n",
    "    # Select columns of type category, object, string or datetime.\n",
    "    columnsToEncode = list(df.select_dtypes(include=['category', 'object', 'string', 'datetime']))\n",
    "    for feature in columnsToEncode:\n",
    "        # Initialise the LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        print(feature)\n",
    "        # Encode the column with LabelEncoder\n",
    "        df[feature] = le.fit_transform(df[feature])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be normalised\n",
    "features = ['FL_DATE', 'OP_UNIQUE_CARRIER', 'TAIL_NUM', 'OP_CARRIER_FL_NUM',\n",
    "       'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'DEP_DEL15',\n",
    "       'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME',\n",
    "       'ARR_TIME', 'ARR_DELAY', 'ARR_DEL15', 'CRS_ELAPSED_TIME',\n",
    "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
    "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
    "       'Temperature (°C)', 'Dew Point (°C)', 'Humidity (%)', 'Wind',\n",
    "       'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)',\n",
    "       'Precip. (mm)', 'Condition']\n",
    "\n",
    "# Creation of a MinMaxScaler object \n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features\n",
    "features = ['FL_DATE', 'OP_UNIQUE_CARRIER', 'TAIL_NUM', 'OP_CARRIER_FL_NUM',\n",
    "       'ORIGIN', 'DEST', 'CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'DEP_DEL15',\n",
    "       'TAXI_OUT', 'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME',\n",
    "       'ARR_TIME', 'ARR_DELAY', 'ARR_DEL15', 'CRS_ELAPSED_TIME',\n",
    "       'ACTUAL_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', 'CARRIER_DELAY',\n",
    "       'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY',\n",
    "       'Temperature (°C)', 'Dew Point (°C)', 'Humidity (%)', 'Wind',\n",
    "       'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)',\n",
    "       'Precip. (mm)', 'Condition']\n",
    "\n",
    "target = \"STATUS\"\n",
    "\n",
    "# Divide data into training, validation and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df[target], test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# DataFrame for training data\n",
    "df_train = pd.DataFrame(X_train, columns=features)\n",
    "df_train['STATUS'] = y_train\n",
    "\n",
    "# DataFrame for validation data\n",
    "df_val = pd.DataFrame(X_val, columns=features)\n",
    "df_val['STATUS'] = y_val\n",
    "\n",
    "# DataFrame for test data\n",
    "df_test = pd.DataFrame(X_test, columns=features)\n",
    "df_test['STATUS'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of an instance of SMOTE with a specific random string for reproducibility\n",
    "smote = SMOTE(random_state=RANDOM_SEED)\n",
    "\n",
    "# Application of SMOTE to resample training data in order to balance the data\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Creation of a DataFrame with the resampled data\n",
    "df_train_resampled = pd.DataFrame(X_train_resampled, columns=features)\n",
    "df_train_resampled['STATUS'] = y_train_resampled\n",
    "df_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_resampled['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of relevant columns to be retained in the DataFrame before selection\n",
    "relevant_columns = ['FL_DATE','CRS_DEP_TIME', 'DEP_TIME', 'DEP_DELAY', 'DEP_DEL15','TAXI_OUT', 'WHEELS_OFF', 'CRS_ARR_TIME',\n",
    "                    'CRS_ELAPSED_TIME', 'DISTANCE','Temperature (°C)', 'Dew Point (°C)', 'Humidity (%)', 'Wind',\n",
    "                    'Wind Speed (km/h)', 'Wind Gust (km/h)', 'Pressure (hPa)','Precip. (mm)', 'Condition', \n",
    "                    'STATUS']\n",
    "\n",
    "df_train_resampled = df_train_resampled[relevant_columns]\n",
    "df_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = df_train_resampled.corr()\n",
    "print(corr_matrix)\n",
    "\n",
    "# Heat map of the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X_feature_selection = df_train_resampled.drop(columns=['STATUS'])\n",
    "y_feature_selection = df_train_resampled['STATUS']\n",
    "\n",
    "# Use the mutual information score to determine the relationships between features and the target variable\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "X_results = selector.fit_transform(X_feature_selection, y_feature_selection)\n",
    "\n",
    "# Display scores\n",
    "mutual_info_scores = pd.DataFrame({'Feature': X_feature_selection.columns, 'Score': selector.scores_})\n",
    "print(mutual_info_scores.sort_values(by='Score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort scores in descending order\n",
    "mutual_info_scores = mutual_info_scores.sort_values(by='Score', ascending=False)\n",
    "\n",
    "# Horizontal bar chart with features and their mutual information scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(mutual_info_scores[\"Feature\"], mutual_info_scores[\"Score\"])\n",
    "\n",
    "# Axis configuration\n",
    "plt.xlabel('Mutual information score', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Features', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Mutual information score threshold\n",
    "plt.axvline(x=0.15, color='red', linestyle='--', linewidth=2) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with a score of more than 0.2 are retained.\n",
    "features = ['DEP_DELAY', 'WHEELS_OFF', 'TAXI_OUT', 'DEP_TIME', 'FL_DATE', 'CRS_ARR_TIME', 'DEP_DEL15', \n",
    "            'CRS_ELAPSED_TIME', 'Pressure (hPa)','CRS_DEP_TIME', 'Humidity (%)','Temperature (°C)',\n",
    "            'Dew Point (°C)','Wind Speed (km/h)','DISTANCE','Wind','Condition']\n",
    "\n",
    "# Correlation matrix for selected features\n",
    "corr_matrix = df_train_resampled[features].corr()\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Heat map of the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', center=0, linewidths=.5)\n",
    "plt.show()\n",
    "\n",
    "# Selection of feature pairs with an absolute correlation greater than 0.8\n",
    "high_corr = corr_matrix[((corr_matrix >= 0.8) & (corr_matrix < 1.00)) | ((corr_matrix <= -0.8) & (corr_matrix <= -1.00))]\n",
    "high_corr = high_corr.dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "\n",
    "# Transformation of the correlation matrix into a DataFrame \n",
    "high_corr_unstacked = high_corr.unstack().dropna().reset_index()\n",
    "high_corr_unstacked.columns = ['Feature 1', 'Feature 2', 'Correlation Coefficient']\n",
    "\n",
    "# Store pairs of highly correlated features\n",
    "high_corr_unstacked['Ordered Features'] = high_corr_unstacked.apply(lambda row: tuple(sorted([row['Feature 1'], row['Feature 2']])), axis=1)\n",
    "\n",
    "# Delete duplicate pairs\n",
    "high_corr_unstacked = high_corr_unstacked.drop_duplicates(subset='Ordered Features').drop(columns='Ordered Features')\n",
    "\n",
    "print(high_corr_unstacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features selected for training and evaluation of models\n",
    "features = ['DEP_DELAY', 'WHEELS_OFF', 'TAXI_OUT', 'FL_DATE', 'CRS_ARR_TIME', 'DEP_DEL15', \n",
    "            'CRS_ELAPSED_TIME', 'Pressure (hPa)','CRS_DEP_TIME', 'Humidity (%)','Temperature (°C)'\n",
    "            ,'Wind Speed (km/h)','Wind','Condition']\n",
    "\n",
    "target = 'STATUS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_resampled = df_train_resampled[features + [target]]\n",
    "df_val = df_val[features + [target]]\n",
    "df_test = df_test[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving data\n",
    "df_train_resampled.to_csv(f\"Training_Dataset_{timing}h.csv\",index=False) \n",
    "df_val.to_csv(f\"Validation_Dataset_{timing}h.csv\",index=False) \n",
    "df_test.to_csv(f\"Testing_Dataset_{timing}h.csv\",index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
