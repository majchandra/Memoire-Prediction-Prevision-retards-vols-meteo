CUDA_VISIBLE_DEVICES=GPU-415dcdca-40f2-6526-4804-510e0422b7ad
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pandas in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.2.2)
Requirement already satisfied: pytz>=2020.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: tzdata>=2022.7 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: numpy>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (1.26.4)
Requirement already satisfied: six>=1.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: imblearn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.0)
Requirement already satisfied: imbalanced-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imblearn) (0.12.3)
Requirement already satisfied: joblib>=1.1.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.4.2)
Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.5.0)
Requirement already satisfied: scikit-learn>=1.0.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.5.0)
Requirement already satisfied: numpy>=1.17.3 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.26.4)
Requirement already satisfied: scipy>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.13.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.3.1)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (3.6.0)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2024.6.0)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.11.3)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (1.10.1)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.8.4)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.20.5)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.3.1)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (4.12.1)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch) (1.2.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: scikit-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: scipy>=1.6.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)
Requirement already satisfied: threadpoolctl>=3.1.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (3.5.0)
Requirement already satisfied: joblib>=1.2.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)
Requirement already satisfied: numpy>=1.19.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.26.4)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.26.4)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torchdiffeq in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.2.4)
Requirement already satisfied: scipy>=1.4.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (1.13.1)
Requirement already satisfied: torch>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (2.3.1)
Requirement already satisfied: numpy<2.3,>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (1.10.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (4.12.1)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.3.1)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.11.3)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.8.4)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (3.6.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.20.5)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2024.6.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.2.1)
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
42
cuda
0h
Testing configuration: batch_size=1024, num_epochs=20, num_layers=2, learning_rate=0.001, dropout=0.5, hidden_size=150
Epoch 1/20, Train Loss: 0.6175, Val Loss: 0.4611
Epoch 2/20, Train Loss: 0.5521, Val Loss: 0.4019
Epoch 3/20, Train Loss: 0.5344, Val Loss: 0.4100
Epoch 4/20, Train Loss: 0.5223, Val Loss: 0.3815
Epoch 5/20, Train Loss: 0.5136, Val Loss: 0.4254
Epoch 6/20, Train Loss: 0.5069, Val Loss: 0.3601
Epoch 7/20, Train Loss: 0.5009, Val Loss: 0.3870
Epoch 8/20, Train Loss: 0.4962, Val Loss: 0.3737
Epoch 9/20, Train Loss: 0.4928, Val Loss: 0.3685
Epoch 10/20, Train Loss: 0.4894, Val Loss: 0.3773
Epoch 11/20, Train Loss: 0.4870, Val Loss: 0.3464
Epoch 12/20, Train Loss: 0.4846, Val Loss: 0.4234
Epoch 13/20, Train Loss: 0.4823, Val Loss: 0.3661
Epoch 14/20, Train Loss: 0.4802, Val Loss: 0.3704
Epoch 15/20, Train Loss: 0.4779, Val Loss: 0.4454
Epoch 16/20, Train Loss: 0.4763, Val Loss: 0.3932
Epoch 17/20, Train Loss: 0.4742, Val Loss: 0.4693
Epoch 18/20, Train Loss: 0.4720, Val Loss: 0.3898
Epoch 19/20, Train Loss: 0.4706, Val Loss: 0.3760
Epoch 20/20, Train Loss: 0.4683, Val Loss: 0.3631
Total training time: 688.0322s

Confusion Matrix:
[[179985  12407   2577]
 [  8397  32602  12593]
 [   132    580   2427]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.72      0.61      0.66     53592
           2       0.14      0.77      0.23      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.77      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8542
Total evaluation time: 5.5619s
Test Loss: 0.3648
Testing configuration: batch_size=1024, num_epochs=20, num_layers=2, learning_rate=0.0001, dropout=0.5, hidden_size=150
Epoch 1/20, Train Loss: 0.7654, Val Loss: 0.5177
Epoch 2/20, Train Loss: 0.6259, Val Loss: 0.4652
Epoch 3/20, Train Loss: 0.6075, Val Loss: 0.4602
Epoch 4/20, Train Loss: 0.5970, Val Loss: 0.4446
Epoch 5/20, Train Loss: 0.5885, Val Loss: 0.4408
Epoch 6/20, Train Loss: 0.5816, Val Loss: 0.4249
Epoch 7/20, Train Loss: 0.5751, Val Loss: 0.4153
Epoch 8/20, Train Loss: 0.5690, Val Loss: 0.4072
Epoch 9/20, Train Loss: 0.5635, Val Loss: 0.3872
Epoch 10/20, Train Loss: 0.5586, Val Loss: 0.4071
Epoch 11/20, Train Loss: 0.5543, Val Loss: 0.4149
Epoch 12/20, Train Loss: 0.5500, Val Loss: 0.3895
Epoch 13/20, Train Loss: 0.5464, Val Loss: 0.3994
Epoch 14/20, Train Loss: 0.5431, Val Loss: 0.4082
Epoch 15/20, Train Loss: 0.5400, Val Loss: 0.3975
Epoch 16/20, Train Loss: 0.5373, Val Loss: 0.3908
Epoch 17/20, Train Loss: 0.5352, Val Loss: 0.3754
Epoch 18/20, Train Loss: 0.5333, Val Loss: 0.3918
Epoch 19/20, Train Loss: 0.5323, Val Loss: 0.3741
Epoch 20/20, Train Loss: 0.5307, Val Loss: 0.3971
Total training time: 687.3511s

Confusion Matrix:
[[178015  15708   1246]
 [  8076  33344  12172]
 [   141    744   2254]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.67      0.62      0.65     53592
           2       0.14      0.72      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.75      0.61    251700
weighted avg       0.88      0.85      0.86    251700


Global Accuracy: 0.8487
Total evaluation time: 5.5624s
Test Loss: 0.3985
Testing configuration: batch_size=1024, num_epochs=20, num_layers=5, learning_rate=0.001, dropout=0.5, hidden_size=150
Epoch 1/20, Train Loss: 0.6354, Val Loss: 0.3957
Epoch 2/20, Train Loss: 0.5657, Val Loss: 0.3855
Epoch 3/20, Train Loss: 0.5430, Val Loss: 0.3579
Epoch 4/20, Train Loss: 0.5321, Val Loss: 0.3684
Epoch 5/20, Train Loss: 0.5239, Val Loss: 0.3314
Epoch 6/20, Train Loss: 0.5174, Val Loss: 0.3340
Epoch 7/20, Train Loss: 0.5111, Val Loss: 0.3762
Epoch 8/20, Train Loss: 0.5057, Val Loss: 0.3588
Epoch 9/20, Train Loss: 0.5030, Val Loss: 0.3782
Epoch 10/20, Train Loss: 0.5005, Val Loss: 0.4243
Epoch 11/20, Train Loss: 0.4985, Val Loss: 0.4041
Epoch 12/20, Train Loss: 0.4970, Val Loss: 0.3678
Epoch 13/20, Train Loss: 0.4948, Val Loss: 0.3707
Epoch 14/20, Train Loss: 0.4937, Val Loss: 0.3810
Epoch 15/20, Train Loss: 0.4926, Val Loss: 0.3584
Epoch 16/20, Train Loss: 0.4910, Val Loss: 0.3680
Epoch 17/20, Train Loss: 0.4899, Val Loss: 0.3319
Epoch 18/20, Train Loss: 0.4892, Val Loss: 0.4108
Epoch 19/20, Train Loss: 0.4878, Val Loss: 0.3808
Epoch 20/20, Train Loss: 0.4866, Val Loss: 0.3725
Total training time: 1145.5424s

Confusion Matrix:
[[177367  16088   1514]
 [  7672  34056  11864]
 [   139    623   2377]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.67      0.64      0.65     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.77      0.61    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8494
Total evaluation time: 8.3300s
Test Loss: 0.3742
Testing configuration: batch_size=1024, num_epochs=20, num_layers=5, learning_rate=0.0001, dropout=0.5, hidden_size=150
Epoch 1/20, Train Loss: 0.7438, Val Loss: 0.4782
Epoch 2/20, Train Loss: 0.6345, Val Loss: 0.4984
Epoch 3/20, Train Loss: 0.6193, Val Loss: 0.4739
Epoch 4/20, Train Loss: 0.6101, Val Loss: 0.4601
Epoch 5/20, Train Loss: 0.6028, Val Loss: 0.4525
Epoch 6/20, Train Loss: 0.5919, Val Loss: 0.4296
Epoch 7/20, Train Loss: 0.5805, Val Loss: 0.4144
Epoch 8/20, Train Loss: 0.5725, Val Loss: 0.4025
Epoch 9/20, Train Loss: 0.5672, Val Loss: 0.4233
Epoch 10/20, Train Loss: 0.5632, Val Loss: 0.3888
Epoch 11/20, Train Loss: 0.5596, Val Loss: 0.4088
Epoch 12/20, Train Loss: 0.5559, Val Loss: 0.3993
Epoch 13/20, Train Loss: 0.5525, Val Loss: 0.3800
Epoch 14/20, Train Loss: 0.5493, Val Loss: 0.3990
Epoch 15/20, Train Loss: 0.5460, Val Loss: 0.3810
Epoch 16/20, Train Loss: 0.5434, Val Loss: 0.3945
Epoch 17/20, Train Loss: 0.5411, Val Loss: 0.3821
Epoch 18/20, Train Loss: 0.5385, Val Loss: 0.3919
Epoch 19/20, Train Loss: 0.5366, Val Loss: 0.3870
Epoch 20/20, Train Loss: 0.5348, Val Loss: 0.3895
Total training time: 1148.2378s

Confusion Matrix:
[[178719  14656   1594]
 [  8257  33191  12144]
 [   145    751   2243]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.68      0.62      0.65     53592
           2       0.14      0.71      0.23      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.75      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8508
Total evaluation time: 8.3054s
Test Loss: 0.3912
Testing configuration: batch_size=1024, num_epochs=20, num_layers=10, learning_rate=0.001, dropout=0.5, hidden_size=150
Epoch 1/20, Train Loss: 1.0987, Val Loss: 1.1029
Epoch 2/20, Train Loss: 1.0960, Val Loss: 1.0993
Epoch 3/20, Train Loss: 1.0986, Val Loss: 1.0967
Epoch 4/20, Train Loss: 1.0986, Val Loss: 1.0993
Epoch 5/20, Train Loss: 1.0986, Val Loss: 1.0988
Epoch 6/20, Train Loss: 1.0986, Val Loss: 1.1024
Epoch 7/20, Train Loss: 1.0986, Val Loss: 1.0877
Epoch 8/20, Train Loss: 1.0986, Val Loss: 1.0936
Epoch 9/20, Train Loss: 1.0986, Val Loss: 1.0968
Epoch 10/20, Train Loss: 1.0986, Val Loss: 1.1008
Epoch 11/20, Train Loss: 1.0986, Val Loss: 1.0909
Epoch 12/20, Train Loss: 1.0986, Val Loss: 1.0958
Epoch 13/20, Train Loss: 1.0986, Val Loss: 1.0906
Epoch 14/20, Train Loss: 1.0986, Val Loss: 1.1009
Epoch 15/20, Train Loss: 1.0986, Val Loss: 1.0978
Epoch 16/20, Train Loss: 1.0986, Val Loss: 1.0959
Epoch 17/20, Train Loss: 1.0986, Val Loss: 1.0951
Epoch 18/20, Train Loss: 1.0986, Val Loss: 1.1025
Epoch 19/20, Train Loss: 1.0986, Val Loss: 1.0928
Epoch 20/20, Train Loss: 1.0986, Val Loss: 1.0996
Total training time: 1955.1294s

Confusion Matrix:
[[     0 194969      0]
 [     0  53592      0]
 [     0   3139      0]]

Classification Report:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00    194969
           1       0.21      1.00      0.35     53592
           2       0.00      0.00      0.00      3139

    accuracy                           0.21    251700
   macro avg       0.07      0.33      0.12    251700
weighted avg       0.05      0.21      0.07    251700


Global Accuracy: 0.2129
Total evaluation time: 12.7473s
Test Loss: 1.0996
Testing configuration: batch_size=1024, num_epochs=20, num_layers=10, learning_rate=0.0001, dropout=0.5, hidden_size=150
Epoch 1/20, Train Loss: 1.0987, Val Loss: 1.1017
Epoch 2/20, Train Loss: 1.0986, Val Loss: 1.1003
Epoch 3/20, Train Loss: 1.0986, Val Loss: 1.1015
Epoch 4/20, Train Loss: 0.9386, Val Loss: 0.5685
Epoch 5/20, Train Loss: 0.6596, Val Loss: 0.4824
Epoch 6/20, Train Loss: 0.6291, Val Loss: 0.4617
Epoch 7/20, Train Loss: 0.6185, Val Loss: 0.4563
Epoch 8/20, Train Loss: 0.6122, Val Loss: 0.4447
Epoch 9/20, Train Loss: 0.6068, Val Loss: 0.4336
Epoch 10/20, Train Loss: 0.6005, Val Loss: 0.4235
Epoch 11/20, Train Loss: 0.5943, Val Loss: 0.4200
Epoch 12/20, Train Loss: 0.5876, Val Loss: 0.4117
Epoch 13/20, Train Loss: 0.5821, Val Loss: 0.4450
Epoch 14/20, Train Loss: 0.5779, Val Loss: 0.4007
Epoch 15/20, Train Loss: 0.5749, Val Loss: 0.3913
Epoch 16/20, Train Loss: 0.5718, Val Loss: 0.4089
Epoch 17/20, Train Loss: 0.5693, Val Loss: 0.3904
Epoch 18/20, Train Loss: 0.5665, Val Loss: 0.4096
Epoch 19/20, Train Loss: 0.5642, Val Loss: 0.4149
Epoch 20/20, Train Loss: 0.5620, Val Loss: 0.3922
Total training time: 1945.7471s

Confusion Matrix:
[[181551  13118    300]
 [  9440  31392  12760]
 [   156    796   2187]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.69      0.59      0.63     53592
           2       0.14      0.70      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.74      0.60    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8547
Total evaluation time: 12.9376s
Test Loss: 0.3936
Testing configuration: batch_size=1024, num_epochs=50, num_layers=2, learning_rate=0.001, dropout=0.5, hidden_size=150
Epoch 1/50, Train Loss: 0.6180, Val Loss: 0.4393
Epoch 2/50, Train Loss: 0.5528, Val Loss: 0.4477
Epoch 3/50, Train Loss: 0.5338, Val Loss: 0.3811
Epoch 4/50, Train Loss: 0.5231, Val Loss: 0.4108
Epoch 5/50, Train Loss: 0.5134, Val Loss: 0.3586
Epoch 6/50, Train Loss: 0.5058, Val Loss: 0.3583
Epoch 7/50, Train Loss: 0.4993, Val Loss: 0.3791
Epoch 8/50, Train Loss: 0.4955, Val Loss: 0.3505
Epoch 9/50, Train Loss: 0.4916, Val Loss: 0.3455
Epoch 10/50, Train Loss: 0.4889, Val Loss: 0.3514
Epoch 11/50, Train Loss: 0.4862, Val Loss: 0.3555
Epoch 12/50, Train Loss: 0.4842, Val Loss: 0.3638
Epoch 13/50, Train Loss: 0.4817, Val Loss: 0.4121
Epoch 14/50, Train Loss: 0.4803, Val Loss: 0.4086
Epoch 15/50, Train Loss: 0.4778, Val Loss: 0.3464
Epoch 16/50, Train Loss: 0.4762, Val Loss: 0.3835
Epoch 17/50, Train Loss: 0.4743, Val Loss: 0.3958
Epoch 18/50, Train Loss: 0.4725, Val Loss: 0.3280
Epoch 19/50, Train Loss: 0.4710, Val Loss: 0.3663
Epoch 20/50, Train Loss: 0.4691, Val Loss: 0.3703
Epoch 21/50, Train Loss: 0.4675, Val Loss: 0.3481
Epoch 22/50, Train Loss: 0.4650, Val Loss: 0.3943
Epoch 23/50, Train Loss: 0.4636, Val Loss: 0.3504
Epoch 24/50, Train Loss: 0.4614, Val Loss: 0.3846
Epoch 25/50, Train Loss: 0.4600, Val Loss: 0.3432
Epoch 26/50, Train Loss: 0.4589, Val Loss: 0.3680
Epoch 27/50, Train Loss: 0.4571, Val Loss: 0.3845
Epoch 28/50, Train Loss: 0.4554, Val Loss: 0.3477
Epoch 29/50, Train Loss: 0.4543, Val Loss: 0.3712
Epoch 30/50, Train Loss: 0.4525, Val Loss: 0.3479
Epoch 31/50, Train Loss: 0.4511, Val Loss: 0.3354
Epoch 32/50, Train Loss: 0.4502, Val Loss: 0.3333
Epoch 33/50, Train Loss: 0.4487, Val Loss: 0.3354
Epoch 34/50, Train Loss: 0.4474, Val Loss: 0.3636
Epoch 35/50, Train Loss: 0.4462, Val Loss: 0.3621
Epoch 36/50, Train Loss: 0.4452, Val Loss: 0.3574
Epoch 37/50, Train Loss: 0.4436, Val Loss: 0.3526
Epoch 38/50, Train Loss: 0.4429, Val Loss: 0.3673
Epoch 39/50, Train Loss: 0.4418, Val Loss: 0.3606
Epoch 40/50, Train Loss: 0.4406, Val Loss: 0.3542
Epoch 41/50, Train Loss: 0.4398, Val Loss: 0.3479
Epoch 42/50, Train Loss: 0.4387, Val Loss: 0.3344
Epoch 43/50, Train Loss: 0.4379, Val Loss: 0.3659
Epoch 44/50, Train Loss: 0.4371, Val Loss: 0.3743
Epoch 45/50, Train Loss: 0.4361, Val Loss: 0.3579
Epoch 46/50, Train Loss: 0.4349, Val Loss: 0.3657
Epoch 47/50, Train Loss: 0.4344, Val Loss: 0.3617
Epoch 48/50, Train Loss: 0.4332, Val Loss: 0.3539
Epoch 49/50, Train Loss: 0.4326, Val Loss: 0.3601
Epoch 50/50, Train Loss: 0.4316, Val Loss: 0.3922
Total training time: 1711.4834s

Confusion Matrix:
[[173244  18331   3394]
 [  6604  36048  10940]
 [   106    668   2365]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.89      0.92    194969
           1       0.65      0.67      0.66     53592
           2       0.14      0.75      0.24      3139

    accuracy                           0.84    251700
   macro avg       0.59      0.77      0.61    251700
weighted avg       0.89      0.84      0.86    251700


Global Accuracy: 0.8409
Total evaluation time: 5.5653s
Test Loss: 0.3928
Testing configuration: batch_size=1024, num_epochs=50, num_layers=2, learning_rate=0.0001, dropout=0.5, hidden_size=150
Epoch 1/50, Train Loss: 0.7698, Val Loss: 0.5245
Epoch 2/50, Train Loss: 0.6268, Val Loss: 0.4598
Epoch 3/50, Train Loss: 0.6087, Val Loss: 0.4607
Epoch 4/50, Train Loss: 0.5989, Val Loss: 0.4511
Epoch 5/50, Train Loss: 0.5895, Val Loss: 0.4374
Epoch 6/50, Train Loss: 0.5819, Val Loss: 0.4372
Epoch 7/50, Train Loss: 0.5753, Val Loss: 0.4187
Epoch 8/50, Train Loss: 0.5691, Val Loss: 0.3980
Epoch 9/50, Train Loss: 0.5634, Val Loss: 0.3889
Epoch 10/50, Train Loss: 0.5583, Val Loss: 0.3871
Epoch 11/50, Train Loss: 0.5536, Val Loss: 0.3891
Epoch 12/50, Train Loss: 0.5493, Val Loss: 0.3979
Epoch 13/50, Train Loss: 0.5455, Val Loss: 0.3775
Epoch 14/50, Train Loss: 0.5421, Val Loss: 0.3792
Epoch 15/50, Train Loss: 0.5392, Val Loss: 0.3896
Epoch 16/50, Train Loss: 0.5370, Val Loss: 0.3806
Epoch 17/50, Train Loss: 0.5350, Val Loss: 0.3986
Epoch 18/50, Train Loss: 0.5336, Val Loss: 0.3729
Epoch 19/50, Train Loss: 0.5324, Val Loss: 0.3949
Epoch 20/50, Train Loss: 0.5309, Val Loss: 0.4350
Epoch 21/50, Train Loss: 0.5297, Val Loss: 0.3875
Epoch 22/50, Train Loss: 0.5286, Val Loss: 0.3907
Epoch 23/50, Train Loss: 0.5273, Val Loss: 0.3853
Epoch 24/50, Train Loss: 0.5263, Val Loss: 0.3892
Epoch 25/50, Train Loss: 0.5248, Val Loss: 0.3788
Epoch 26/50, Train Loss: 0.5237, Val Loss: 0.3951
Epoch 27/50, Train Loss: 0.5224, Val Loss: 0.3954
Epoch 28/50, Train Loss: 0.5213, Val Loss: 0.4023
Epoch 29/50, Train Loss: 0.5199, Val Loss: 0.3913
Epoch 30/50, Train Loss: 0.5188, Val Loss: 0.3967
Epoch 31/50, Train Loss: 0.5178, Val Loss: 0.3959
Epoch 32/50, Train Loss: 0.5166, Val Loss: 0.3759
Epoch 33/50, Train Loss: 0.5153, Val Loss: 0.3715
Epoch 34/50, Train Loss: 0.5141, Val Loss: 0.3690
Epoch 35/50, Train Loss: 0.5133, Val Loss: 0.3920
Epoch 36/50, Train Loss: 0.5120, Val Loss: 0.3748
Epoch 37/50, Train Loss: 0.5112, Val Loss: 0.3645
Epoch 38/50, Train Loss: 0.5105, Val Loss: 0.3813
Epoch 39/50, Train Loss: 0.5097, Val Loss: 0.3862
Epoch 40/50, Train Loss: 0.5089, Val Loss: 0.3974
Epoch 41/50, Train Loss: 0.5083, Val Loss: 0.3662
Epoch 42/50, Train Loss: 0.5073, Val Loss: 0.3763
Epoch 43/50, Train Loss: 0.5067, Val Loss: 0.3715
Epoch 44/50, Train Loss: 0.5060, Val Loss: 0.3636
Epoch 45/50, Train Loss: 0.5053, Val Loss: 0.3891
Epoch 46/50, Train Loss: 0.5044, Val Loss: 0.3679
Epoch 47/50, Train Loss: 0.5040, Val Loss: 0.3823
Epoch 48/50, Train Loss: 0.5030, Val Loss: 0.3897
Epoch 49/50, Train Loss: 0.5025, Val Loss: 0.3926
Epoch 50/50, Train Loss: 0.5017, Val Loss: 0.3643
Total training time: 1709.7345s

Confusion Matrix:
[[180434  13127   1408]
 [  8733  33289  11570]
 [   149    729   2261]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.71      0.62      0.66     53592
           2       0.15      0.72      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.60      0.76      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8581
Total evaluation time: 5.5387s
Test Loss: 0.3661
Testing configuration: batch_size=1024, num_epochs=50, num_layers=5, learning_rate=0.001, dropout=0.5, hidden_size=150
Epoch 1/50, Train Loss: 0.6318, Val Loss: 0.5065
Epoch 2/50, Train Loss: 0.5626, Val Loss: 0.3696
Epoch 3/50, Train Loss: 0.5426, Val Loss: 0.3990
Epoch 4/50, Train Loss: 0.5326, Val Loss: 0.4123
Epoch 5/50, Train Loss: 0.5250, Val Loss: 0.3761
Epoch 6/50, Train Loss: 0.5189, Val Loss: 0.3463
Epoch 7/50, Train Loss: 0.5136, Val Loss: 0.3722
Epoch 8/50, Train Loss: 0.5079, Val Loss: 0.3606
Epoch 9/50, Train Loss: 0.5042, Val Loss: 0.3836
Epoch 10/50, Train Loss: 0.5017, Val Loss: 0.4290
Epoch 11/50, Train Loss: 0.4999, Val Loss: 0.3836
Epoch 12/50, Train Loss: 0.4976, Val Loss: 0.4246
Epoch 13/50, Train Loss: 0.4962, Val Loss: 0.3556
Epoch 14/50, Train Loss: 0.4945, Val Loss: 0.4019
Epoch 15/50, Train Loss: 0.4932, Val Loss: 0.3858
Epoch 16/50, Train Loss: 0.4921, Val Loss: 0.3805
Epoch 17/50, Train Loss: 0.4910, Val Loss: 0.3926
Epoch 18/50, Train Loss: 0.4901, Val Loss: 0.3377
Epoch 19/50, Train Loss: 0.4883, Val Loss: 0.4274
Epoch 20/50, Train Loss: 0.4878, Val Loss: 0.3407
Epoch 21/50, Train Loss: 0.4868, Val Loss: 0.3899
Epoch 22/50, Train Loss: 0.4854, Val Loss: 0.3851
Epoch 23/50, Train Loss: 0.4846, Val Loss: 0.3904
Epoch 24/50, Train Loss: 0.4837, Val Loss: 0.3629
Epoch 25/50, Train Loss: 0.4826, Val Loss: 0.3515
Epoch 26/50, Train Loss: 0.4817, Val Loss: 0.3805
Epoch 27/50, Train Loss: 0.4813, Val Loss: 0.3611
Epoch 28/50, Train Loss: 0.4802, Val Loss: 0.3474
Epoch 29/50, Train Loss: 0.4798, Val Loss: 0.3572
Epoch 30/50, Train Loss: 0.4788, Val Loss: 0.3892
Epoch 31/50, Train Loss: 0.4783, Val Loss: 0.3343
Epoch 32/50, Train Loss: 0.4774, Val Loss: 0.3699
Epoch 33/50, Train Loss: 0.4771, Val Loss: 0.3747
Epoch 34/50, Train Loss: 0.4760, Val Loss: 0.3776
Epoch 35/50, Train Loss: 0.4755, Val Loss: 0.3705
Epoch 36/50, Train Loss: 0.4745, Val Loss: 0.3514
Epoch 37/50, Train Loss: 0.4740, Val Loss: 0.3756
Epoch 38/50, Train Loss: 0.4736, Val Loss: 0.3441
Epoch 39/50, Train Loss: 0.4729, Val Loss: 0.3725
Epoch 40/50, Train Loss: 0.4725, Val Loss: 0.3375
Epoch 41/50, Train Loss: 0.4714, Val Loss: 0.3647
Epoch 42/50, Train Loss: 0.4714, Val Loss: 0.3404
Epoch 43/50, Train Loss: 0.4710, Val Loss: 0.3685
Epoch 44/50, Train Loss: 0.4700, Val Loss: 0.3763
Epoch 45/50, Train Loss: 0.4697, Val Loss: 0.3707
Epoch 46/50, Train Loss: 0.4690, Val Loss: 0.3610
Epoch 47/50, Train Loss: 0.4685, Val Loss: 0.3580
Epoch 48/50, Train Loss: 0.4679, Val Loss: 0.3356
Epoch 49/50, Train Loss: 0.4676, Val Loss: 0.3590
Epoch 50/50, Train Loss: 0.4674, Val Loss: 0.3527
Total training time: 2853.6685s

Confusion Matrix:
[[179350  13622   1997]
 [  8164  35131  10297]
 [   135    668   2336]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.71      0.66      0.68     53592
           2       0.16      0.74      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.63    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8614
Total evaluation time: 8.3534s
Test Loss: 0.3540
Testing configuration: batch_size=1024, num_epochs=50, num_layers=5, learning_rate=0.0001, dropout=0.5, hidden_size=150
Epoch 1/50, Train Loss: 0.7450, Val Loss: 0.4858
Epoch 2/50, Train Loss: 0.6331, Val Loss: 0.4712
Epoch 3/50, Train Loss: 0.6182, Val Loss: 0.4762
Epoch 4/50, Train Loss: 0.6090, Val Loss: 0.4390
Epoch 5/50, Train Loss: 0.6010, Val Loss: 0.4362
Epoch 6/50, Train Loss: 0.5908, Val Loss: 0.4268
Epoch 7/50, Train Loss: 0.5807, Val Loss: 0.4255
Epoch 8/50, Train Loss: 0.5727, Val Loss: 0.4295
Epoch 9/50, Train Loss: 0.5668, Val Loss: 0.4381
Epoch 10/50, Train Loss: 0.5625, Val Loss: 0.4036
Epoch 11/50, Train Loss: 0.5589, Val Loss: 0.4063
Epoch 12/50, Train Loss: 0.5550, Val Loss: 0.3954
Epoch 13/50, Train Loss: 0.5517, Val Loss: 0.3891
Epoch 14/50, Train Loss: 0.5485, Val Loss: 0.4090
Epoch 15/50, Train Loss: 0.5454, Val Loss: 0.3730
Epoch 16/50, Train Loss: 0.5429, Val Loss: 0.4079
Epoch 17/50, Train Loss: 0.5403, Val Loss: 0.3882
Epoch 18/50, Train Loss: 0.5382, Val Loss: 0.4089
Epoch 19/50, Train Loss: 0.5364, Val Loss: 0.3838
Epoch 20/50, Train Loss: 0.5348, Val Loss: 0.3870
Epoch 21/50, Train Loss: 0.5332, Val Loss: 0.4117
Epoch 22/50, Train Loss: 0.5317, Val Loss: 0.3630
Epoch 23/50, Train Loss: 0.5305, Val Loss: 0.3757
Epoch 24/50, Train Loss: 0.5296, Val Loss: 0.4040
Epoch 25/50, Train Loss: 0.5284, Val Loss: 0.3819
Epoch 26/50, Train Loss: 0.5273, Val Loss: 0.3946
Epoch 27/50, Train Loss: 0.5266, Val Loss: 0.3807
Epoch 28/50, Train Loss: 0.5259, Val Loss: 0.4062
Epoch 29/50, Train Loss: 0.5248, Val Loss: 0.4144
Epoch 30/50, Train Loss: 0.5242, Val Loss: 0.3665
Epoch 31/50, Train Loss: 0.5233, Val Loss: 0.3879
Epoch 32/50, Train Loss: 0.5227, Val Loss: 0.3760
Epoch 33/50, Train Loss: 0.5217, Val Loss: 0.3909
Epoch 34/50, Train Loss: 0.5211, Val Loss: 0.3992
Epoch 35/50, Train Loss: 0.5206, Val Loss: 0.3879
Epoch 36/50, Train Loss: 0.5197, Val Loss: 0.3883
Epoch 37/50, Train Loss: 0.5190, Val Loss: 0.3855
Epoch 38/50, Train Loss: 0.5185, Val Loss: 0.3771
Epoch 39/50, Train Loss: 0.5175, Val Loss: 0.3631
Epoch 40/50, Train Loss: 0.5169, Val Loss: 0.3769
Epoch 41/50, Train Loss: 0.5166, Val Loss: 0.4059
Epoch 42/50, Train Loss: 0.5160, Val Loss: 0.3805
Epoch 43/50, Train Loss: 0.5149, Val Loss: 0.3785
Epoch 44/50, Train Loss: 0.5146, Val Loss: 0.3660
Epoch 45/50, Train Loss: 0.5140, Val Loss: 0.3716
Epoch 46/50, Train Loss: 0.5135, Val Loss: 0.3812
Epoch 47/50, Train Loss: 0.5129, Val Loss: 0.4089
Epoch 48/50, Train Loss: 0.5121, Val Loss: 0.3937
Epoch 49/50, Train Loss: 0.5114, Val Loss: 0.3669
Epoch 50/50, Train Loss: 0.5111, Val Loss: 0.3848
Total training time: 2855.4529s

Confusion Matrix:
[[177422  15997   1550]
 [  7811  33299  12482]
 [   135    665   2339]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.67      0.62      0.64     53592
           2       0.14      0.75      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.76      0.61    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8465
Total evaluation time: 8.2805s
Test Loss: 0.3866
Testing configuration: batch_size=1024, num_epochs=50, num_layers=10, learning_rate=0.001, dropout=0.5, hidden_size=150
Epoch 1/50, Train Loss: 1.0402, Val Loss: 0.6698
Epoch 2/50, Train Loss: 0.8493, Val Loss: 0.6622
Epoch 3/50, Train Loss: 0.8153, Val Loss: 0.6658
Epoch 4/50, Train Loss: 0.8116, Val Loss: 0.6639
Epoch 5/50, Train Loss: 0.8136, Val Loss: 0.6391
Epoch 6/50, Train Loss: 0.8353, Val Loss: 0.5888
Epoch 7/50, Train Loss: 0.7271, Val Loss: 0.5309
Epoch 8/50, Train Loss: 0.6436, Val Loss: 0.4914
Epoch 9/50, Train Loss: 0.6231, Val Loss: 0.4621
Epoch 10/50, Train Loss: 0.6056, Val Loss: 0.4391
Epoch 11/50, Train Loss: 0.5870, Val Loss: 0.4143
Epoch 12/50, Train Loss: 0.5741, Val Loss: 0.4125
Epoch 13/50, Train Loss: 0.5687, Val Loss: 0.4083
Epoch 14/50, Train Loss: 0.5542, Val Loss: 0.3402
Epoch 15/50, Train Loss: 0.5479, Val Loss: 0.4099
Epoch 16/50, Train Loss: 0.5429, Val Loss: 0.3718
Epoch 17/50, Train Loss: 0.5375, Val Loss: 0.3596
Epoch 18/50, Train Loss: 0.5327, Val Loss: 0.3844
Epoch 19/50, Train Loss: 0.5273, Val Loss: 0.3690
Epoch 20/50, Train Loss: 0.5241, Val Loss: 0.3678
Epoch 21/50, Train Loss: 0.5196, Val Loss: 0.3978
Epoch 22/50, Train Loss: 0.5167, Val Loss: 0.3404
Epoch 23/50, Train Loss: 0.5136, Val Loss: 0.4038
Epoch 24/50, Train Loss: 0.5121, Val Loss: 0.4060
Epoch 25/50, Train Loss: 0.5105, Val Loss: 0.3393
Epoch 26/50, Train Loss: 0.5078, Val Loss: 0.3791
Epoch 27/50, Train Loss: 0.5070, Val Loss: 0.3413
Epoch 28/50, Train Loss: 0.5048, Val Loss: 0.3657
Epoch 29/50, Train Loss: 0.5029, Val Loss: 0.3756
Epoch 30/50, Train Loss: 0.5025, Val Loss: 0.3401
Epoch 31/50, Train Loss: 0.5018, Val Loss: 0.3679
Epoch 32/50, Train Loss: 0.5010, Val Loss: 0.3555
Epoch 33/50, Train Loss: 0.4993, Val Loss: 0.3639
Epoch 34/50, Train Loss: 0.4979, Val Loss: 0.3793
Epoch 35/50, Train Loss: 0.4971, Val Loss: 0.3776
Epoch 36/50, Train Loss: 0.4994, Val Loss: 0.3899
Epoch 37/50, Train Loss: 0.4951, Val Loss: 0.3340
Epoch 38/50, Train Loss: 0.4947, Val Loss: 0.3677
Epoch 39/50, Train Loss: 0.4940, Val Loss: 0.4009
Epoch 40/50, Train Loss: 0.4939, Val Loss: 0.3724
Epoch 41/50, Train Loss: 0.4924, Val Loss: 0.4128
Epoch 42/50, Train Loss: 0.4926, Val Loss: 0.3653
Epoch 43/50, Train Loss: 0.4909, Val Loss: 0.3676
Epoch 44/50, Train Loss: 0.4910, Val Loss: 0.3526
Epoch 45/50, Train Loss: 0.4893, Val Loss: 0.3627
Epoch 46/50, Train Loss: 0.4904, Val Loss: 0.3803
Epoch 47/50, Train Loss: 0.4877, Val Loss: 0.4052
Epoch 48/50, Train Loss: 0.4878, Val Loss: 0.4015
Epoch 49/50, Train Loss: 0.4872, Val Loss: 0.3416
Epoch 50/50, Train Loss: 0.4863, Val Loss: 0.3481
Total training time: 4878.1029s

Confusion Matrix:
[[182228  11459   1282]
 [  9149  33130  11313]
 [   161    655   2323]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.73      0.62      0.67     53592
           2       0.16      0.74      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.76      0.62    251700
weighted avg       0.89      0.86      0.88    251700


Global Accuracy: 0.8648
Total evaluation time: 13.0728s
Test Loss: 0.3503
Testing configuration: batch_size=1024, num_epochs=50, num_layers=10, learning_rate=0.0001, dropout=0.5, hidden_size=150
Epoch 1/50, Train Loss: 1.0986, Val Loss: 1.0981
Epoch 2/50, Train Loss: 1.0986, Val Loss: 1.0966
Epoch 3/50, Train Loss: 1.0986, Val Loss: 1.0969
Epoch 4/50, Train Loss: 1.0986, Val Loss: 1.1035
Epoch 5/50, Train Loss: 1.0986, Val Loss: 1.0988
Epoch 6/50, Train Loss: 1.0986, Val Loss: 1.0995
Epoch 7/50, Train Loss: 1.0986, Val Loss: 1.0994
Epoch 8/50, Train Loss: 1.0986, Val Loss: 1.1004
Epoch 9/50, Train Loss: 1.0986, Val Loss: 1.0980
Epoch 10/50, Train Loss: 1.0986, Val Loss: 1.0990
Epoch 11/50, Train Loss: 1.0986, Val Loss: 1.0955
Epoch 12/50, Train Loss: 1.0986, Val Loss: 1.0979
Epoch 13/50, Train Loss: 1.0986, Val Loss: 1.1002
Epoch 14/50, Train Loss: 0.7513, Val Loss: 0.5003
Epoch 15/50, Train Loss: 0.6403, Val Loss: 0.4817
Epoch 16/50, Train Loss: 0.6240, Val Loss: 0.4492
Epoch 17/50, Train Loss: 0.6149, Val Loss: 0.4610
Epoch 18/50, Train Loss: 0.6090, Val Loss: 0.4504
Epoch 19/50, Train Loss: 0.6038, Val Loss: 0.4356
Epoch 20/50, Train Loss: 0.5974, Val Loss: 0.4259
Epoch 21/50, Train Loss: 0.5907, Val Loss: 0.4134
Epoch 22/50, Train Loss: 0.5849, Val Loss: 0.4413
Epoch 23/50, Train Loss: 0.5802, Val Loss: 0.4463
Epoch 24/50, Train Loss: 0.5770, Val Loss: 0.4048
Epoch 25/50, Train Loss: 0.5739, Val Loss: 0.4429
Epoch 26/50, Train Loss: 0.5712, Val Loss: 0.4203
Epoch 27/50, Train Loss: 0.5682, Val Loss: 0.4213
Epoch 28/50, Train Loss: 0.5656, Val Loss: 0.3974
Epoch 29/50, Train Loss: 0.5629, Val Loss: 0.4030
Epoch 30/50, Train Loss: 0.5609, Val Loss: 0.4294
Epoch 31/50, Train Loss: 0.5587, Val Loss: 0.4128
Epoch 32/50, Train Loss: 0.5568, Val Loss: 0.4154
Epoch 33/50, Train Loss: 0.5551, Val Loss: 0.4149
Epoch 34/50, Train Loss: 0.5535, Val Loss: 0.4014
Epoch 35/50, Train Loss: 0.5524, Val Loss: 0.3876
Epoch 36/50, Train Loss: 0.5513, Val Loss: 0.4002
Epoch 37/50, Train Loss: 0.5501, Val Loss: 0.4260
Epoch 38/50, Train Loss: 0.5492, Val Loss: 0.3714
Epoch 39/50, Train Loss: 0.5479, Val Loss: 0.4037
Epoch 40/50, Train Loss: 0.5472, Val Loss: 0.4064
Epoch 41/50, Train Loss: 0.5465, Val Loss: 0.3849
Epoch 42/50, Train Loss: 0.5457, Val Loss: 0.3732
Epoch 43/50, Train Loss: 0.5448, Val Loss: 0.3959
Epoch 44/50, Train Loss: 0.5438, Val Loss: 0.3864
Epoch 45/50, Train Loss: 0.5431, Val Loss: 0.3623
Epoch 46/50, Train Loss: 0.5432, Val Loss: 0.3908
Epoch 47/50, Train Loss: 0.5417, Val Loss: 0.3914
Epoch 48/50, Train Loss: 0.5408, Val Loss: 0.3898
Epoch 49/50, Train Loss: 0.5390, Val Loss: 0.3995
Epoch 50/50, Train Loss: 0.5350, Val Loss: 0.3744
Total training time: 4862.6504s

Confusion Matrix:
[[180825  13330    814]
 [  9101  32135  12356]
 [   149    687   2303]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.70      0.60      0.64     53592
           2       0.15      0.73      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.60      0.75      0.61    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8552
Total evaluation time: 13.0120s
Test Loss: 0.3763
Best configuration: {'batch_size': 1024, 'num_epochs': 50, 'num_layers': 10, 'learning_rate': 0.001, 'dropout': 0.5, 'hidden_size': 150} with accuracy: 0.8648
