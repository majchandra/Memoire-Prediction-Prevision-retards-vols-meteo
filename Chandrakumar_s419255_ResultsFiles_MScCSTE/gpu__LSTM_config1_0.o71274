CUDA_VISIBLE_DEVICES=GPU-0d9695e9-5701-ca6e-d4e6-b2066ff1f2b4
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pandas in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.2.2)
Requirement already satisfied: numpy>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (1.26.4)
Requirement already satisfied: tzdata>=2022.7 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: pytz>=2020.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: imblearn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.0)
Requirement already satisfied: imbalanced-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imblearn) (0.12.3)
Requirement already satisfied: numpy>=1.17.3 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.26.4)
Requirement already satisfied: scikit-learn>=1.0.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.5.0)
Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.5.0)
Requirement already satisfied: scipy>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.13.1)
Requirement already satisfied: joblib>=1.1.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.4.2)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.3.1)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (3.6.0)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.20.5)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.3.1)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.8.4)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2024.6.0)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (1.10.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (4.12.1)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.11.3)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch) (1.2.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: scikit-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: numpy>=1.19.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.26.4)
Requirement already satisfied: scipy>=1.6.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)
Requirement already satisfied: threadpoolctl>=3.1.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (3.5.0)
Requirement already satisfied: joblib>=1.2.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.26.4)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torchdiffeq in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.2.4)
Requirement already satisfied: scipy>=1.4.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (1.13.1)
Requirement already satisfied: torch>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (2.3.1)
Requirement already satisfied: numpy<2.3,>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (4.12.1)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.11.3)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (3.6.0)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2024.6.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (1.10.1)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.20.5)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.8.4)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.2.1)
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
42
cuda
0h
Testing configuration: batch_size=1024, num_epochs=20, num_layers=2, learning_rate=0.001, dropout=0.5, hidden_size=50
Epoch 1/20, Train Loss: 0.6452, Val Loss: 0.4165
Epoch 2/20, Train Loss: 0.5767, Val Loss: 0.5047
Epoch 3/20, Train Loss: 0.5552, Val Loss: 0.4087
Epoch 4/20, Train Loss: 0.5447, Val Loss: 0.3854
Epoch 5/20, Train Loss: 0.5378, Val Loss: 0.3794
Epoch 6/20, Train Loss: 0.5327, Val Loss: 0.3998
Epoch 7/20, Train Loss: 0.5288, Val Loss: 0.3453
Epoch 8/20, Train Loss: 0.5251, Val Loss: 0.3950
Epoch 9/20, Train Loss: 0.5222, Val Loss: 0.3762
Epoch 10/20, Train Loss: 0.5196, Val Loss: 0.3772
Epoch 11/20, Train Loss: 0.5170, Val Loss: 0.3840
Epoch 12/20, Train Loss: 0.5149, Val Loss: 0.3982
Epoch 13/20, Train Loss: 0.5135, Val Loss: 0.3883
Epoch 14/20, Train Loss: 0.5107, Val Loss: 0.3913
Epoch 15/20, Train Loss: 0.5086, Val Loss: 0.3552
Epoch 16/20, Train Loss: 0.5071, Val Loss: 0.3970
Epoch 17/20, Train Loss: 0.5058, Val Loss: 0.3705
Epoch 18/20, Train Loss: 0.5042, Val Loss: 0.4235
Epoch 19/20, Train Loss: 0.5034, Val Loss: 0.3838
Epoch 20/20, Train Loss: 0.5024, Val Loss: 0.3875
Total training time: 485.1443s

Confusion Matrix:
[[175209  18151   1609]
 [  7220  36551   9821]
 [   125    812   2202]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.90      0.93    194969
           1       0.66      0.68      0.67     53592
           2       0.16      0.70      0.26      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.76      0.62    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8501
Total evaluation time: 4.1397s
Test Loss: 0.3893
Testing configuration: batch_size=1024, num_epochs=20, num_layers=2, learning_rate=0.001, dropout=0.5, hidden_size=100
Epoch 1/20, Train Loss: 0.6274, Val Loss: 0.4024
Epoch 2/20, Train Loss: 0.5587, Val Loss: 0.3761
Epoch 3/20, Train Loss: 0.5372, Val Loss: 0.3702
Epoch 4/20, Train Loss: 0.5267, Val Loss: 0.4051
Epoch 5/20, Train Loss: 0.5192, Val Loss: 0.3602
Epoch 6/20, Train Loss: 0.5137, Val Loss: 0.3458
Epoch 7/20, Train Loss: 0.5091, Val Loss: 0.3632
Epoch 8/20, Train Loss: 0.5046, Val Loss: 0.4115
Epoch 9/20, Train Loss: 0.5008, Val Loss: 0.3421
Epoch 10/20, Train Loss: 0.4964, Val Loss: 0.3856
Epoch 11/20, Train Loss: 0.4939, Val Loss: 0.3515
Epoch 12/20, Train Loss: 0.4916, Val Loss: 0.3633
Epoch 13/20, Train Loss: 0.4899, Val Loss: 0.3434
Epoch 14/20, Train Loss: 0.4882, Val Loss: 0.4146
Epoch 15/20, Train Loss: 0.4864, Val Loss: 0.3604
Epoch 16/20, Train Loss: 0.4851, Val Loss: 0.3572
Epoch 17/20, Train Loss: 0.4838, Val Loss: 0.3933
Epoch 18/20, Train Loss: 0.4823, Val Loss: 0.3537
Epoch 19/20, Train Loss: 0.4809, Val Loss: 0.3767
Epoch 20/20, Train Loss: 0.4796, Val Loss: 0.3805
Total training time: 587.7166s

Confusion Matrix:
[[177755  15350   1864]
 [  7730  33016  12846]
 [   133    570   2436]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.67      0.62      0.64     53592
           2       0.14      0.78      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.77      0.61    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8471
Total evaluation time: 5.0976s
Test Loss: 0.3822
Testing configuration: batch_size=1024, num_epochs=20, num_layers=2, learning_rate=0.0001, dropout=0.5, hidden_size=50
Epoch 1/20, Train Loss: 0.8601, Val Loss: 0.5483
Epoch 2/20, Train Loss: 0.6665, Val Loss: 0.4950
Epoch 3/20, Train Loss: 0.6339, Val Loss: 0.4819
Epoch 4/20, Train Loss: 0.6208, Val Loss: 0.4678
Epoch 5/20, Train Loss: 0.6134, Val Loss: 0.4665
Epoch 6/20, Train Loss: 0.6070, Val Loss: 0.4562
Epoch 7/20, Train Loss: 0.6009, Val Loss: 0.4469
Epoch 8/20, Train Loss: 0.5954, Val Loss: 0.4507
Epoch 9/20, Train Loss: 0.5903, Val Loss: 0.4372
Epoch 10/20, Train Loss: 0.5860, Val Loss: 0.4310
Epoch 11/20, Train Loss: 0.5812, Val Loss: 0.4153
Epoch 12/20, Train Loss: 0.5768, Val Loss: 0.4246
Epoch 13/20, Train Loss: 0.5729, Val Loss: 0.4137
Epoch 14/20, Train Loss: 0.5688, Val Loss: 0.4049
Epoch 15/20, Train Loss: 0.5651, Val Loss: 0.4110
Epoch 16/20, Train Loss: 0.5622, Val Loss: 0.3872
Epoch 17/20, Train Loss: 0.5595, Val Loss: 0.4000
Epoch 18/20, Train Loss: 0.5571, Val Loss: 0.4175
Epoch 19/20, Train Loss: 0.5553, Val Loss: 0.3971
Epoch 20/20, Train Loss: 0.5537, Val Loss: 0.3903
Total training time: 483.2678s

Confusion Matrix:
[[180194  13615   1160]
 [  8839  31911  12842]
 [   159    797   2183]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.69      0.60      0.64     53592
           2       0.13      0.70      0.23      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.74      0.60    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8514
Total evaluation time: 4.3399s
Test Loss: 0.3914
Testing configuration: batch_size=1024, num_epochs=20, num_layers=2, learning_rate=0.0001, dropout=0.5, hidden_size=100
Epoch 1/20, Train Loss: 0.7972, Val Loss: 0.5436
Epoch 2/20, Train Loss: 0.6387, Val Loss: 0.4671
Epoch 3/20, Train Loss: 0.6156, Val Loss: 0.4741
Epoch 4/20, Train Loss: 0.6059, Val Loss: 0.4538
Epoch 5/20, Train Loss: 0.5977, Val Loss: 0.4513
Epoch 6/20, Train Loss: 0.5906, Val Loss: 0.4507
Epoch 7/20, Train Loss: 0.5840, Val Loss: 0.4415
Epoch 8/20, Train Loss: 0.5780, Val Loss: 0.4379
Epoch 9/20, Train Loss: 0.5721, Val Loss: 0.4375
Epoch 10/20, Train Loss: 0.5663, Val Loss: 0.4050
Epoch 11/20, Train Loss: 0.5608, Val Loss: 0.4259
Epoch 12/20, Train Loss: 0.5558, Val Loss: 0.3985
Epoch 13/20, Train Loss: 0.5517, Val Loss: 0.3849
Epoch 14/20, Train Loss: 0.5483, Val Loss: 0.3889
Epoch 15/20, Train Loss: 0.5453, Val Loss: 0.4053
Epoch 16/20, Train Loss: 0.5424, Val Loss: 0.3869
Epoch 17/20, Train Loss: 0.5400, Val Loss: 0.3899
Epoch 18/20, Train Loss: 0.5384, Val Loss: 0.3875
Epoch 19/20, Train Loss: 0.5366, Val Loss: 0.3799
Epoch 20/20, Train Loss: 0.5355, Val Loss: 0.3810
Total training time: 586.2212s

Confusion Matrix:
[[180419  13353   1197]
 [  8857  32382  12353]
 [   154    736   2249]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.70      0.60      0.65     53592
           2       0.14      0.72      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.75      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8544
Total evaluation time: 5.0555s
Test Loss: 0.3825
Testing configuration: batch_size=1024, num_epochs=20, num_layers=5, learning_rate=0.001, dropout=0.5, hidden_size=50
Epoch 1/20, Train Loss: 0.6672, Val Loss: 0.4698
Epoch 2/20, Train Loss: 0.6006, Val Loss: 0.4556
Epoch 3/20, Train Loss: 0.5697, Val Loss: 0.4271
Epoch 4/20, Train Loss: 0.5549, Val Loss: 0.4024
Epoch 5/20, Train Loss: 0.5467, Val Loss: 0.3869
Epoch 6/20, Train Loss: 0.5426, Val Loss: 0.4000
Epoch 7/20, Train Loss: 0.5391, Val Loss: 0.3720
Epoch 8/20, Train Loss: 0.5366, Val Loss: 0.3783
Epoch 9/20, Train Loss: 0.5345, Val Loss: 0.3972
Epoch 10/20, Train Loss: 0.5323, Val Loss: 0.4018
Epoch 11/20, Train Loss: 0.5308, Val Loss: 0.3442
Epoch 12/20, Train Loss: 0.5293, Val Loss: 0.3853
Epoch 13/20, Train Loss: 0.5281, Val Loss: 0.3997
Epoch 14/20, Train Loss: 0.5268, Val Loss: 0.4138
Epoch 15/20, Train Loss: 0.5256, Val Loss: 0.3856
Epoch 16/20, Train Loss: 0.5251, Val Loss: 0.3731
Epoch 17/20, Train Loss: 0.5239, Val Loss: 0.3733
Epoch 18/20, Train Loss: 0.5232, Val Loss: 0.3410
Epoch 19/20, Train Loss: 0.5226, Val Loss: 0.3751
Epoch 20/20, Train Loss: 0.5215, Val Loss: 0.3632
Total training time: 551.6242s

Confusion Matrix:
[[182401  11255   1313]
 [  9385  30956  13251]
 [   165    587   2387]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.94      0.94    194969
           1       0.72      0.58      0.64     53592
           2       0.14      0.76      0.24      3139

    accuracy                           0.86    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8571
Total evaluation time: 4.6340s
Test Loss: 0.3653
Testing configuration: batch_size=1024, num_epochs=20, num_layers=5, learning_rate=0.001, dropout=0.5, hidden_size=100
Epoch 1/20, Train Loss: 0.6462, Val Loss: 0.4451
Epoch 2/20, Train Loss: 0.5752, Val Loss: 0.4352
Epoch 3/20, Train Loss: 0.5511, Val Loss: 0.3947
Epoch 4/20, Train Loss: 0.5396, Val Loss: 0.3524
Epoch 5/20, Train Loss: 0.5331, Val Loss: 0.3349
Epoch 6/20, Train Loss: 0.5280, Val Loss: 0.3847
Epoch 7/20, Train Loss: 0.5240, Val Loss: 0.3713
Epoch 8/20, Train Loss: 0.5209, Val Loss: 0.3610
Epoch 9/20, Train Loss: 0.5182, Val Loss: 0.3620
Epoch 10/20, Train Loss: 0.5155, Val Loss: 0.3798
Epoch 11/20, Train Loss: 0.5131, Val Loss: 0.3982
Epoch 12/20, Train Loss: 0.5106, Val Loss: 0.3627
Epoch 13/20, Train Loss: 0.5078, Val Loss: 0.3811
Epoch 14/20, Train Loss: 0.5056, Val Loss: 0.3481
Epoch 15/20, Train Loss: 0.5043, Val Loss: 0.3547
Epoch 16/20, Train Loss: 0.5032, Val Loss: 0.3532
Epoch 17/20, Train Loss: 0.5011, Val Loss: 0.3580
Epoch 18/20, Train Loss: 0.5005, Val Loss: 0.3655
Epoch 19/20, Train Loss: 0.4995, Val Loss: 0.3659
Epoch 20/20, Train Loss: 0.4978, Val Loss: 0.3523
Total training time: 678.2476s

Confusion Matrix:
[[182307  11507   1155]
 [  9292  32396  11904]
 [   161    614   2364]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.94      0.94    194969
           1       0.73      0.60      0.66     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.76      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8624
Total evaluation time: 5.2811s
Test Loss: 0.3541
Testing configuration: batch_size=1024, num_epochs=20, num_layers=5, learning_rate=0.0001, dropout=0.5, hidden_size=50
Epoch 1/20, Train Loss: 0.8491, Val Loss: 0.5254
Epoch 2/20, Train Loss: 0.6640, Val Loss: 0.4994
Epoch 3/20, Train Loss: 0.6472, Val Loss: 0.4753
Epoch 4/20, Train Loss: 0.6375, Val Loss: 0.4657
Epoch 5/20, Train Loss: 0.6300, Val Loss: 0.4574
Epoch 6/20, Train Loss: 0.6244, Val Loss: 0.4649
Epoch 7/20, Train Loss: 0.6206, Val Loss: 0.4634
Epoch 8/20, Train Loss: 0.6171, Val Loss: 0.4497
Epoch 9/20, Train Loss: 0.6138, Val Loss: 0.4496
Epoch 10/20, Train Loss: 0.6104, Val Loss: 0.4463
Epoch 11/20, Train Loss: 0.6065, Val Loss: 0.4427
Epoch 12/20, Train Loss: 0.6013, Val Loss: 0.4402
Epoch 13/20, Train Loss: 0.5967, Val Loss: 0.4230
Epoch 14/20, Train Loss: 0.5908, Val Loss: 0.4233
Epoch 15/20, Train Loss: 0.5855, Val Loss: 0.3971
Epoch 16/20, Train Loss: 0.5821, Val Loss: 0.4042
Epoch 17/20, Train Loss: 0.5790, Val Loss: 0.4404
Epoch 18/20, Train Loss: 0.5761, Val Loss: 0.4040
Epoch 19/20, Train Loss: 0.5732, Val Loss: 0.3845
Epoch 20/20, Train Loss: 0.5706, Val Loss: 0.4226
Total training time: 552.9376s

Confusion Matrix:
[[175570  18623    776]
 [  7625  32435  13532]
 [   131    768   2240]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.90      0.93    194969
           1       0.63      0.61      0.62     53592
           2       0.14      0.71      0.23      3139

    accuracy                           0.84    251700
   macro avg       0.57      0.74      0.59    251700
weighted avg       0.88      0.84      0.85    251700


Global Accuracy: 0.8353
Total evaluation time: 4.6528s
Test Loss: 0.4238
Testing configuration: batch_size=1024, num_epochs=20, num_layers=5, learning_rate=0.0001, dropout=0.5, hidden_size=100
Epoch 1/20, Train Loss: 0.7772, Val Loss: 0.5051
Epoch 2/20, Train Loss: 0.6453, Val Loss: 0.4830
Epoch 3/20, Train Loss: 0.6297, Val Loss: 0.4703
Epoch 4/20, Train Loss: 0.6194, Val Loss: 0.4486
Epoch 5/20, Train Loss: 0.6134, Val Loss: 0.4612
Epoch 6/20, Train Loss: 0.6090, Val Loss: 0.4283
Epoch 7/20, Train Loss: 0.6034, Val Loss: 0.4419
Epoch 8/20, Train Loss: 0.5954, Val Loss: 0.4528
Epoch 9/20, Train Loss: 0.5860, Val Loss: 0.4254
Epoch 10/20, Train Loss: 0.5779, Val Loss: 0.4237
Epoch 11/20, Train Loss: 0.5720, Val Loss: 0.4175
Epoch 12/20, Train Loss: 0.5676, Val Loss: 0.4138
Epoch 13/20, Train Loss: 0.5645, Val Loss: 0.3927
Epoch 14/20, Train Loss: 0.5610, Val Loss: 0.3776
Epoch 15/20, Train Loss: 0.5577, Val Loss: 0.3777
Epoch 16/20, Train Loss: 0.5553, Val Loss: 0.3903
Epoch 17/20, Train Loss: 0.5525, Val Loss: 0.3759
Epoch 18/20, Train Loss: 0.5501, Val Loss: 0.3880
Epoch 19/20, Train Loss: 0.5479, Val Loss: 0.3949
Epoch 20/20, Train Loss: 0.5458, Val Loss: 0.3861
Total training time: 676.1395s

Confusion Matrix:
[[179693  13969   1307]
 [  8571  32646  12375]
 [   154    741   2244]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.69      0.61      0.65     53592
           2       0.14      0.71      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.75      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8525
Total evaluation time: 5.3416s
Test Loss: 0.3877
Testing configuration: batch_size=1024, num_epochs=20, num_layers=10, learning_rate=0.001, dropout=0.5, hidden_size=50
Epoch 1/20, Train Loss: 0.9176, Val Loss: 0.6641
Epoch 2/20, Train Loss: 0.8106, Val Loss: 0.6591
Epoch 3/20, Train Loss: 0.8108, Val Loss: 0.6863
Epoch 4/20, Train Loss: 0.8183, Val Loss: 0.6599
Epoch 5/20, Train Loss: 0.8103, Val Loss: 0.6561
Epoch 6/20, Train Loss: 0.8130, Val Loss: 0.6560
Epoch 7/20, Train Loss: 0.8101, Val Loss: 0.6675
Epoch 8/20, Train Loss: 0.8101, Val Loss: 0.6561
Epoch 9/20, Train Loss: 0.8087, Val Loss: 0.6159
Epoch 10/20, Train Loss: 0.7553, Val Loss: 0.5492
Epoch 11/20, Train Loss: 0.7272, Val Loss: 0.5708
Epoch 12/20, Train Loss: 0.7215, Val Loss: 0.5655
Epoch 13/20, Train Loss: 0.7181, Val Loss: 0.5450
Epoch 14/20, Train Loss: 0.7153, Val Loss: 0.5234
Epoch 15/20, Train Loss: 0.7132, Val Loss: 0.5555
Epoch 16/20, Train Loss: 0.7112, Val Loss: 0.5644
Epoch 17/20, Train Loss: 0.7086, Val Loss: 0.5260
Epoch 18/20, Train Loss: 0.7074, Val Loss: 0.5601
Epoch 19/20, Train Loss: 0.7051, Val Loss: 0.5237
Epoch 20/20, Train Loss: 0.7033, Val Loss: 0.5167
Total training time: 600.9186s

Confusion Matrix:
[[175383   6523  13063]
 [  8031   7552  38009]
 [   126    158   2855]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.90      0.93    194969
           1       0.53      0.14      0.22     53592
           2       0.05      0.91      0.10      3139

    accuracy                           0.74    251700
   macro avg       0.51      0.65      0.42    251700
weighted avg       0.85      0.74      0.77    251700


Global Accuracy: 0.7381
Total evaluation time: 5.0459s
Test Loss: 0.5198
Testing configuration: batch_size=1024, num_epochs=20, num_layers=10, learning_rate=0.001, dropout=0.5, hidden_size=100
Epoch 1/20, Train Loss: 1.0931, Val Loss: 0.6716
Epoch 2/20, Train Loss: 0.8107, Val Loss: 0.6501
Epoch 3/20, Train Loss: 0.8139, Val Loss: 0.6482
Epoch 4/20, Train Loss: 0.8105, Val Loss: 0.6586
Epoch 5/20, Train Loss: 0.8105, Val Loss: 0.6570
Epoch 6/20, Train Loss: 0.8111, Val Loss: 0.6523
Epoch 7/20, Train Loss: 0.8105, Val Loss: 0.6538
Epoch 8/20, Train Loss: 0.8115, Val Loss: 0.6561
Epoch 9/20, Train Loss: 0.8104, Val Loss: 0.6499
Epoch 10/20, Train Loss: 0.8115, Val Loss: 0.6456
Epoch 11/20, Train Loss: 0.8119, Val Loss: 0.6598
Epoch 12/20, Train Loss: 0.8106, Val Loss: 0.6424
Epoch 13/20, Train Loss: 0.8117, Val Loss: 0.6554
Epoch 14/20, Train Loss: 0.8107, Val Loss: 0.6500
Epoch 15/20, Train Loss: 0.8036, Val Loss: 0.5300
Epoch 16/20, Train Loss: 0.7277, Val Loss: 0.5394
Epoch 17/20, Train Loss: 0.6754, Val Loss: 0.4953
Epoch 18/20, Train Loss: 0.6342, Val Loss: 0.4329
Epoch 19/20, Train Loss: 0.6155, Val Loss: 0.4214
Epoch 20/20, Train Loss: 0.6004, Val Loss: 0.3918
Total training time: 976.4791s

Confusion Matrix:
[[181412  13229    328]
 [  9480  31612  12500]
 [   162    867   2110]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.69      0.59      0.64     53592
           2       0.14      0.67      0.23      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.73      0.60    251700
weighted avg       0.88      0.85      0.87    251700


Global Accuracy: 0.8547
Total evaluation time: 6.5169s
Test Loss: 0.3934
Testing configuration: batch_size=1024, num_epochs=20, num_layers=10, learning_rate=0.0001, dropout=0.5, hidden_size=50
Epoch 1/20, Train Loss: 1.0987, Val Loss: 1.0979
Epoch 2/20, Train Loss: 1.0986, Val Loss: 1.1006
Epoch 3/20, Train Loss: 1.0986, Val Loss: 1.0982
Epoch 4/20, Train Loss: 1.0986, Val Loss: 1.0974
Epoch 5/20, Train Loss: 1.0986, Val Loss: 1.0968
Epoch 6/20, Train Loss: 1.0986, Val Loss: 1.1008
Epoch 7/20, Train Loss: 1.0986, Val Loss: 1.0989
Epoch 8/20, Train Loss: 1.0986, Val Loss: 1.0993
Epoch 9/20, Train Loss: 1.0986, Val Loss: 1.0975
Epoch 10/20, Train Loss: 1.0986, Val Loss: 1.0999
Epoch 11/20, Train Loss: 1.0986, Val Loss: 1.1007
Epoch 12/20, Train Loss: 1.0986, Val Loss: 1.1002
Epoch 13/20, Train Loss: 1.0986, Val Loss: 1.0998
Epoch 14/20, Train Loss: 1.0986, Val Loss: 1.0970
Epoch 15/20, Train Loss: 1.0986, Val Loss: 1.0984
Epoch 16/20, Train Loss: 1.0471, Val Loss: 0.6047
Epoch 17/20, Train Loss: 0.7525, Val Loss: 0.5568
Epoch 18/20, Train Loss: 0.7300, Val Loss: 0.5551
Epoch 19/20, Train Loss: 0.6813, Val Loss: 0.4992
Epoch 20/20, Train Loss: 0.6607, Val Loss: 0.4708
Total training time: 597.5749s

Confusion Matrix:
[[174831  19484    654]
 [  8662  30110  14820]
 [   141    800   2198]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.90      0.92    194969
           1       0.60      0.56      0.58     53592
           2       0.12      0.70      0.21      3139

    accuracy                           0.82    251700
   macro avg       0.56      0.72      0.57    251700
weighted avg       0.87      0.82      0.84    251700


Global Accuracy: 0.8230
Total evaluation time: 4.9964s
Test Loss: 0.4725
Testing configuration: batch_size=1024, num_epochs=20, num_layers=10, learning_rate=0.0001, dropout=0.5, hidden_size=100
Epoch 1/20, Train Loss: 1.0988, Val Loss: 1.0954
Epoch 2/20, Train Loss: 0.9067, Val Loss: 0.5570
Epoch 3/20, Train Loss: 0.6875, Val Loss: 0.4917
Epoch 4/20, Train Loss: 0.6436, Val Loss: 0.4779
Epoch 5/20, Train Loss: 0.6303, Val Loss: 0.4462
Epoch 6/20, Train Loss: 0.6227, Val Loss: 0.4775
Epoch 7/20, Train Loss: 0.6170, Val Loss: 0.4442
Epoch 8/20, Train Loss: 0.6123, Val Loss: 0.4598
Epoch 9/20, Train Loss: 0.6072, Val Loss: 0.4449
Epoch 10/20, Train Loss: 0.6018, Val Loss: 0.4223
Epoch 11/20, Train Loss: 0.5959, Val Loss: 0.4495
Epoch 12/20, Train Loss: 0.5904, Val Loss: 0.4411
Epoch 13/20, Train Loss: 0.5857, Val Loss: 0.4406
Epoch 14/20, Train Loss: 0.5822, Val Loss: 0.4109
Epoch 15/20, Train Loss: 0.5794, Val Loss: 0.4245
Epoch 16/20, Train Loss: 0.5769, Val Loss: 0.4145
Epoch 17/20, Train Loss: 0.5750, Val Loss: 0.3835
Epoch 18/20, Train Loss: 0.5726, Val Loss: 0.4264
Epoch 19/20, Train Loss: 0.5710, Val Loss: 0.3886
Epoch 20/20, Train Loss: 0.5691, Val Loss: 0.4228
Total training time: 975.4547s

Confusion Matrix:
[[177179  17510    280]
 [  7983  32710  12899]
 [   132    830   2177]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.64      0.61      0.63     53592
           2       0.14      0.69      0.24      3139

    accuracy                           0.84    251700
   macro avg       0.58      0.74      0.60    251700
weighted avg       0.88      0.84      0.86    251700


Global Accuracy: 0.8425
Total evaluation time: 6.5395s
Test Loss: 0.4239
Testing configuration: batch_size=1024, num_epochs=50, num_layers=2, learning_rate=0.001, dropout=0.5, hidden_size=50
Epoch 1/50, Train Loss: 0.6468, Val Loss: 0.4691
Epoch 2/50, Train Loss: 0.5759, Val Loss: 0.3850
Epoch 3/50, Train Loss: 0.5525, Val Loss: 0.3980
Epoch 4/50, Train Loss: 0.5410, Val Loss: 0.3540
Epoch 5/50, Train Loss: 0.5346, Val Loss: 0.3425
Epoch 6/50, Train Loss: 0.5294, Val Loss: 0.3718
Epoch 7/50, Train Loss: 0.5256, Val Loss: 0.4049
Epoch 8/50, Train Loss: 0.5223, Val Loss: 0.4204
Epoch 9/50, Train Loss: 0.5190, Val Loss: 0.3462
Epoch 10/50, Train Loss: 0.5164, Val Loss: 0.3944
Epoch 11/50, Train Loss: 0.5137, Val Loss: 0.3907
Epoch 12/50, Train Loss: 0.5114, Val Loss: 0.3902
Epoch 13/50, Train Loss: 0.5099, Val Loss: 0.3813
Epoch 14/50, Train Loss: 0.5083, Val Loss: 0.4017
Epoch 15/50, Train Loss: 0.5065, Val Loss: 0.4036
Epoch 16/50, Train Loss: 0.5054, Val Loss: 0.4089
Epoch 17/50, Train Loss: 0.5042, Val Loss: 0.3914
Epoch 18/50, Train Loss: 0.5036, Val Loss: 0.3730
Epoch 19/50, Train Loss: 0.5025, Val Loss: 0.4095
Epoch 20/50, Train Loss: 0.5012, Val Loss: 0.3431
Epoch 21/50, Train Loss: 0.5009, Val Loss: 0.3807
Epoch 22/50, Train Loss: 0.5002, Val Loss: 0.4179
Epoch 23/50, Train Loss: 0.4998, Val Loss: 0.4105
Epoch 24/50, Train Loss: 0.4985, Val Loss: 0.3871
Epoch 25/50, Train Loss: 0.4981, Val Loss: 0.3727
Epoch 26/50, Train Loss: 0.4972, Val Loss: 0.3723
Epoch 27/50, Train Loss: 0.4967, Val Loss: 0.3750
Epoch 28/50, Train Loss: 0.4962, Val Loss: 0.3726
Epoch 29/50, Train Loss: 0.4958, Val Loss: 0.3633
Epoch 30/50, Train Loss: 0.4955, Val Loss: 0.3930
Epoch 31/50, Train Loss: 0.4946, Val Loss: 0.3697
Epoch 32/50, Train Loss: 0.4940, Val Loss: 0.4259
Epoch 33/50, Train Loss: 0.4938, Val Loss: 0.3884
Epoch 34/50, Train Loss: 0.4934, Val Loss: 0.4080
Epoch 35/50, Train Loss: 0.4931, Val Loss: 0.3956
Epoch 36/50, Train Loss: 0.4924, Val Loss: 0.3712
Epoch 37/50, Train Loss: 0.4918, Val Loss: 0.3537
Epoch 38/50, Train Loss: 0.4918, Val Loss: 0.3694
Epoch 39/50, Train Loss: 0.4912, Val Loss: 0.3684
Epoch 40/50, Train Loss: 0.4908, Val Loss: 0.3677
Epoch 41/50, Train Loss: 0.4903, Val Loss: 0.3778
Epoch 42/50, Train Loss: 0.4901, Val Loss: 0.4277
Epoch 43/50, Train Loss: 0.4897, Val Loss: 0.3503
Epoch 44/50, Train Loss: 0.4893, Val Loss: 0.3805
Epoch 45/50, Train Loss: 0.4890, Val Loss: 0.4014
Epoch 46/50, Train Loss: 0.4889, Val Loss: 0.3897
Epoch 47/50, Train Loss: 0.4883, Val Loss: 0.4257
Epoch 48/50, Train Loss: 0.4886, Val Loss: 0.3772
Epoch 49/50, Train Loss: 0.4878, Val Loss: 0.3641
Epoch 50/50, Train Loss: 0.4874, Val Loss: 0.3860
Total training time: 1192.2433s

Confusion Matrix:
[[173650  18995   2324]
 [  6977  37222   9393]
 [   125    809   2205]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.89      0.92    194969
           1       0.65      0.69      0.67     53592
           2       0.16      0.70      0.26      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.76      0.62    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8466
Total evaluation time: 4.0971s
Test Loss: 0.3876
Testing configuration: batch_size=1024, num_epochs=50, num_layers=2, learning_rate=0.001, dropout=0.5, hidden_size=100
Epoch 1/50, Train Loss: 0.6261, Val Loss: 0.4302
Epoch 2/50, Train Loss: 0.5588, Val Loss: 0.4430
Epoch 3/50, Train Loss: 0.5390, Val Loss: 0.3535
Epoch 4/50, Train Loss: 0.5299, Val Loss: 0.3943
Epoch 5/50, Train Loss: 0.5215, Val Loss: 0.3891
Epoch 6/50, Train Loss: 0.5149, Val Loss: 0.3750
Epoch 7/50, Train Loss: 0.5104, Val Loss: 0.3708
Epoch 8/50, Train Loss: 0.5057, Val Loss: 0.3520
Epoch 9/50, Train Loss: 0.5011, Val Loss: 0.3789
Epoch 10/50, Train Loss: 0.4975, Val Loss: 0.3894
Epoch 11/50, Train Loss: 0.4950, Val Loss: 0.4202
Epoch 12/50, Train Loss: 0.4925, Val Loss: 0.3389
Epoch 13/50, Train Loss: 0.4909, Val Loss: 0.3868
Epoch 14/50, Train Loss: 0.4889, Val Loss: 0.3936
Epoch 15/50, Train Loss: 0.4875, Val Loss: 0.3379
Epoch 16/50, Train Loss: 0.4859, Val Loss: 0.4011
Epoch 17/50, Train Loss: 0.4851, Val Loss: 0.3597
Epoch 18/50, Train Loss: 0.4835, Val Loss: 0.3620
Epoch 19/50, Train Loss: 0.4824, Val Loss: 0.4031
Epoch 20/50, Train Loss: 0.4813, Val Loss: 0.3748
Epoch 21/50, Train Loss: 0.4798, Val Loss: 0.3855
Epoch 22/50, Train Loss: 0.4787, Val Loss: 0.3809
Epoch 23/50, Train Loss: 0.4778, Val Loss: 0.3693
Epoch 24/50, Train Loss: 0.4768, Val Loss: 0.3844
Epoch 25/50, Train Loss: 0.4760, Val Loss: 0.3974
Epoch 26/50, Train Loss: 0.4751, Val Loss: 0.3743
Epoch 27/50, Train Loss: 0.4740, Val Loss: 0.3596
Epoch 28/50, Train Loss: 0.4730, Val Loss: 0.3835
Epoch 29/50, Train Loss: 0.4719, Val Loss: 0.3609
Epoch 30/50, Train Loss: 0.4716, Val Loss: 0.3819
Epoch 31/50, Train Loss: 0.4704, Val Loss: 0.3736
Epoch 32/50, Train Loss: 0.4696, Val Loss: 0.3738
Epoch 33/50, Train Loss: 0.4690, Val Loss: 0.3684
Epoch 34/50, Train Loss: 0.4676, Val Loss: 0.3959
Epoch 35/50, Train Loss: 0.4672, Val Loss: 0.3777
Epoch 36/50, Train Loss: 0.4667, Val Loss: 0.3577
Epoch 37/50, Train Loss: 0.4657, Val Loss: 0.3505
Epoch 38/50, Train Loss: 0.4648, Val Loss: 0.3875
Epoch 39/50, Train Loss: 0.4643, Val Loss: 0.3552
Epoch 40/50, Train Loss: 0.4634, Val Loss: 0.3670
Epoch 41/50, Train Loss: 0.4632, Val Loss: 0.3647
Epoch 42/50, Train Loss: 0.4624, Val Loss: 0.3461
Epoch 43/50, Train Loss: 0.4617, Val Loss: 0.4101
Epoch 44/50, Train Loss: 0.4615, Val Loss: 0.3466
Epoch 45/50, Train Loss: 0.4605, Val Loss: 0.3759
Epoch 46/50, Train Loss: 0.4600, Val Loss: 0.3912
Epoch 47/50, Train Loss: 0.4594, Val Loss: 0.3950
Epoch 48/50, Train Loss: 0.4587, Val Loss: 0.3570
Epoch 49/50, Train Loss: 0.4584, Val Loss: 0.3904
Epoch 50/50, Train Loss: 0.4575, Val Loss: 0.3881
Total training time: 1448.4399s

Confusion Matrix:
[[174505  17506   2958]
 [  6985  35675  10932]
 [   105    680   2354]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.90      0.93    194969
           1       0.66      0.67      0.66     53592
           2       0.14      0.75      0.24      3139

    accuracy                           0.84    251700
   macro avg       0.59      0.77      0.61    251700
weighted avg       0.89      0.84      0.86    251700


Global Accuracy: 0.8444
Total evaluation time: 5.0369s
Test Loss: 0.3892
Testing configuration: batch_size=1024, num_epochs=50, num_layers=2, learning_rate=0.0001, dropout=0.5, hidden_size=50
Epoch 1/50, Train Loss: 0.8574, Val Loss: 0.5567
Epoch 2/50, Train Loss: 0.6654, Val Loss: 0.4910
Epoch 3/50, Train Loss: 0.6308, Val Loss: 0.4782
Epoch 4/50, Train Loss: 0.6186, Val Loss: 0.4586
Epoch 5/50, Train Loss: 0.6104, Val Loss: 0.4656
Epoch 6/50, Train Loss: 0.6035, Val Loss: 0.4483
Epoch 7/50, Train Loss: 0.5976, Val Loss: 0.4443
Epoch 8/50, Train Loss: 0.5922, Val Loss: 0.4315
Epoch 9/50, Train Loss: 0.5870, Val Loss: 0.4302
Epoch 10/50, Train Loss: 0.5821, Val Loss: 0.4254
Epoch 11/50, Train Loss: 0.5774, Val Loss: 0.4243
Epoch 12/50, Train Loss: 0.5729, Val Loss: 0.4108
Epoch 13/50, Train Loss: 0.5686, Val Loss: 0.3993
Epoch 14/50, Train Loss: 0.5648, Val Loss: 0.4046
Epoch 15/50, Train Loss: 0.5615, Val Loss: 0.4109
Epoch 16/50, Train Loss: 0.5585, Val Loss: 0.3991
Epoch 17/50, Train Loss: 0.5560, Val Loss: 0.3930
Epoch 18/50, Train Loss: 0.5540, Val Loss: 0.3943
Epoch 19/50, Train Loss: 0.5523, Val Loss: 0.3970
Epoch 20/50, Train Loss: 0.5505, Val Loss: 0.3902
Epoch 21/50, Train Loss: 0.5490, Val Loss: 0.3951
Epoch 22/50, Train Loss: 0.5474, Val Loss: 0.3949
Epoch 23/50, Train Loss: 0.5456, Val Loss: 0.3852
Epoch 24/50, Train Loss: 0.5442, Val Loss: 0.3768
Epoch 25/50, Train Loss: 0.5435, Val Loss: 0.3721
Epoch 26/50, Train Loss: 0.5425, Val Loss: 0.3889
Epoch 27/50, Train Loss: 0.5412, Val Loss: 0.4013
Epoch 28/50, Train Loss: 0.5407, Val Loss: 0.3904
Epoch 29/50, Train Loss: 0.5398, Val Loss: 0.4031
Epoch 30/50, Train Loss: 0.5390, Val Loss: 0.3988
Epoch 31/50, Train Loss: 0.5381, Val Loss: 0.3800
Epoch 32/50, Train Loss: 0.5374, Val Loss: 0.3828
Epoch 33/50, Train Loss: 0.5367, Val Loss: 0.3879
Epoch 34/50, Train Loss: 0.5359, Val Loss: 0.3999
Epoch 35/50, Train Loss: 0.5353, Val Loss: 0.3905
Epoch 36/50, Train Loss: 0.5349, Val Loss: 0.3894
Epoch 37/50, Train Loss: 0.5341, Val Loss: 0.3911
Epoch 38/50, Train Loss: 0.5338, Val Loss: 0.3844
Epoch 39/50, Train Loss: 0.5330, Val Loss: 0.4011
Epoch 40/50, Train Loss: 0.5321, Val Loss: 0.3755
Epoch 41/50, Train Loss: 0.5319, Val Loss: 0.3788
Epoch 42/50, Train Loss: 0.5313, Val Loss: 0.3989
Epoch 43/50, Train Loss: 0.5309, Val Loss: 0.3933
Epoch 44/50, Train Loss: 0.5303, Val Loss: 0.3931
Epoch 45/50, Train Loss: 0.5295, Val Loss: 0.3839
Epoch 46/50, Train Loss: 0.5294, Val Loss: 0.3900
Epoch 47/50, Train Loss: 0.5288, Val Loss: 0.3900
Epoch 48/50, Train Loss: 0.5285, Val Loss: 0.3789
Epoch 49/50, Train Loss: 0.5282, Val Loss: 0.4013
Epoch 50/50, Train Loss: 0.5276, Val Loss: 0.3869
Total training time: 1193.7444s

Confusion Matrix:
[[178795  15089   1085]
 [  8320  33106  12166]
 [   143    720   2276]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.68      0.62      0.65     53592
           2       0.15      0.73      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.75      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8509
Total evaluation time: 4.2721s
Test Loss: 0.3884
Testing configuration: batch_size=1024, num_epochs=50, num_layers=2, learning_rate=0.0001, dropout=0.5, hidden_size=100
Epoch 1/50, Train Loss: 0.7961, Val Loss: 0.5294
Epoch 2/50, Train Loss: 0.6389, Val Loss: 0.4795
Epoch 3/50, Train Loss: 0.6152, Val Loss: 0.4737
Epoch 4/50, Train Loss: 0.6054, Val Loss: 0.4612
Epoch 5/50, Train Loss: 0.5971, Val Loss: 0.4530
Epoch 6/50, Train Loss: 0.5901, Val Loss: 0.4476
Epoch 7/50, Train Loss: 0.5841, Val Loss: 0.4270
Epoch 8/50, Train Loss: 0.5784, Val Loss: 0.4213
Epoch 9/50, Train Loss: 0.5734, Val Loss: 0.4190
Epoch 10/50, Train Loss: 0.5680, Val Loss: 0.4143
Epoch 11/50, Train Loss: 0.5630, Val Loss: 0.3983
Epoch 12/50, Train Loss: 0.5582, Val Loss: 0.3942
Epoch 13/50, Train Loss: 0.5539, Val Loss: 0.4086
Epoch 14/50, Train Loss: 0.5508, Val Loss: 0.3947
Epoch 15/50, Train Loss: 0.5473, Val Loss: 0.4093
Epoch 16/50, Train Loss: 0.5446, Val Loss: 0.3985
Epoch 17/50, Train Loss: 0.5421, Val Loss: 0.3829
Epoch 18/50, Train Loss: 0.5398, Val Loss: 0.3898
Epoch 19/50, Train Loss: 0.5381, Val Loss: 0.3885
Epoch 20/50, Train Loss: 0.5365, Val Loss: 0.3776
Epoch 21/50, Train Loss: 0.5353, Val Loss: 0.3933
Epoch 22/50, Train Loss: 0.5342, Val Loss: 0.3943
Epoch 23/50, Train Loss: 0.5333, Val Loss: 0.3991
Epoch 24/50, Train Loss: 0.5320, Val Loss: 0.3900
Epoch 25/50, Train Loss: 0.5314, Val Loss: 0.3950
Epoch 26/50, Train Loss: 0.5305, Val Loss: 0.3940
Epoch 27/50, Train Loss: 0.5296, Val Loss: 0.3912
Epoch 28/50, Train Loss: 0.5289, Val Loss: 0.3876
Epoch 29/50, Train Loss: 0.5280, Val Loss: 0.3845
Epoch 30/50, Train Loss: 0.5273, Val Loss: 0.3903
Epoch 31/50, Train Loss: 0.5263, Val Loss: 0.3731
Epoch 32/50, Train Loss: 0.5255, Val Loss: 0.3960
Epoch 33/50, Train Loss: 0.5246, Val Loss: 0.3613
Epoch 34/50, Train Loss: 0.5239, Val Loss: 0.3741
Epoch 35/50, Train Loss: 0.5229, Val Loss: 0.3727
Epoch 36/50, Train Loss: 0.5222, Val Loss: 0.3831
Epoch 37/50, Train Loss: 0.5211, Val Loss: 0.4062
Epoch 38/50, Train Loss: 0.5202, Val Loss: 0.3901
Epoch 39/50, Train Loss: 0.5193, Val Loss: 0.4094
Epoch 40/50, Train Loss: 0.5185, Val Loss: 0.3870
Epoch 41/50, Train Loss: 0.5176, Val Loss: 0.3998
Epoch 42/50, Train Loss: 0.5168, Val Loss: 0.3893
Epoch 43/50, Train Loss: 0.5161, Val Loss: 0.3687
Epoch 44/50, Train Loss: 0.5148, Val Loss: 0.3869
Epoch 45/50, Train Loss: 0.5143, Val Loss: 0.3785
Epoch 46/50, Train Loss: 0.5137, Val Loss: 0.3705
Epoch 47/50, Train Loss: 0.5130, Val Loss: 0.3772
Epoch 48/50, Train Loss: 0.5122, Val Loss: 0.3742
Epoch 49/50, Train Loss: 0.5115, Val Loss: 0.3788
Epoch 50/50, Train Loss: 0.5109, Val Loss: 0.3762
Total training time: 1444.9964s

Confusion Matrix:
[[179137  14429   1403]
 [  8401  33681  11510]
 [   146    735   2258]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.69      0.63      0.66     53592
           2       0.15      0.72      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8545
Total evaluation time: 5.5502s
Test Loss: 0.3780
Testing configuration: batch_size=1024, num_epochs=50, num_layers=5, learning_rate=0.001, dropout=0.5, hidden_size=50
Epoch 1/50, Train Loss: 0.6669, Val Loss: 0.4287
Epoch 2/50, Train Loss: 0.6059, Val Loss: 0.4315
Epoch 3/50, Train Loss: 0.5766, Val Loss: 0.3995
Epoch 4/50, Train Loss: 0.5604, Val Loss: 0.3651
Epoch 5/50, Train Loss: 0.5515, Val Loss: 0.3857
Epoch 6/50, Train Loss: 0.5454, Val Loss: 0.3633
Epoch 7/50, Train Loss: 0.5418, Val Loss: 0.4289
Epoch 8/50, Train Loss: 0.5386, Val Loss: 0.3795
Epoch 9/50, Train Loss: 0.5360, Val Loss: 0.3887
Epoch 10/50, Train Loss: 0.5341, Val Loss: 0.3635
Epoch 11/50, Train Loss: 0.5328, Val Loss: 0.4095
Epoch 12/50, Train Loss: 0.5314, Val Loss: 0.3696
Epoch 13/50, Train Loss: 0.5301, Val Loss: 0.3727
Epoch 14/50, Train Loss: 0.5291, Val Loss: 0.3624
Epoch 15/50, Train Loss: 0.5278, Val Loss: 0.3983
Epoch 16/50, Train Loss: 0.5270, Val Loss: 0.3743
Epoch 17/50, Train Loss: 0.5255, Val Loss: 0.3632
Epoch 18/50, Train Loss: 0.5247, Val Loss: 0.4093
Epoch 19/50, Train Loss: 0.5234, Val Loss: 0.4003
Epoch 20/50, Train Loss: 0.5225, Val Loss: 0.4340
Epoch 21/50, Train Loss: 0.5215, Val Loss: 0.4168
Epoch 22/50, Train Loss: 0.5205, Val Loss: 0.3675
Epoch 23/50, Train Loss: 0.5199, Val Loss: 0.3639
Epoch 24/50, Train Loss: 0.5187, Val Loss: 0.3979
Epoch 25/50, Train Loss: 0.5186, Val Loss: 0.3436
Epoch 26/50, Train Loss: 0.5179, Val Loss: 0.3350
Epoch 27/50, Train Loss: 0.5169, Val Loss: 0.3880
Epoch 28/50, Train Loss: 0.5161, Val Loss: 0.4055
Epoch 29/50, Train Loss: 0.5160, Val Loss: 0.3956
Epoch 30/50, Train Loss: 0.5157, Val Loss: 0.4072
Epoch 31/50, Train Loss: 0.5153, Val Loss: 0.4013
Epoch 32/50, Train Loss: 0.5149, Val Loss: 0.3552
Epoch 33/50, Train Loss: 0.5141, Val Loss: 0.3701
Epoch 34/50, Train Loss: 0.5134, Val Loss: 0.3788
Epoch 35/50, Train Loss: 0.5136, Val Loss: 0.4141
Epoch 36/50, Train Loss: 0.5131, Val Loss: 0.3826
Epoch 37/50, Train Loss: 0.5126, Val Loss: 0.4072
Epoch 38/50, Train Loss: 0.5124, Val Loss: 0.3961
Epoch 39/50, Train Loss: 0.5118, Val Loss: 0.3847
Epoch 40/50, Train Loss: 0.5119, Val Loss: 0.3948
Epoch 41/50, Train Loss: 0.5114, Val Loss: 0.3756
Epoch 42/50, Train Loss: 0.5110, Val Loss: 0.3944
Epoch 43/50, Train Loss: 0.5104, Val Loss: 0.3648
Epoch 44/50, Train Loss: 0.5105, Val Loss: 0.3812
Epoch 45/50, Train Loss: 0.5097, Val Loss: 0.3725
Epoch 46/50, Train Loss: 0.5096, Val Loss: 0.3702
Epoch 47/50, Train Loss: 0.5098, Val Loss: 0.3646
Epoch 48/50, Train Loss: 0.5092, Val Loss: 0.3833
Epoch 49/50, Train Loss: 0.5090, Val Loss: 0.3573
Epoch 50/50, Train Loss: 0.5082, Val Loss: 0.3745
Total training time: 1371.1655s

Confusion Matrix:
[[180223  13044   1702]
 [  8495  31958  13139]
 [   148    566   2425]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.70      0.60      0.64     53592
           2       0.14      0.77      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8526
Total evaluation time: 4.6788s
Test Loss: 0.3763
Testing configuration: batch_size=1024, num_epochs=50, num_layers=5, learning_rate=0.001, dropout=0.5, hidden_size=100
Epoch 1/50, Train Loss: 0.6469, Val Loss: 0.4446
Epoch 2/50, Train Loss: 0.5799, Val Loss: 0.3974
Epoch 3/50, Train Loss: 0.5521, Val Loss: 0.3701
Epoch 4/50, Train Loss: 0.5409, Val Loss: 0.3752
Epoch 5/50, Train Loss: 0.5346, Val Loss: 0.3912
Epoch 6/50, Train Loss: 0.5302, Val Loss: 0.3447
Epoch 7/50, Train Loss: 0.5254, Val Loss: 0.4061
Epoch 8/50, Train Loss: 0.5211, Val Loss: 0.3756
Epoch 9/50, Train Loss: 0.5177, Val Loss: 0.3814
Epoch 10/50, Train Loss: 0.5142, Val Loss: 0.3605
Epoch 11/50, Train Loss: 0.5114, Val Loss: 0.3831
Epoch 12/50, Train Loss: 0.5089, Val Loss: 0.3782
Epoch 13/50, Train Loss: 0.5064, Val Loss: 0.3432
Epoch 14/50, Train Loss: 0.5051, Val Loss: 0.3580
Epoch 15/50, Train Loss: 0.5042, Val Loss: 0.4041
Epoch 16/50, Train Loss: 0.5023, Val Loss: 0.3594
Epoch 17/50, Train Loss: 0.5012, Val Loss: 0.3717
Epoch 18/50, Train Loss: 0.5000, Val Loss: 0.3681
Epoch 19/50, Train Loss: 0.4992, Val Loss: 0.4105
Epoch 20/50, Train Loss: 0.4983, Val Loss: 0.3436
Epoch 21/50, Train Loss: 0.4973, Val Loss: 0.3498
Epoch 22/50, Train Loss: 0.4963, Val Loss: 0.3416
Epoch 23/50, Train Loss: 0.4954, Val Loss: 0.3473
Epoch 24/50, Train Loss: 0.4947, Val Loss: 0.4231
Epoch 25/50, Train Loss: 0.4947, Val Loss: 0.3601
Epoch 26/50, Train Loss: 0.4928, Val Loss: 0.3750
Epoch 27/50, Train Loss: 0.4926, Val Loss: 0.3675
Epoch 28/50, Train Loss: 0.4918, Val Loss: 0.3802
Epoch 29/50, Train Loss: 0.4919, Val Loss: 0.3727
Epoch 30/50, Train Loss: 0.4902, Val Loss: 0.3584
Epoch 31/50, Train Loss: 0.4914, Val Loss: 0.3766
Epoch 32/50, Train Loss: 0.4894, Val Loss: 0.3725
Epoch 33/50, Train Loss: 0.4884, Val Loss: 0.3844
Epoch 34/50, Train Loss: 0.4887, Val Loss: 0.3705
Epoch 35/50, Train Loss: 0.4883, Val Loss: 0.3514
Epoch 36/50, Train Loss: 0.4873, Val Loss: 0.3648
Epoch 37/50, Train Loss: 0.4867, Val Loss: 0.3533
Epoch 38/50, Train Loss: 0.4870, Val Loss: 0.4351
Epoch 39/50, Train Loss: 0.4858, Val Loss: 0.3709
Epoch 40/50, Train Loss: 0.4853, Val Loss: 0.3343
Epoch 41/50, Train Loss: 0.4848, Val Loss: 0.4159
Epoch 42/50, Train Loss: 0.4852, Val Loss: 0.3501
Epoch 43/50, Train Loss: 0.4844, Val Loss: 0.3570
Epoch 44/50, Train Loss: 0.4838, Val Loss: 0.3634
Epoch 45/50, Train Loss: 0.4834, Val Loss: 0.3647
Epoch 46/50, Train Loss: 0.4838, Val Loss: 0.3612
Epoch 47/50, Train Loss: 0.4827, Val Loss: 0.3404
Epoch 48/50, Train Loss: 0.4820, Val Loss: 0.3938
Epoch 49/50, Train Loss: 0.4817, Val Loss: 0.3679
Epoch 50/50, Train Loss: 0.4819, Val Loss: 0.3931
Total training time: 1687.7952s

Confusion Matrix:
[[178113  13942   2914]
 [  7909  32559  13124]
 [   134    561   2444]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.69      0.61      0.65     53592
           2       0.13      0.78      0.23      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.77      0.60    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8467
Total evaluation time: 5.1325s
Test Loss: 0.3946
Testing configuration: batch_size=1024, num_epochs=50, num_layers=5, learning_rate=0.0001, dropout=0.5, hidden_size=50
Epoch 1/50, Train Loss: 0.8629, Val Loss: 0.5397
Epoch 2/50, Train Loss: 0.6800, Val Loss: 0.4792
Epoch 3/50, Train Loss: 0.6513, Val Loss: 0.4784
Epoch 4/50, Train Loss: 0.6392, Val Loss: 0.4578
Epoch 5/50, Train Loss: 0.6308, Val Loss: 0.4579
Epoch 6/50, Train Loss: 0.6251, Val Loss: 0.4483
Epoch 7/50, Train Loss: 0.6210, Val Loss: 0.4611
Epoch 8/50, Train Loss: 0.6168, Val Loss: 0.4449
Epoch 9/50, Train Loss: 0.6130, Val Loss: 0.4388
Epoch 10/50, Train Loss: 0.6084, Val Loss: 0.4319
Epoch 11/50, Train Loss: 0.6027, Val Loss: 0.4224
Epoch 12/50, Train Loss: 0.5955, Val Loss: 0.4114
Epoch 13/50, Train Loss: 0.5873, Val Loss: 0.4152
Epoch 14/50, Train Loss: 0.5820, Val Loss: 0.3984
Epoch 15/50, Train Loss: 0.5781, Val Loss: 0.3992
Epoch 16/50, Train Loss: 0.5751, Val Loss: 0.3938
Epoch 17/50, Train Loss: 0.5728, Val Loss: 0.3889
Epoch 18/50, Train Loss: 0.5701, Val Loss: 0.3930
Epoch 19/50, Train Loss: 0.5677, Val Loss: 0.3882
Epoch 20/50, Train Loss: 0.5658, Val Loss: 0.3980
Epoch 21/50, Train Loss: 0.5633, Val Loss: 0.3928
Epoch 22/50, Train Loss: 0.5622, Val Loss: 0.3944
Epoch 23/50, Train Loss: 0.5607, Val Loss: 0.4072
Epoch 24/50, Train Loss: 0.5588, Val Loss: 0.4054
Epoch 25/50, Train Loss: 0.5570, Val Loss: 0.3842
Epoch 26/50, Train Loss: 0.5559, Val Loss: 0.3902
Epoch 27/50, Train Loss: 0.5539, Val Loss: 0.3806
Epoch 28/50, Train Loss: 0.5528, Val Loss: 0.3983
Epoch 29/50, Train Loss: 0.5514, Val Loss: 0.4013
Epoch 30/50, Train Loss: 0.5502, Val Loss: 0.3995
Epoch 31/50, Train Loss: 0.5489, Val Loss: 0.3779
Epoch 32/50, Train Loss: 0.5481, Val Loss: 0.3831
Epoch 33/50, Train Loss: 0.5474, Val Loss: 0.3721
Epoch 34/50, Train Loss: 0.5464, Val Loss: 0.3992
Epoch 35/50, Train Loss: 0.5451, Val Loss: 0.3755
Epoch 36/50, Train Loss: 0.5446, Val Loss: 0.3566
Epoch 37/50, Train Loss: 0.5436, Val Loss: 0.3878
Epoch 38/50, Train Loss: 0.5430, Val Loss: 0.4221
Epoch 39/50, Train Loss: 0.5422, Val Loss: 0.3862
Epoch 40/50, Train Loss: 0.5416, Val Loss: 0.3900
Epoch 41/50, Train Loss: 0.5412, Val Loss: 0.3746
Epoch 42/50, Train Loss: 0.5403, Val Loss: 0.3718
Epoch 43/50, Train Loss: 0.5401, Val Loss: 0.3808
Epoch 44/50, Train Loss: 0.5398, Val Loss: 0.3932
Epoch 45/50, Train Loss: 0.5391, Val Loss: 0.3759
Epoch 46/50, Train Loss: 0.5386, Val Loss: 0.3897
Epoch 47/50, Train Loss: 0.5381, Val Loss: 0.3958
Epoch 48/50, Train Loss: 0.5376, Val Loss: 0.3690
Epoch 49/50, Train Loss: 0.5374, Val Loss: 0.3926
Epoch 50/50, Train Loss: 0.5366, Val Loss: 0.3854
Total training time: 1372.8007s

Confusion Matrix:
[[179319  13908   1742]
 [  8382  33051  12159]
 [   147    716   2276]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.69      0.62      0.65     53592
           2       0.14      0.73      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.75      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8528
Total evaluation time: 4.7212s
Test Loss: 0.3871
Testing configuration: batch_size=1024, num_epochs=50, num_layers=5, learning_rate=0.0001, dropout=0.5, hidden_size=100
Epoch 1/50, Train Loss: 0.7762, Val Loss: 0.4888
Epoch 2/50, Train Loss: 0.6451, Val Loss: 0.4804
Epoch 3/50, Train Loss: 0.6296, Val Loss: 0.4655
Epoch 4/50, Train Loss: 0.6188, Val Loss: 0.4718
Epoch 5/50, Train Loss: 0.6128, Val Loss: 0.4640
Epoch 6/50, Train Loss: 0.6075, Val Loss: 0.4450
Epoch 7/50, Train Loss: 0.6011, Val Loss: 0.4475
Epoch 8/50, Train Loss: 0.5917, Val Loss: 0.4456
Epoch 9/50, Train Loss: 0.5824, Val Loss: 0.4031
Epoch 10/50, Train Loss: 0.5753, Val Loss: 0.4011
Epoch 11/50, Train Loss: 0.5704, Val Loss: 0.3906
Epoch 12/50, Train Loss: 0.5663, Val Loss: 0.3928
Epoch 13/50, Train Loss: 0.5627, Val Loss: 0.4004
Epoch 14/50, Train Loss: 0.5595, Val Loss: 0.3965
Epoch 15/50, Train Loss: 0.5565, Val Loss: 0.4017
Epoch 16/50, Train Loss: 0.5540, Val Loss: 0.3889
Epoch 17/50, Train Loss: 0.5513, Val Loss: 0.3770
Epoch 18/50, Train Loss: 0.5495, Val Loss: 0.3869
Epoch 19/50, Train Loss: 0.5471, Val Loss: 0.4160
Epoch 20/50, Train Loss: 0.5452, Val Loss: 0.3932
Epoch 21/50, Train Loss: 0.5433, Val Loss: 0.3777
Epoch 22/50, Train Loss: 0.5420, Val Loss: 0.3943
Epoch 23/50, Train Loss: 0.5407, Val Loss: 0.3960
Epoch 24/50, Train Loss: 0.5388, Val Loss: 0.3895
Epoch 25/50, Train Loss: 0.5377, Val Loss: 0.3879
Epoch 26/50, Train Loss: 0.5369, Val Loss: 0.4037
Epoch 27/50, Train Loss: 0.5357, Val Loss: 0.3900
Epoch 28/50, Train Loss: 0.5350, Val Loss: 0.3879
Epoch 29/50, Train Loss: 0.5339, Val Loss: 0.3830
Epoch 30/50, Train Loss: 0.5332, Val Loss: 0.3957
Epoch 31/50, Train Loss: 0.5321, Val Loss: 0.4104
Epoch 32/50, Train Loss: 0.5318, Val Loss: 0.3964
Epoch 33/50, Train Loss: 0.5308, Val Loss: 0.3851
Epoch 34/50, Train Loss: 0.5302, Val Loss: 0.3935
Epoch 35/50, Train Loss: 0.5294, Val Loss: 0.3879
Epoch 36/50, Train Loss: 0.5290, Val Loss: 0.3715
Epoch 37/50, Train Loss: 0.5284, Val Loss: 0.3899
Epoch 38/50, Train Loss: 0.5275, Val Loss: 0.3900
Epoch 39/50, Train Loss: 0.5272, Val Loss: 0.3828
Epoch 40/50, Train Loss: 0.5264, Val Loss: 0.3873
Epoch 41/50, Train Loss: 0.5260, Val Loss: 0.4003
Epoch 42/50, Train Loss: 0.5255, Val Loss: 0.3787
Epoch 43/50, Train Loss: 0.5249, Val Loss: 0.3837
Epoch 44/50, Train Loss: 0.5242, Val Loss: 0.3729
Epoch 45/50, Train Loss: 0.5239, Val Loss: 0.3659
Epoch 46/50, Train Loss: 0.5232, Val Loss: 0.4017
Epoch 47/50, Train Loss: 0.5228, Val Loss: 0.3732
Epoch 48/50, Train Loss: 0.5222, Val Loss: 0.3827
Epoch 49/50, Train Loss: 0.5219, Val Loss: 0.3756
Epoch 50/50, Train Loss: 0.5217, Val Loss: 0.3762
Total training time: 1687.6984s

Confusion Matrix:
[[178921  14429   1619]
 [  8264  33664  11664]
 [   144    727   2268]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.69      0.63      0.66     53592
           2       0.15      0.72      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8536
Total evaluation time: 5.6969s
Test Loss: 0.3781
Testing configuration: batch_size=1024, num_epochs=50, num_layers=10, learning_rate=0.001, dropout=0.5, hidden_size=50
Epoch 1/50, Train Loss: 0.9438, Val Loss: 0.6478
Epoch 2/50, Train Loss: 0.8091, Val Loss: 0.6571
Epoch 3/50, Train Loss: 0.7895, Val Loss: 0.5436
Epoch 4/50, Train Loss: 0.7266, Val Loss: 0.5401
Epoch 5/50, Train Loss: 0.6843, Val Loss: 0.4151
Epoch 6/50, Train Loss: 0.6192, Val Loss: 0.4158
Epoch 7/50, Train Loss: 0.5975, Val Loss: 0.3920
Epoch 8/50, Train Loss: 0.5848, Val Loss: 0.4282
Epoch 9/50, Train Loss: 0.5767, Val Loss: 0.3786
Epoch 10/50, Train Loss: 0.5730, Val Loss: 0.4557
Epoch 11/50, Train Loss: 0.5681, Val Loss: 0.4052
Epoch 12/50, Train Loss: 0.5654, Val Loss: 0.3610
Epoch 13/50, Train Loss: 0.5647, Val Loss: 0.3854
Epoch 14/50, Train Loss: 0.5627, Val Loss: 0.3928
Epoch 15/50, Train Loss: 0.5630, Val Loss: 0.3923
Epoch 16/50, Train Loss: 0.5613, Val Loss: 0.3774
Epoch 17/50, Train Loss: 0.5605, Val Loss: 0.4222
Epoch 18/50, Train Loss: 0.5571, Val Loss: 0.4178
Epoch 19/50, Train Loss: 0.5569, Val Loss: 0.4193
Epoch 20/50, Train Loss: 0.5581, Val Loss: 0.3812
Epoch 21/50, Train Loss: 0.5564, Val Loss: 0.4388
Epoch 22/50, Train Loss: 0.5566, Val Loss: 0.3738
Epoch 23/50, Train Loss: 0.5539, Val Loss: 0.3825
Epoch 24/50, Train Loss: 0.5588, Val Loss: 0.3679
Epoch 25/50, Train Loss: 0.5530, Val Loss: 0.4008
Epoch 26/50, Train Loss: 0.5524, Val Loss: 0.4042
Epoch 27/50, Train Loss: 0.5552, Val Loss: 0.4093
Epoch 28/50, Train Loss: 0.5560, Val Loss: 0.4259
Epoch 29/50, Train Loss: 0.5553, Val Loss: 0.4288
Epoch 30/50, Train Loss: 0.5539, Val Loss: 0.3710
Epoch 31/50, Train Loss: 0.5555, Val Loss: 0.4141
Epoch 32/50, Train Loss: 0.5528, Val Loss: 0.3915
Epoch 33/50, Train Loss: 0.5519, Val Loss: 0.3804
Epoch 34/50, Train Loss: 0.5579, Val Loss: 0.3587
Epoch 35/50, Train Loss: 0.5602, Val Loss: 0.4469
Epoch 36/50, Train Loss: 0.5537, Val Loss: 0.4070
Epoch 37/50, Train Loss: 0.5554, Val Loss: 0.4115
Epoch 38/50, Train Loss: 0.5657, Val Loss: 0.4037
Epoch 39/50, Train Loss: 0.5614, Val Loss: 0.4366
Epoch 40/50, Train Loss: 0.5587, Val Loss: 0.3760
Epoch 41/50, Train Loss: 0.5647, Val Loss: 0.3503
Epoch 42/50, Train Loss: 0.5725, Val Loss: 0.3829
Epoch 43/50, Train Loss: 0.5637, Val Loss: 0.4027
Epoch 44/50, Train Loss: 0.5725, Val Loss: 0.3855
Epoch 45/50, Train Loss: 0.5723, Val Loss: 0.4060
Epoch 46/50, Train Loss: 0.5617, Val Loss: 0.3993
Epoch 47/50, Train Loss: 0.5626, Val Loss: 0.3793
Epoch 48/50, Train Loss: 0.5696, Val Loss: 0.3716
Epoch 49/50, Train Loss: 0.5612, Val Loss: 0.3853
Epoch 50/50, Train Loss: 0.6116, Val Loss: 0.4012
Total training time: 1499.9624s

Confusion Matrix:
[[183186  10937    846]
 [ 10530  32236  10826]
 [   166    755   2218]]

Classification Report:
              precision    recall  f1-score   support

           0       0.94      0.94      0.94    194969
           1       0.73      0.60      0.66     53592
           2       0.16      0.71      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.75      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8647
Total evaluation time: 5.0343s
Test Loss: 0.4033
Testing configuration: batch_size=1024, num_epochs=50, num_layers=10, learning_rate=0.001, dropout=0.5, hidden_size=100
Epoch 1/50, Train Loss: 1.0987, Val Loss: 1.1090
Epoch 2/50, Train Loss: 1.0725, Val Loss: 0.6692
Epoch 3/50, Train Loss: 0.7761, Val Loss: 0.5265
Epoch 4/50, Train Loss: 0.7241, Val Loss: 0.5465
Epoch 5/50, Train Loss: 0.6856, Val Loss: 0.4972
Epoch 6/50, Train Loss: 0.6211, Val Loss: 0.3973
Epoch 7/50, Train Loss: 0.5979, Val Loss: 0.4195
Epoch 8/50, Train Loss: 0.5783, Val Loss: 0.4295
Epoch 9/50, Train Loss: 0.5678, Val Loss: 0.3663
Epoch 10/50, Train Loss: 0.5626, Val Loss: 0.3737
Epoch 11/50, Train Loss: 0.5621, Val Loss: 0.4211
Epoch 12/50, Train Loss: 0.5588, Val Loss: 0.3957
Epoch 13/50, Train Loss: 0.5572, Val Loss: 0.3376
Epoch 14/50, Train Loss: 0.5542, Val Loss: 0.4134
Epoch 15/50, Train Loss: 0.5468, Val Loss: 0.3717
Epoch 16/50, Train Loss: 0.5439, Val Loss: 0.4067
Epoch 17/50, Train Loss: 0.5409, Val Loss: 0.3867
Epoch 18/50, Train Loss: 0.5374, Val Loss: 0.3856
Epoch 19/50, Train Loss: 0.5490, Val Loss: 0.3779
Epoch 20/50, Train Loss: 0.5316, Val Loss: 0.3976
Epoch 21/50, Train Loss: 0.5291, Val Loss: 0.3758
Epoch 22/50, Train Loss: 0.5303, Val Loss: 0.4117
Epoch 23/50, Train Loss: 0.5239, Val Loss: 0.3995
Epoch 24/50, Train Loss: 0.5228, Val Loss: 0.3826
Epoch 25/50, Train Loss: 0.5211, Val Loss: 0.3842
Epoch 26/50, Train Loss: 0.5239, Val Loss: 0.3486
Epoch 27/50, Train Loss: 0.5196, Val Loss: 0.4097
Epoch 28/50, Train Loss: 0.5187, Val Loss: 0.3939
Epoch 29/50, Train Loss: 0.5163, Val Loss: 0.3678
Epoch 30/50, Train Loss: 0.5156, Val Loss: 0.3886
Epoch 31/50, Train Loss: 0.5148, Val Loss: 0.4105
Epoch 32/50, Train Loss: 0.5145, Val Loss: 0.4177
Epoch 33/50, Train Loss: 0.5131, Val Loss: 0.4173
Epoch 34/50, Train Loss: 0.5133, Val Loss: 0.4265
Epoch 35/50, Train Loss: 0.5126, Val Loss: 0.3770
Epoch 36/50, Train Loss: 0.5123, Val Loss: 0.3684
Epoch 37/50, Train Loss: 0.5151, Val Loss: 0.3742
Epoch 38/50, Train Loss: 0.5095, Val Loss: 0.3894
Epoch 39/50, Train Loss: 0.5134, Val Loss: 0.3926
Epoch 40/50, Train Loss: 0.5097, Val Loss: 0.4047
Epoch 41/50, Train Loss: 0.5109, Val Loss: 0.3891
Epoch 42/50, Train Loss: 0.5101, Val Loss: 0.3984
Epoch 43/50, Train Loss: 0.5112, Val Loss: 0.3745
Epoch 44/50, Train Loss: 0.5071, Val Loss: 0.3560
Epoch 45/50, Train Loss: 0.5077, Val Loss: 0.3509
Epoch 46/50, Train Loss: 0.5076, Val Loss: 0.3678
Epoch 47/50, Train Loss: 0.5078, Val Loss: 0.3725
Epoch 48/50, Train Loss: 0.5052, Val Loss: 0.3711
Epoch 49/50, Train Loss: 0.5091, Val Loss: 0.4053
Epoch 50/50, Train Loss: 0.5072, Val Loss: 0.3998
Total training time: 2445.8859s

Confusion Matrix:
[[178206  15361   1402]
 [  7956  31961  13675]
 [   143    555   2441]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.67      0.60      0.63     53592
           2       0.14      0.78      0.24      3139

    accuracy                           0.84    251700
   macro avg       0.59      0.76      0.60    251700
weighted avg       0.88      0.84      0.86    251700


Global Accuracy: 0.8447
Total evaluation time: 6.5254s
Test Loss: 0.4014
Testing configuration: batch_size=1024, num_epochs=50, num_layers=10, learning_rate=0.0001, dropout=0.5, hidden_size=50
Epoch 1/50, Train Loss: 1.0991, Val Loss: 1.0957
Epoch 2/50, Train Loss: 0.9664, Val Loss: 0.6021
Epoch 3/50, Train Loss: 0.7454, Val Loss: 0.5311
Epoch 4/50, Train Loss: 0.6883, Val Loss: 0.4850
Epoch 5/50, Train Loss: 0.6652, Val Loss: 0.4939
Epoch 6/50, Train Loss: 0.6536, Val Loss: 0.4716
Epoch 7/50, Train Loss: 0.6437, Val Loss: 0.4701
Epoch 8/50, Train Loss: 0.6369, Val Loss: 0.4568
Epoch 9/50, Train Loss: 0.6326, Val Loss: 0.4622
Epoch 10/50, Train Loss: 0.6284, Val Loss: 0.4625
Epoch 11/50, Train Loss: 0.6252, Val Loss: 0.4538
Epoch 12/50, Train Loss: 0.6217, Val Loss: 0.4468
Epoch 13/50, Train Loss: 0.6184, Val Loss: 0.4537
Epoch 14/50, Train Loss: 0.6147, Val Loss: 0.4517
Epoch 15/50, Train Loss: 0.6111, Val Loss: 0.4223
Epoch 16/50, Train Loss: 0.6069, Val Loss: 0.4311
Epoch 17/50, Train Loss: 0.6028, Val Loss: 0.4212
Epoch 18/50, Train Loss: 0.5983, Val Loss: 0.4256
Epoch 19/50, Train Loss: 0.5945, Val Loss: 0.4247
Epoch 20/50, Train Loss: 0.5916, Val Loss: 0.4067
Epoch 21/50, Train Loss: 0.5894, Val Loss: 0.4115
Epoch 22/50, Train Loss: 0.5875, Val Loss: 0.4063
Epoch 23/50, Train Loss: 0.5860, Val Loss: 0.4099
Epoch 24/50, Train Loss: 0.5845, Val Loss: 0.3987
Epoch 25/50, Train Loss: 0.5830, Val Loss: 0.3992
Epoch 26/50, Train Loss: 0.5816, Val Loss: 0.4321
Epoch 27/50, Train Loss: 0.5806, Val Loss: 0.4155
Epoch 28/50, Train Loss: 0.5796, Val Loss: 0.4075
Epoch 29/50, Train Loss: 0.5780, Val Loss: 0.4224
Epoch 30/50, Train Loss: 0.5761, Val Loss: 0.3940
Epoch 31/50, Train Loss: 0.5757, Val Loss: 0.4154
Epoch 32/50, Train Loss: 0.5746, Val Loss: 0.4061
Epoch 33/50, Train Loss: 0.5733, Val Loss: 0.4214
Epoch 34/50, Train Loss: 0.5723, Val Loss: 0.3877
Epoch 35/50, Train Loss: 0.5716, Val Loss: 0.4302
Epoch 36/50, Train Loss: 0.5706, Val Loss: 0.3960
Epoch 37/50, Train Loss: 0.5692, Val Loss: 0.3914
Epoch 38/50, Train Loss: 0.5688, Val Loss: 0.4058
Epoch 39/50, Train Loss: 0.5678, Val Loss: 0.4018
Epoch 40/50, Train Loss: 0.5671, Val Loss: 0.4058
Epoch 41/50, Train Loss: 0.5662, Val Loss: 0.3828
Epoch 42/50, Train Loss: 0.5655, Val Loss: 0.4020
Epoch 43/50, Train Loss: 0.5647, Val Loss: 0.4133
Epoch 44/50, Train Loss: 0.5642, Val Loss: 0.4099
Epoch 45/50, Train Loss: 0.5635, Val Loss: 0.4013
Epoch 46/50, Train Loss: 0.5628, Val Loss: 0.3846
Epoch 47/50, Train Loss: 0.5630, Val Loss: 0.4055
Epoch 48/50, Train Loss: 0.5615, Val Loss: 0.3943
Epoch 49/50, Train Loss: 0.5612, Val Loss: 0.4023
Epoch 50/50, Train Loss: 0.5609, Val Loss: 0.3913
Total training time: 1501.8444s

Confusion Matrix:
[[181834  12668    467]
 [  9390  31698  12504]
 [   161    731   2247]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.70      0.59      0.64     53592
           2       0.15      0.72      0.24      3139

    accuracy                           0.86    251700
   macro avg       0.60      0.75      0.61    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8573
Total evaluation time: 5.0236s
Test Loss: 0.3931
Testing configuration: batch_size=1024, num_epochs=50, num_layers=10, learning_rate=0.0001, dropout=0.5, hidden_size=100
Epoch 1/50, Train Loss: 1.0988, Val Loss: 1.0960
Epoch 2/50, Train Loss: 1.0986, Val Loss: 1.0986
Epoch 3/50, Train Loss: 0.7408, Val Loss: 0.4904
Epoch 4/50, Train Loss: 0.6506, Val Loss: 0.4766
Epoch 5/50, Train Loss: 0.6337, Val Loss: 0.4732
Epoch 6/50, Train Loss: 0.6243, Val Loss: 0.4497
Epoch 7/50, Train Loss: 0.6187, Val Loss: 0.4480
Epoch 8/50, Train Loss: 0.6132, Val Loss: 0.4530
Epoch 9/50, Train Loss: 0.6083, Val Loss: 0.4399
Epoch 10/50, Train Loss: 0.6033, Val Loss: 0.4198
Epoch 11/50, Train Loss: 0.5975, Val Loss: 0.4213
Epoch 12/50, Train Loss: 0.5919, Val Loss: 0.4065
Epoch 13/50, Train Loss: 0.5867, Val Loss: 0.3964
Epoch 14/50, Train Loss: 0.5828, Val Loss: 0.4308
Epoch 15/50, Train Loss: 0.5796, Val Loss: 0.3896
Epoch 16/50, Train Loss: 0.5770, Val Loss: 0.4051
Epoch 17/50, Train Loss: 0.5746, Val Loss: 0.4156
Epoch 18/50, Train Loss: 0.5723, Val Loss: 0.3864
Epoch 19/50, Train Loss: 0.5703, Val Loss: 0.3921
Epoch 20/50, Train Loss: 0.5684, Val Loss: 0.4254
Epoch 21/50, Train Loss: 0.5665, Val Loss: 0.3934
Epoch 22/50, Train Loss: 0.5645, Val Loss: 0.4005
Epoch 23/50, Train Loss: 0.5630, Val Loss: 0.4262
Epoch 24/50, Train Loss: 0.5618, Val Loss: 0.4057
Epoch 25/50, Train Loss: 0.5602, Val Loss: 0.4006
Epoch 26/50, Train Loss: 0.5592, Val Loss: 0.4062
Epoch 27/50, Train Loss: 0.5578, Val Loss: 0.4067
Epoch 28/50, Train Loss: 0.5567, Val Loss: 0.3914
Epoch 29/50, Train Loss: 0.5557, Val Loss: 0.4020
Epoch 30/50, Train Loss: 0.5550, Val Loss: 0.3871
Epoch 31/50, Train Loss: 0.5538, Val Loss: 0.3934
Epoch 32/50, Train Loss: 0.5532, Val Loss: 0.3827
Epoch 33/50, Train Loss: 0.5525, Val Loss: 0.3895
Epoch 34/50, Train Loss: 0.5514, Val Loss: 0.4158
Epoch 35/50, Train Loss: 0.5508, Val Loss: 0.4128
Epoch 36/50, Train Loss: 0.5503, Val Loss: 0.3996
Epoch 37/50, Train Loss: 0.5496, Val Loss: 0.4050
Epoch 38/50, Train Loss: 0.5489, Val Loss: 0.4050
Epoch 39/50, Train Loss: 0.5481, Val Loss: 0.3701
Epoch 40/50, Train Loss: 0.5476, Val Loss: 0.3748
Epoch 41/50, Train Loss: 0.5473, Val Loss: 0.3704
Epoch 42/50, Train Loss: 0.5463, Val Loss: 0.4006
Epoch 43/50, Train Loss: 0.5457, Val Loss: 0.3847
Epoch 44/50, Train Loss: 0.5455, Val Loss: 0.4061
Epoch 45/50, Train Loss: 0.5450, Val Loss: 0.3747
Epoch 46/50, Train Loss: 0.5445, Val Loss: 0.3762
Epoch 47/50, Train Loss: 0.5441, Val Loss: 0.3935
Epoch 48/50, Train Loss: 0.5438, Val Loss: 0.3737
Epoch 49/50, Train Loss: 0.5434, Val Loss: 0.3847
Epoch 50/50, Train Loss: 0.5429, Val Loss: 0.3902
Total training time: 2442.2348s

Confusion Matrix:
[[179874  14593    502]
 [  8734  32689  12169]
 [   150    708   2281]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.68      0.61      0.64     53592
           2       0.15      0.73      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.75      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8536
Total evaluation time: 6.4283s
Test Loss: 0.3923
Best configuration: {'batch_size': 1024, 'num_epochs': 50, 'num_layers': 10, 'learning_rate': 0.001, 'dropout': 0.5, 'hidden_size': 50} with accuracy: 0.8647
