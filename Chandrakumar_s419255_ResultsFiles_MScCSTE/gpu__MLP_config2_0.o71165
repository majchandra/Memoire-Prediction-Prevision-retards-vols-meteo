CUDA_VISIBLE_DEVICES=GPU-0d9695e9-5701-ca6e-d4e6-b2066ff1f2b4
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pandas in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.2.2)
Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: tzdata>=2022.7 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: numpy>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (1.26.4)
Requirement already satisfied: pytz>=2020.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: six>=1.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: imblearn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.0)
Requirement already satisfied: imbalanced-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imblearn) (0.12.3)
Requirement already satisfied: scikit-learn>=1.0.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.5.0)
Requirement already satisfied: numpy>=1.17.3 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.26.4)
Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.5.0)
Requirement already satisfied: joblib>=1.1.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.4.2)
Requirement already satisfied: scipy>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.13.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.3.1)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.8.4)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.20.5)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2024.6.0)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.3.1)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.11.3)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (1.10.1)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (4.12.1)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (3.6.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch) (1.2.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: scikit-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: numpy>=1.19.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.26.4)
Requirement already satisfied: joblib>=1.2.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (3.5.0)
Requirement already satisfied: scipy>=1.6.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.26.4)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torchdiffeq in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.2.4)
Requirement already satisfied: torch>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (2.3.1)
Requirement already satisfied: scipy>=1.4.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (1.13.1)
Requirement already satisfied: numpy<2.3,>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.20.5)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.11.3)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (4.12.1)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (3.6.0)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (1.10.1)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.3.1)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.8.4)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2024.6.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.2.1)
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
42
cuda
0h
Testing configuration: batch_size=512, num_epochs=10, learning_rate=0.001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/10, Train Loss: 0.6323, Val Loss: 0.4000
Epoch 2/10, Train Loss: 0.5680, Val Loss: 0.3687
Epoch 3/10, Train Loss: 0.5518, Val Loss: 0.4420
Epoch 4/10, Train Loss: 0.5457, Val Loss: 0.3889
Epoch 5/10, Train Loss: 0.5411, Val Loss: 0.3713
Epoch 6/10, Train Loss: 0.5379, Val Loss: 0.3767
Epoch 7/10, Train Loss: 0.5353, Val Loss: 0.3854
Epoch 8/10, Train Loss: 0.5336, Val Loss: 0.3787
Epoch 9/10, Train Loss: 0.5328, Val Loss: 0.3709
Epoch 10/10, Train Loss: 0.5308, Val Loss: 0.3811
Total training time: 214.3774s

Confusion Matrix:
[[177458  16016   1495]
 [  7797  33705  12090]
 [   132    677   2330]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.67      0.63      0.65     53592
           2       0.15      0.74      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.76      0.61    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8482
Total evaluation time: 3.1096s
Test Loss: 0.3827
Testing configuration: batch_size=512, num_epochs=10, learning_rate=0.001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/10, Train Loss: 0.5993, Val Loss: 0.3964
Epoch 2/10, Train Loss: 0.5388, Val Loss: 0.4095
Epoch 3/10, Train Loss: 0.5215, Val Loss: 0.3437
Epoch 4/10, Train Loss: 0.5143, Val Loss: 0.3805
Epoch 5/10, Train Loss: 0.5090, Val Loss: 0.3783
Epoch 6/10, Train Loss: 0.5058, Val Loss: 0.3557
Epoch 7/10, Train Loss: 0.5030, Val Loss: 0.3638
Epoch 8/10, Train Loss: 0.5009, Val Loss: 0.4100
Epoch 9/10, Train Loss: 0.4990, Val Loss: 0.3693
Epoch 10/10, Train Loss: 0.4975, Val Loss: 0.3605
Total training time: 208.7734s

Confusion Matrix:
[[179315  13974   1680]
 [  8157  33456  11979]
 [   131    626   2382]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.70      0.62      0.66     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.77      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8548
Total evaluation time: 3.0606s
Test Loss: 0.3623
Testing configuration: batch_size=512, num_epochs=10, learning_rate=0.001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/10, Train Loss: 0.5751, Val Loss: 0.3869
Epoch 2/10, Train Loss: 0.5198, Val Loss: 0.3716
Epoch 3/10, Train Loss: 0.5007, Val Loss: 0.3462
Epoch 4/10, Train Loss: 0.4910, Val Loss: 0.3911
Epoch 5/10, Train Loss: 0.4848, Val Loss: 0.3807
Epoch 6/10, Train Loss: 0.4800, Val Loss: 0.3515
Epoch 7/10, Train Loss: 0.4764, Val Loss: 0.3496
Epoch 8/10, Train Loss: 0.4732, Val Loss: 0.3282
Epoch 9/10, Train Loss: 0.4703, Val Loss: 0.3694
Epoch 10/10, Train Loss: 0.4679, Val Loss: 0.3916
Total training time: 211.3146s

Confusion Matrix:
[[173558  18858   2553]
 [  6889  36411  10292]
 [   110    693   2336]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.89      0.92    194969
           1       0.65      0.68      0.66     53592
           2       0.15      0.74      0.26      3139

    accuracy                           0.84    251700
   macro avg       0.59      0.77      0.61    251700
weighted avg       0.89      0.84      0.86    251700


Global Accuracy: 0.8435
Total evaluation time: 2.8952s
Test Loss: 0.3936
Testing configuration: batch_size=512, num_epochs=10, learning_rate=0.0001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/10, Train Loss: 0.7680, Val Loss: 0.4990
Epoch 2/10, Train Loss: 0.6621, Val Loss: 0.4681
Epoch 3/10, Train Loss: 0.6362, Val Loss: 0.4550
Epoch 4/10, Train Loss: 0.6197, Val Loss: 0.4524
Epoch 5/10, Train Loss: 0.6087, Val Loss: 0.4389
Epoch 6/10, Train Loss: 0.6005, Val Loss: 0.4442
Epoch 7/10, Train Loss: 0.5934, Val Loss: 0.4180
Epoch 8/10, Train Loss: 0.5865, Val Loss: 0.4205
Epoch 9/10, Train Loss: 0.5806, Val Loss: 0.4133
Epoch 10/10, Train Loss: 0.5747, Val Loss: 0.4128
Total training time: 208.0673s

Confusion Matrix:
[[178749  14761   1459]
 [  8618  32446  12528]
 [   145    677   2317]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.93    194969
           1       0.68      0.61      0.64     53592
           2       0.14      0.74      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.75      0.60    251700
weighted avg       0.88      0.85      0.86    251700


Global Accuracy: 0.8483
Total evaluation time: 2.8411s
Test Loss: 0.4152
Testing configuration: batch_size=512, num_epochs=10, learning_rate=0.0001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/10, Train Loss: 0.7103, Val Loss: 0.4897
Epoch 2/10, Train Loss: 0.6227, Val Loss: 0.4552
Epoch 3/10, Train Loss: 0.5990, Val Loss: 0.4397
Epoch 4/10, Train Loss: 0.5855, Val Loss: 0.4301
Epoch 5/10, Train Loss: 0.5748, Val Loss: 0.4299
Epoch 6/10, Train Loss: 0.5663, Val Loss: 0.4173
Epoch 7/10, Train Loss: 0.5588, Val Loss: 0.3968
Epoch 8/10, Train Loss: 0.5524, Val Loss: 0.4145
Epoch 9/10, Train Loss: 0.5457, Val Loss: 0.4080
Epoch 10/10, Train Loss: 0.5401, Val Loss: 0.3891
Total training time: 209.6907s

Confusion Matrix:
[[179058  14495   1416]
 [  8533  32948  12111]
 [   142    647   2350]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.69      0.61      0.65     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8516
Total evaluation time: 2.8895s
Test Loss: 0.3911
Testing configuration: batch_size=512, num_epochs=10, learning_rate=0.0001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/10, Train Loss: 0.6639, Val Loss: 0.4725
Epoch 2/10, Train Loss: 0.5929, Val Loss: 0.4487
Epoch 3/10, Train Loss: 0.5728, Val Loss: 0.4302
Epoch 4/10, Train Loss: 0.5592, Val Loss: 0.4307
Epoch 5/10, Train Loss: 0.5480, Val Loss: 0.4151
Epoch 6/10, Train Loss: 0.5389, Val Loss: 0.4017
Epoch 7/10, Train Loss: 0.5304, Val Loss: 0.3924
Epoch 8/10, Train Loss: 0.5234, Val Loss: 0.3949
Epoch 9/10, Train Loss: 0.5172, Val Loss: 0.3917
Epoch 10/10, Train Loss: 0.5114, Val Loss: 0.3786
Total training time: 211.0923s

Confusion Matrix:
[[179692  13346   1931]
 [  8812  32805  11975]
 [   142    624   2373]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.70      0.61      0.65     53592
           2       0.15      0.76      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8537
Total evaluation time: 2.8900s
Test Loss: 0.3806
Testing configuration: batch_size=512, num_epochs=20, learning_rate=0.001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/20, Train Loss: 0.6345, Val Loss: 0.4357
Epoch 2/20, Train Loss: 0.5704, Val Loss: 0.4034
Epoch 3/20, Train Loss: 0.5524, Val Loss: 0.3659
Epoch 4/20, Train Loss: 0.5469, Val Loss: 0.3833
Epoch 5/20, Train Loss: 0.5421, Val Loss: 0.4014
Epoch 6/20, Train Loss: 0.5387, Val Loss: 0.3632
Epoch 7/20, Train Loss: 0.5366, Val Loss: 0.3551
Epoch 8/20, Train Loss: 0.5347, Val Loss: 0.3827
Epoch 9/20, Train Loss: 0.5323, Val Loss: 0.3727
Epoch 10/20, Train Loss: 0.5314, Val Loss: 0.3367
Epoch 11/20, Train Loss: 0.5300, Val Loss: 0.3913
Epoch 12/20, Train Loss: 0.5288, Val Loss: 0.3521
Epoch 13/20, Train Loss: 0.5278, Val Loss: 0.3769
Epoch 14/20, Train Loss: 0.5267, Val Loss: 0.3530
Epoch 15/20, Train Loss: 0.5267, Val Loss: 0.3738
Epoch 16/20, Train Loss: 0.5257, Val Loss: 0.3688
Epoch 17/20, Train Loss: 0.5252, Val Loss: 0.3479
Epoch 18/20, Train Loss: 0.5244, Val Loss: 0.3943
Epoch 19/20, Train Loss: 0.5240, Val Loss: 0.3945
Epoch 20/20, Train Loss: 0.5228, Val Loss: 0.3580
Total training time: 413.7778s

Confusion Matrix:
[[181993  11754   1222]
 [  9033  32647  11912]
 [   150    625   2364]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.73      0.61      0.66     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8622
Total evaluation time: 3.0536s
Test Loss: 0.3598
Testing configuration: batch_size=512, num_epochs=20, learning_rate=0.001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/20, Train Loss: 0.5998, Val Loss: 0.3951
Epoch 2/20, Train Loss: 0.5408, Val Loss: 0.3747
Epoch 3/20, Train Loss: 0.5239, Val Loss: 0.3812
Epoch 4/20, Train Loss: 0.5156, Val Loss: 0.3698
Epoch 5/20, Train Loss: 0.5096, Val Loss: 0.3734
Epoch 6/20, Train Loss: 0.5067, Val Loss: 0.3425
Epoch 7/20, Train Loss: 0.5036, Val Loss: 0.3515
Epoch 8/20, Train Loss: 0.5021, Val Loss: 0.3352
Epoch 9/20, Train Loss: 0.5004, Val Loss: 0.3677
Epoch 10/20, Train Loss: 0.4987, Val Loss: 0.3566
Epoch 11/20, Train Loss: 0.4972, Val Loss: 0.3925
Epoch 12/20, Train Loss: 0.4957, Val Loss: 0.3781
Epoch 13/20, Train Loss: 0.4946, Val Loss: 0.3399
Epoch 14/20, Train Loss: 0.4936, Val Loss: 0.3689
Epoch 15/20, Train Loss: 0.4927, Val Loss: 0.3941
Epoch 16/20, Train Loss: 0.4919, Val Loss: 0.3576
Epoch 17/20, Train Loss: 0.4904, Val Loss: 0.3575
Epoch 18/20, Train Loss: 0.4897, Val Loss: 0.3793
Epoch 19/20, Train Loss: 0.4894, Val Loss: 0.3667
Epoch 20/20, Train Loss: 0.4887, Val Loss: 0.3460
Total training time: 413.9180s

Confusion Matrix:
[[180485  12774   1710]
 [  8544  33676  11372]
 [   140    633   2366]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.72      0.63      0.67     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8603
Total evaluation time: 3.0536s
Test Loss: 0.3478
Testing configuration: batch_size=512, num_epochs=20, learning_rate=0.001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/20, Train Loss: 0.5752, Val Loss: 0.4160
Epoch 2/20, Train Loss: 0.5182, Val Loss: 0.3862
Epoch 3/20, Train Loss: 0.4991, Val Loss: 0.3702
Epoch 4/20, Train Loss: 0.4901, Val Loss: 0.3513
Epoch 5/20, Train Loss: 0.4831, Val Loss: 0.3429
Epoch 6/20, Train Loss: 0.4793, Val Loss: 0.3775
Epoch 7/20, Train Loss: 0.4750, Val Loss: 0.3682
Epoch 8/20, Train Loss: 0.4714, Val Loss: 0.3579
Epoch 9/20, Train Loss: 0.4688, Val Loss: 0.3628
Epoch 10/20, Train Loss: 0.4662, Val Loss: 0.3572
Epoch 11/20, Train Loss: 0.4642, Val Loss: 0.3699
Epoch 12/20, Train Loss: 0.4631, Val Loss: 0.3696
Epoch 13/20, Train Loss: 0.4606, Val Loss: 0.3507
Epoch 14/20, Train Loss: 0.4595, Val Loss: 0.3837
Epoch 15/20, Train Loss: 0.4576, Val Loss: 0.3304
Epoch 16/20, Train Loss: 0.4560, Val Loss: 0.3935
Epoch 17/20, Train Loss: 0.4554, Val Loss: 0.3352
Epoch 18/20, Train Loss: 0.4544, Val Loss: 0.3518
Epoch 19/20, Train Loss: 0.4526, Val Loss: 0.3435
Epoch 20/20, Train Loss: 0.4523, Val Loss: 0.3482
Total training time: 421.6673s

Confusion Matrix:
[[178551  13549   2869]
 [  8038  35861   9693]
 [   120    693   2326]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.72      0.67      0.69     53592
           2       0.16      0.74      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.78      0.63    251700
weighted avg       0.90      0.86      0.88    251700


Global Accuracy: 0.8611
Total evaluation time: 3.0540s
Test Loss: 0.3496
Testing configuration: batch_size=512, num_epochs=20, learning_rate=0.0001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/20, Train Loss: 0.7778, Val Loss: 0.4944
Epoch 2/20, Train Loss: 0.6630, Val Loss: 0.4776
Epoch 3/20, Train Loss: 0.6356, Val Loss: 0.4665
Epoch 4/20, Train Loss: 0.6186, Val Loss: 0.4499
Epoch 5/20, Train Loss: 0.6063, Val Loss: 0.4359
Epoch 6/20, Train Loss: 0.5962, Val Loss: 0.4164
Epoch 7/20, Train Loss: 0.5883, Val Loss: 0.4257
Epoch 8/20, Train Loss: 0.5822, Val Loss: 0.4057
Epoch 9/20, Train Loss: 0.5762, Val Loss: 0.4051
Epoch 10/20, Train Loss: 0.5717, Val Loss: 0.4014
Epoch 11/20, Train Loss: 0.5675, Val Loss: 0.4038
Epoch 12/20, Train Loss: 0.5632, Val Loss: 0.3841
Epoch 13/20, Train Loss: 0.5603, Val Loss: 0.3982
Epoch 14/20, Train Loss: 0.5572, Val Loss: 0.3918
Epoch 15/20, Train Loss: 0.5545, Val Loss: 0.3934
Epoch 16/20, Train Loss: 0.5515, Val Loss: 0.3915
Epoch 17/20, Train Loss: 0.5496, Val Loss: 0.3814
Epoch 18/20, Train Loss: 0.5478, Val Loss: 0.4015
Epoch 19/20, Train Loss: 0.5458, Val Loss: 0.3927
Epoch 20/20, Train Loss: 0.5443, Val Loss: 0.3889
Total training time: 415.4541s

Confusion Matrix:
[[178289  15016   1664]
 [  7984  32857  12751]
 [   137    627   2375]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.68      0.61      0.64     53592
           2       0.14      0.76      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.76      0.61    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8483
Total evaluation time: 3.0382s
Test Loss: 0.3913
Testing configuration: batch_size=512, num_epochs=20, learning_rate=0.0001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/20, Train Loss: 0.7150, Val Loss: 0.4828
Epoch 2/20, Train Loss: 0.6226, Val Loss: 0.4541
Epoch 3/20, Train Loss: 0.5999, Val Loss: 0.4362
Epoch 4/20, Train Loss: 0.5855, Val Loss: 0.4288
Epoch 5/20, Train Loss: 0.5742, Val Loss: 0.4254
Epoch 6/20, Train Loss: 0.5649, Val Loss: 0.3987
Epoch 7/20, Train Loss: 0.5564, Val Loss: 0.4116
Epoch 8/20, Train Loss: 0.5490, Val Loss: 0.4068
Epoch 9/20, Train Loss: 0.5426, Val Loss: 0.3814
Epoch 10/20, Train Loss: 0.5377, Val Loss: 0.3932
Epoch 11/20, Train Loss: 0.5327, Val Loss: 0.3761
Epoch 12/20, Train Loss: 0.5291, Val Loss: 0.3807
Epoch 13/20, Train Loss: 0.5252, Val Loss: 0.3782
Epoch 14/20, Train Loss: 0.5219, Val Loss: 0.3744
Epoch 15/20, Train Loss: 0.5186, Val Loss: 0.3888
Epoch 16/20, Train Loss: 0.5157, Val Loss: 0.3744
Epoch 17/20, Train Loss: 0.5128, Val Loss: 0.3709
Epoch 18/20, Train Loss: 0.5104, Val Loss: 0.3768
Epoch 19/20, Train Loss: 0.5081, Val Loss: 0.3772
Epoch 20/20, Train Loss: 0.5063, Val Loss: 0.3607
Total training time: 411.8856s

Confusion Matrix:
[[180521  12720   1728]
 [  8590  32872  12130]
 [   143    612   2384]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.71      0.61      0.66     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.60      0.77      0.61    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8573
Total evaluation time: 3.0486s
Test Loss: 0.3625
Testing configuration: batch_size=512, num_epochs=20, learning_rate=0.0001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/20, Train Loss: 0.6626, Val Loss: 0.4772
Epoch 2/20, Train Loss: 0.5909, Val Loss: 0.4476
Epoch 3/20, Train Loss: 0.5705, Val Loss: 0.4188
Epoch 4/20, Train Loss: 0.5567, Val Loss: 0.4221
Epoch 5/20, Train Loss: 0.5460, Val Loss: 0.4169
Epoch 6/20, Train Loss: 0.5372, Val Loss: 0.4125
Epoch 7/20, Train Loss: 0.5294, Val Loss: 0.3987
Epoch 8/20, Train Loss: 0.5224, Val Loss: 0.3768
Epoch 9/20, Train Loss: 0.5160, Val Loss: 0.3863
Epoch 10/20, Train Loss: 0.5101, Val Loss: 0.3863
Epoch 11/20, Train Loss: 0.5050, Val Loss: 0.3801
Epoch 12/20, Train Loss: 0.5002, Val Loss: 0.3831
Epoch 13/20, Train Loss: 0.4950, Val Loss: 0.3795
Epoch 14/20, Train Loss: 0.4909, Val Loss: 0.3581
Epoch 15/20, Train Loss: 0.4869, Val Loss: 0.3572
Epoch 16/20, Train Loss: 0.4831, Val Loss: 0.3637
Epoch 17/20, Train Loss: 0.4797, Val Loss: 0.3745
Epoch 18/20, Train Loss: 0.4771, Val Loss: 0.3504
Epoch 19/20, Train Loss: 0.4739, Val Loss: 0.3558
Epoch 20/20, Train Loss: 0.4718, Val Loss: 0.3572
Total training time: 418.4851s

Confusion Matrix:
[[179796  12728   2445]
 [  8414  33951  11227]
 [   131    642   2366]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.92      0.94    194969
           1       0.72      0.63      0.67     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8586
Total evaluation time: 3.0503s
Test Loss: 0.3592
Testing configuration: batch_size=512, num_epochs=30, learning_rate=0.001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/30, Train Loss: 0.6318, Val Loss: 0.4325
Epoch 2/30, Train Loss: 0.5660, Val Loss: 0.3604
Epoch 3/30, Train Loss: 0.5515, Val Loss: 0.3734
Epoch 4/30, Train Loss: 0.5439, Val Loss: 0.3952
Epoch 5/30, Train Loss: 0.5403, Val Loss: 0.3559
Epoch 6/30, Train Loss: 0.5372, Val Loss: 0.3832
Epoch 7/30, Train Loss: 0.5347, Val Loss: 0.3717
Epoch 8/30, Train Loss: 0.5320, Val Loss: 0.4109
Epoch 9/30, Train Loss: 0.5306, Val Loss: 0.3644
Epoch 10/30, Train Loss: 0.5287, Val Loss: 0.4016
Epoch 11/30, Train Loss: 0.5281, Val Loss: 0.3974
Epoch 12/30, Train Loss: 0.5281, Val Loss: 0.3916
Epoch 13/30, Train Loss: 0.5275, Val Loss: 0.3535
Epoch 14/30, Train Loss: 0.5253, Val Loss: 0.3713
Epoch 15/30, Train Loss: 0.5253, Val Loss: 0.3667
Epoch 16/30, Train Loss: 0.5240, Val Loss: 0.3646
Epoch 17/30, Train Loss: 0.5235, Val Loss: 0.3561
Epoch 18/30, Train Loss: 0.5231, Val Loss: 0.3583
Epoch 19/30, Train Loss: 0.5226, Val Loss: 0.3492
Epoch 20/30, Train Loss: 0.5215, Val Loss: 0.3703
Epoch 21/30, Train Loss: 0.5210, Val Loss: 0.3776
Epoch 22/30, Train Loss: 0.5210, Val Loss: 0.3774
Epoch 23/30, Train Loss: 0.5195, Val Loss: 0.3747
Epoch 24/30, Train Loss: 0.5193, Val Loss: 0.4175
Epoch 25/30, Train Loss: 0.5190, Val Loss: 0.3703
Epoch 26/30, Train Loss: 0.5195, Val Loss: 0.3709
Epoch 27/30, Train Loss: 0.5195, Val Loss: 0.3798
Epoch 28/30, Train Loss: 0.5189, Val Loss: 0.3809
Epoch 29/30, Train Loss: 0.5186, Val Loss: 0.3540
Epoch 30/30, Train Loss: 0.5182, Val Loss: 0.3884
Total training time: 621.1690s

Confusion Matrix:
[[178105  15338   1526]
 [  7962  33173  12457]
 [   135    606   2398]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.68      0.62      0.65     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.59      0.77      0.61    251700
weighted avg       0.89      0.85      0.86    251700


Global Accuracy: 0.8489
Total evaluation time: 3.0644s
Test Loss: 0.3904
Testing configuration: batch_size=512, num_epochs=30, learning_rate=0.001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/30, Train Loss: 0.5969, Val Loss: 0.4267
Epoch 2/30, Train Loss: 0.5384, Val Loss: 0.3646
Epoch 3/30, Train Loss: 0.5233, Val Loss: 0.4220
Epoch 4/30, Train Loss: 0.5148, Val Loss: 0.3680
Epoch 5/30, Train Loss: 0.5104, Val Loss: 0.3599
Epoch 6/30, Train Loss: 0.5060, Val Loss: 0.3600
Epoch 7/30, Train Loss: 0.5039, Val Loss: 0.3245
Epoch 8/30, Train Loss: 0.5030, Val Loss: 0.3463
Epoch 9/30, Train Loss: 0.4999, Val Loss: 0.3505
Epoch 10/30, Train Loss: 0.4985, Val Loss: 0.3542
Epoch 11/30, Train Loss: 0.4971, Val Loss: 0.3350
Epoch 12/30, Train Loss: 0.4956, Val Loss: 0.3461
Epoch 13/30, Train Loss: 0.4944, Val Loss: 0.4064
Epoch 14/30, Train Loss: 0.4931, Val Loss: 0.3994
Epoch 15/30, Train Loss: 0.4935, Val Loss: 0.3719
Epoch 16/30, Train Loss: 0.4922, Val Loss: 0.3531
Epoch 17/30, Train Loss: 0.4919, Val Loss: 0.3501
Epoch 18/30, Train Loss: 0.4902, Val Loss: 0.3968
Epoch 19/30, Train Loss: 0.4898, Val Loss: 0.3432
Epoch 20/30, Train Loss: 0.4887, Val Loss: 0.3316
Epoch 21/30, Train Loss: 0.4882, Val Loss: 0.3598
Epoch 22/30, Train Loss: 0.4878, Val Loss: 0.3469
Epoch 23/30, Train Loss: 0.4866, Val Loss: 0.3479
Epoch 24/30, Train Loss: 0.4864, Val Loss: 0.3508
Epoch 25/30, Train Loss: 0.4858, Val Loss: 0.3446
Epoch 26/30, Train Loss: 0.4860, Val Loss: 0.3726
Epoch 27/30, Train Loss: 0.4850, Val Loss: 0.3610
Epoch 28/30, Train Loss: 0.4842, Val Loss: 0.3471
Epoch 29/30, Train Loss: 0.4840, Val Loss: 0.3359
Epoch 30/30, Train Loss: 0.4838, Val Loss: 0.3499
Total training time: 615.1360s

Confusion Matrix:
[[179938  13081   1950]
 [  8318  34132  11142]
 [   137    646   2356]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.71      0.64      0.67     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8599
Total evaluation time: 3.0531s
Test Loss: 0.3516
Testing configuration: batch_size=512, num_epochs=30, learning_rate=0.001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/30, Train Loss: 0.5745, Val Loss: 0.3549
Epoch 2/30, Train Loss: 0.5179, Val Loss: 0.3841
Epoch 3/30, Train Loss: 0.4995, Val Loss: 0.3515
Epoch 4/30, Train Loss: 0.4899, Val Loss: 0.3706
Epoch 5/30, Train Loss: 0.4829, Val Loss: 0.3646
Epoch 6/30, Train Loss: 0.4789, Val Loss: 0.3396
Epoch 7/30, Train Loss: 0.4749, Val Loss: 0.3615
Epoch 8/30, Train Loss: 0.4710, Val Loss: 0.3705
Epoch 9/30, Train Loss: 0.4690, Val Loss: 0.3676
Epoch 10/30, Train Loss: 0.4669, Val Loss: 0.3496
Epoch 11/30, Train Loss: 0.4644, Val Loss: 0.3604
Epoch 12/30, Train Loss: 0.4622, Val Loss: 0.3575
Epoch 13/30, Train Loss: 0.4607, Val Loss: 0.3494
Epoch 14/30, Train Loss: 0.4593, Val Loss: 0.3620
Epoch 15/30, Train Loss: 0.4577, Val Loss: 0.3351
Epoch 16/30, Train Loss: 0.4565, Val Loss: 0.3368
Epoch 17/30, Train Loss: 0.4557, Val Loss: 0.3562
Epoch 18/30, Train Loss: 0.4544, Val Loss: 0.3678
Epoch 19/30, Train Loss: 0.4532, Val Loss: 0.3699
Epoch 20/30, Train Loss: 0.4519, Val Loss: 0.3638
Epoch 21/30, Train Loss: 0.4514, Val Loss: 0.3579
Epoch 22/30, Train Loss: 0.4496, Val Loss: 0.3554
Epoch 23/30, Train Loss: 0.4495, Val Loss: 0.3469
Epoch 24/30, Train Loss: 0.4480, Val Loss: 0.3230
Epoch 25/30, Train Loss: 0.4478, Val Loss: 0.3374
Epoch 26/30, Train Loss: 0.4459, Val Loss: 0.3190
Epoch 27/30, Train Loss: 0.4460, Val Loss: 0.3228
Epoch 28/30, Train Loss: 0.4452, Val Loss: 0.3428
Epoch 29/30, Train Loss: 0.4445, Val Loss: 0.3547
Epoch 30/30, Train Loss: 0.4436, Val Loss: 0.3503
Total training time: 631.7540s

Confusion Matrix:
[[178647  13039   3283]
 [  8244  35285  10063]
 [   117    650   2372]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.72      0.66      0.69     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.78      0.63    251700
weighted avg       0.90      0.86      0.87    251700


Global Accuracy: 0.8594
Total evaluation time: 3.0758s
Test Loss: 0.3519
Testing configuration: batch_size=512, num_epochs=30, learning_rate=0.0001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/30, Train Loss: 0.7654, Val Loss: 0.5052
Epoch 2/30, Train Loss: 0.6604, Val Loss: 0.4596
Epoch 3/30, Train Loss: 0.6337, Val Loss: 0.4673
Epoch 4/30, Train Loss: 0.6174, Val Loss: 0.4448
Epoch 5/30, Train Loss: 0.6063, Val Loss: 0.4457
Epoch 6/30, Train Loss: 0.5979, Val Loss: 0.4383
Epoch 7/30, Train Loss: 0.5915, Val Loss: 0.4307
Epoch 8/30, Train Loss: 0.5851, Val Loss: 0.4240
Epoch 9/30, Train Loss: 0.5795, Val Loss: 0.4039
Epoch 10/30, Train Loss: 0.5738, Val Loss: 0.4016
Epoch 11/30, Train Loss: 0.5685, Val Loss: 0.3923
Epoch 12/30, Train Loss: 0.5635, Val Loss: 0.3938
Epoch 13/30, Train Loss: 0.5590, Val Loss: 0.3916
Epoch 14/30, Train Loss: 0.5553, Val Loss: 0.3765
Epoch 15/30, Train Loss: 0.5524, Val Loss: 0.3932
Epoch 16/30, Train Loss: 0.5494, Val Loss: 0.3856
Epoch 17/30, Train Loss: 0.5464, Val Loss: 0.3715
Epoch 18/30, Train Loss: 0.5445, Val Loss: 0.3799
Epoch 19/30, Train Loss: 0.5421, Val Loss: 0.3730
Epoch 20/30, Train Loss: 0.5404, Val Loss: 0.3804
Epoch 21/30, Train Loss: 0.5390, Val Loss: 0.3717
Epoch 22/30, Train Loss: 0.5377, Val Loss: 0.3616
Epoch 23/30, Train Loss: 0.5360, Val Loss: 0.3716
Epoch 24/30, Train Loss: 0.5350, Val Loss: 0.3690
Epoch 25/30, Train Loss: 0.5336, Val Loss: 0.3735
Epoch 26/30, Train Loss: 0.5328, Val Loss: 0.3840
Epoch 27/30, Train Loss: 0.5321, Val Loss: 0.3782
Epoch 28/30, Train Loss: 0.5312, Val Loss: 0.3696
Epoch 29/30, Train Loss: 0.5308, Val Loss: 0.3649
Epoch 30/30, Train Loss: 0.5300, Val Loss: 0.3756
Total training time: 620.6089s

Confusion Matrix:
[[178520  14923   1526]
 [  8008  33505  12079]
 [   135    642   2362]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.68      0.63      0.65     53592
           2       0.15      0.75      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.76      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8518
Total evaluation time: 3.0524s
Test Loss: 0.3775
Testing configuration: batch_size=512, num_epochs=30, learning_rate=0.0001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/30, Train Loss: 0.7145, Val Loss: 0.4815
Epoch 2/30, Train Loss: 0.6232, Val Loss: 0.4485
Epoch 3/30, Train Loss: 0.5992, Val Loss: 0.4315
Epoch 4/30, Train Loss: 0.5847, Val Loss: 0.4323
Epoch 5/30, Train Loss: 0.5736, Val Loss: 0.4207
Epoch 6/30, Train Loss: 0.5637, Val Loss: 0.4239
Epoch 7/30, Train Loss: 0.5555, Val Loss: 0.4018
Epoch 8/30, Train Loss: 0.5479, Val Loss: 0.3950
Epoch 9/30, Train Loss: 0.5416, Val Loss: 0.3798
Epoch 10/30, Train Loss: 0.5361, Val Loss: 0.3821
Epoch 11/30, Train Loss: 0.5313, Val Loss: 0.3843
Epoch 12/30, Train Loss: 0.5268, Val Loss: 0.3822
Epoch 13/30, Train Loss: 0.5225, Val Loss: 0.3810
Epoch 14/30, Train Loss: 0.5184, Val Loss: 0.3722
Epoch 15/30, Train Loss: 0.5158, Val Loss: 0.3826
Epoch 16/30, Train Loss: 0.5129, Val Loss: 0.3560
Epoch 17/30, Train Loss: 0.5106, Val Loss: 0.3632
Epoch 18/30, Train Loss: 0.5082, Val Loss: 0.3576
Epoch 19/30, Train Loss: 0.5065, Val Loss: 0.3628
Epoch 20/30, Train Loss: 0.5044, Val Loss: 0.3630
Epoch 21/30, Train Loss: 0.5031, Val Loss: 0.3610
Epoch 22/30, Train Loss: 0.5019, Val Loss: 0.3651
Epoch 23/30, Train Loss: 0.5003, Val Loss: 0.3639
Epoch 24/30, Train Loss: 0.4989, Val Loss: 0.3564
Epoch 25/30, Train Loss: 0.4978, Val Loss: 0.3575
Epoch 26/30, Train Loss: 0.4969, Val Loss: 0.3542
Epoch 27/30, Train Loss: 0.4959, Val Loss: 0.3629
Epoch 28/30, Train Loss: 0.4950, Val Loss: 0.3621
Epoch 29/30, Train Loss: 0.4942, Val Loss: 0.3594
Epoch 30/30, Train Loss: 0.4933, Val Loss: 0.3543
Total training time: 618.9934s

Confusion Matrix:
[[181276  11827   1866]
 [  8766  32951  11875]
 [   136    603   2400]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.73      0.61      0.67     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.62    251700
weighted avg       0.89      0.86      0.87    251700


Global Accuracy: 0.8607
Total evaluation time: 3.0437s
Test Loss: 0.3562
Testing configuration: batch_size=512, num_epochs=30, learning_rate=0.0001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/30, Train Loss: 0.6651, Val Loss: 0.4452
Epoch 2/30, Train Loss: 0.5920, Val Loss: 0.4503
Epoch 3/30, Train Loss: 0.5717, Val Loss: 0.4289
Epoch 4/30, Train Loss: 0.5576, Val Loss: 0.4306
Epoch 5/30, Train Loss: 0.5466, Val Loss: 0.4089
Epoch 6/30, Train Loss: 0.5371, Val Loss: 0.4041
Epoch 7/30, Train Loss: 0.5289, Val Loss: 0.3975
Epoch 8/30, Train Loss: 0.5213, Val Loss: 0.3921
Epoch 9/30, Train Loss: 0.5147, Val Loss: 0.3771
Epoch 10/30, Train Loss: 0.5089, Val Loss: 0.3888
Epoch 11/30, Train Loss: 0.5036, Val Loss: 0.3704
Epoch 12/30, Train Loss: 0.4981, Val Loss: 0.3624
Epoch 13/30, Train Loss: 0.4940, Val Loss: 0.3777
Epoch 14/30, Train Loss: 0.4895, Val Loss: 0.3649
Epoch 15/30, Train Loss: 0.4861, Val Loss: 0.3620
Epoch 16/30, Train Loss: 0.4829, Val Loss: 0.3597
Epoch 17/30, Train Loss: 0.4800, Val Loss: 0.3575
Epoch 18/30, Train Loss: 0.4773, Val Loss: 0.3560
Epoch 19/30, Train Loss: 0.4748, Val Loss: 0.3723
Epoch 20/30, Train Loss: 0.4730, Val Loss: 0.3609
Epoch 21/30, Train Loss: 0.4707, Val Loss: 0.3601
Epoch 22/30, Train Loss: 0.4685, Val Loss: 0.3682
Epoch 23/30, Train Loss: 0.4669, Val Loss: 0.3601
Epoch 24/30, Train Loss: 0.4652, Val Loss: 0.3582
Epoch 25/30, Train Loss: 0.4639, Val Loss: 0.3666
Epoch 26/30, Train Loss: 0.4624, Val Loss: 0.3640
Epoch 27/30, Train Loss: 0.4613, Val Loss: 0.3443
Epoch 28/30, Train Loss: 0.4598, Val Loss: 0.3635
Epoch 29/30, Train Loss: 0.4588, Val Loss: 0.3526
Epoch 30/30, Train Loss: 0.4575, Val Loss: 0.3678
Total training time: 628.6257s

Confusion Matrix:
[[177475  14400   3094]
 [  7761  33989  11842]
 [   112    603   2424]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.69      0.63      0.66     53592
           2       0.14      0.77      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.77      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8498
Total evaluation time: 3.0767s
Test Loss: 0.3699
Best configuration: {'num_epochs': 20, 'learning_rate': 0.001, 'hidden_sizes': [128, 64, 32], 'dropout': 0.5, 'batch_size': 512} with accuracy: 0.8622
