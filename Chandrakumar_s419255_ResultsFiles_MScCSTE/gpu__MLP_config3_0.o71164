CUDA_VISIBLE_DEVICES=GPU-415dcdca-40f2-6526-4804-510e0422b7ad
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pandas in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.2.2)
Requirement already satisfied: pytz>=2020.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2.9.0.post0)
Requirement already satisfied: numpy>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (1.26.4)
Requirement already satisfied: tzdata>=2022.7 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from pandas) (2024.1)
Requirement already satisfied: six>=1.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: imblearn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.0)
Requirement already satisfied: imbalanced-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imblearn) (0.12.3)
Requirement already satisfied: scikit-learn>=1.0.2 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.5.0)
Requirement already satisfied: scipy>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.13.1)
Requirement already satisfied: numpy>=1.17.3 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.26.4)
Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.5.0)
Requirement already satisfied: joblib>=1.1.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.4.2)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (2.3.1)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.11.3)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (3.6.0)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2024.6.0)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (1.10.1)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch) (2.8.4)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.20.5)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (2.3.1)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (4.12.1)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch) (1.2.1)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: scikit-learn in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: scipy>=1.6.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.13.1)
Requirement already satisfied: numpy>=1.19.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.26.4)
Requirement already satisfied: joblib>=1.2.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (1.4.2)
Requirement already satisfied: threadpoolctl>=3.1.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scikit-learn) (3.5.0)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: numpy in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (1.26.4)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torchdiffeq in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (0.2.4)
Requirement already satisfied: torch>=1.5.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (2.3.1)
Requirement already satisfied: scipy>=1.4.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torchdiffeq) (1.13.1)
Requirement already satisfied: numpy<2.3,>=1.22.4 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.0.2.54)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (8.9.2.26)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.0.106)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: typing-extensions>=4.8.0 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (4.12.1)
Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.20.5)
Requirement already satisfied: filelock in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (3.6.0)
Requirement already satisfied: networkx in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.8.4)
Requirement already satisfied: jinja2 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.11.3)
Requirement already satisfied: sympy in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (1.10.1)
Requirement already satisfied: fsspec in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2024.6.0)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.3.1)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: triton==2.3.1 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (2.3.1)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (11.4.5.107)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (12.1.105)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from torch>=1.5.0->torchdiffeq) (10.3.2.106)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.5.0->torchdiffeq) (12.5.40)
Requirement already satisfied: MarkupSafe>=0.23 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from jinja2->torch>=1.5.0->torchdiffeq) (2.0.1)
Requirement already satisfied: mpmath>=0.19 in /mnt/beegfs/apps/software/Anaconda3/2022.10/lib/python3.9/site-packages (from sympy->torch>=1.5.0->torchdiffeq) (1.2.1)
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).
  from pandas.core.computation.check import NUMEXPR_INSTALLED
/mnt/beegfs/home/s419255/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
42
cuda
0h
Testing configuration: batch_size=512, num_epochs=50, learning_rate=0.001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/50, Train Loss: 0.6323, Val Loss: 0.4000
Epoch 2/50, Train Loss: 0.5680, Val Loss: 0.3687
Epoch 3/50, Train Loss: 0.5518, Val Loss: 0.4420
Epoch 4/50, Train Loss: 0.5457, Val Loss: 0.3889
Epoch 5/50, Train Loss: 0.5411, Val Loss: 0.3713
Epoch 6/50, Train Loss: 0.5379, Val Loss: 0.3767
Epoch 7/50, Train Loss: 0.5353, Val Loss: 0.3854
Epoch 8/50, Train Loss: 0.5336, Val Loss: 0.3787
Epoch 9/50, Train Loss: 0.5328, Val Loss: 0.3709
Epoch 10/50, Train Loss: 0.5308, Val Loss: 0.3811
Epoch 11/50, Train Loss: 0.5287, Val Loss: 0.3823
Epoch 12/50, Train Loss: 0.5277, Val Loss: 0.3447
Epoch 13/50, Train Loss: 0.5269, Val Loss: 0.3754
Epoch 14/50, Train Loss: 0.5258, Val Loss: 0.3841
Epoch 15/50, Train Loss: 0.5248, Val Loss: 0.3798
Epoch 16/50, Train Loss: 0.5242, Val Loss: 0.3960
Epoch 17/50, Train Loss: 0.5229, Val Loss: 0.3661
Epoch 18/50, Train Loss: 0.5218, Val Loss: 0.3508
Epoch 19/50, Train Loss: 0.5213, Val Loss: 0.3948
Epoch 20/50, Train Loss: 0.5212, Val Loss: 0.3573
Epoch 21/50, Train Loss: 0.5209, Val Loss: 0.3767
Epoch 22/50, Train Loss: 0.5197, Val Loss: 0.3648
Epoch 23/50, Train Loss: 0.5194, Val Loss: 0.3501
Epoch 24/50, Train Loss: 0.5189, Val Loss: 0.3598
Epoch 25/50, Train Loss: 0.5187, Val Loss: 0.3557
Epoch 26/50, Train Loss: 0.5175, Val Loss: 0.3774
Epoch 27/50, Train Loss: 0.5181, Val Loss: 0.3609
Epoch 28/50, Train Loss: 0.5173, Val Loss: 0.3553
Epoch 29/50, Train Loss: 0.5170, Val Loss: 0.3769
Epoch 30/50, Train Loss: 0.5167, Val Loss: 0.3827
Epoch 31/50, Train Loss: 0.5165, Val Loss: 0.3500
Epoch 32/50, Train Loss: 0.5162, Val Loss: 0.3665
Epoch 33/50, Train Loss: 0.5157, Val Loss: 0.3710
Epoch 34/50, Train Loss: 0.5166, Val Loss: 0.3664
Epoch 35/50, Train Loss: 0.5160, Val Loss: 0.3523
Epoch 36/50, Train Loss: 0.5149, Val Loss: 0.3450
Epoch 37/50, Train Loss: 0.5156, Val Loss: 0.3897
Epoch 38/50, Train Loss: 0.5152, Val Loss: 0.4044
Epoch 39/50, Train Loss: 0.5147, Val Loss: 0.3598
Epoch 40/50, Train Loss: 0.5140, Val Loss: 0.3747
Epoch 41/50, Train Loss: 0.5136, Val Loss: 0.3683
Epoch 42/50, Train Loss: 0.5133, Val Loss: 0.3489
Epoch 43/50, Train Loss: 0.5131, Val Loss: 0.3785
Epoch 44/50, Train Loss: 0.5135, Val Loss: 0.3640
Epoch 45/50, Train Loss: 0.5128, Val Loss: 0.3474
Epoch 46/50, Train Loss: 0.5127, Val Loss: 0.3750
Epoch 47/50, Train Loss: 0.5119, Val Loss: 0.3584
Epoch 48/50, Train Loss: 0.5122, Val Loss: 0.3834
Epoch 49/50, Train Loss: 0.5122, Val Loss: 0.3408
Epoch 50/50, Train Loss: 0.5116, Val Loss: 0.3557
Total training time: 1041.2164s

Confusion Matrix:
[[181410  12495   1064]
 [  8970  33911  10711]
 [   151    712   2276]]

Classification Report:
              precision    recall  f1-score   support

           0       0.95      0.93      0.94    194969
           1       0.72      0.63      0.67     53592
           2       0.16      0.73      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.76      0.63    251700
weighted avg       0.89      0.86      0.88    251700


Global Accuracy: 0.8645
Total evaluation time: 3.0652s
Test Loss: 0.3575
Testing configuration: batch_size=512, num_epochs=50, learning_rate=0.001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/50, Train Loss: 0.5983, Val Loss: 0.3992
Epoch 2/50, Train Loss: 0.5389, Val Loss: 0.3691
Epoch 3/50, Train Loss: 0.5209, Val Loss: 0.4128
Epoch 4/50, Train Loss: 0.5134, Val Loss: 0.3987
Epoch 5/50, Train Loss: 0.5089, Val Loss: 0.3731
Epoch 6/50, Train Loss: 0.5050, Val Loss: 0.3577
Epoch 7/50, Train Loss: 0.5026, Val Loss: 0.3785
Epoch 8/50, Train Loss: 0.5003, Val Loss: 0.3707
Epoch 9/50, Train Loss: 0.4985, Val Loss: 0.3875
Epoch 10/50, Train Loss: 0.4976, Val Loss: 0.3780
Epoch 11/50, Train Loss: 0.4962, Val Loss: 0.3565
Epoch 12/50, Train Loss: 0.4947, Val Loss: 0.3636
Epoch 13/50, Train Loss: 0.4942, Val Loss: 0.3387
Epoch 14/50, Train Loss: 0.4934, Val Loss: 0.3641
Epoch 15/50, Train Loss: 0.4918, Val Loss: 0.3533
Epoch 16/50, Train Loss: 0.4909, Val Loss: 0.3609
Epoch 17/50, Train Loss: 0.4901, Val Loss: 0.3564
Epoch 18/50, Train Loss: 0.4895, Val Loss: 0.3773
Epoch 19/50, Train Loss: 0.4889, Val Loss: 0.3478
Epoch 20/50, Train Loss: 0.4886, Val Loss: 0.3604
Epoch 21/50, Train Loss: 0.4878, Val Loss: 0.3490
Epoch 22/50, Train Loss: 0.4876, Val Loss: 0.3382
Epoch 23/50, Train Loss: 0.4863, Val Loss: 0.3578
Epoch 24/50, Train Loss: 0.4856, Val Loss: 0.3874
Epoch 25/50, Train Loss: 0.4850, Val Loss: 0.3641
Epoch 26/50, Train Loss: 0.4843, Val Loss: 0.3413
Epoch 27/50, Train Loss: 0.4834, Val Loss: 0.3529
Epoch 28/50, Train Loss: 0.4836, Val Loss: 0.3428
Epoch 29/50, Train Loss: 0.4834, Val Loss: 0.3577
Epoch 30/50, Train Loss: 0.4823, Val Loss: 0.3438
Epoch 31/50, Train Loss: 0.4817, Val Loss: 0.3620
Epoch 32/50, Train Loss: 0.4816, Val Loss: 0.3562
Epoch 33/50, Train Loss: 0.4807, Val Loss: 0.3807
Epoch 34/50, Train Loss: 0.4803, Val Loss: 0.3633
Epoch 35/50, Train Loss: 0.4800, Val Loss: 0.3545
Epoch 36/50, Train Loss: 0.4794, Val Loss: 0.3622
Epoch 37/50, Train Loss: 0.4794, Val Loss: 0.3398
Epoch 38/50, Train Loss: 0.4792, Val Loss: 0.3436
Epoch 39/50, Train Loss: 0.4787, Val Loss: 0.3353
Epoch 40/50, Train Loss: 0.4788, Val Loss: 0.3675
Epoch 41/50, Train Loss: 0.4784, Val Loss: 0.3618
Epoch 42/50, Train Loss: 0.4778, Val Loss: 0.3721
Epoch 43/50, Train Loss: 0.4778, Val Loss: 0.3413
Epoch 44/50, Train Loss: 0.4779, Val Loss: 0.3444
Epoch 45/50, Train Loss: 0.4768, Val Loss: 0.3388
Epoch 46/50, Train Loss: 0.4769, Val Loss: 0.3449
Epoch 47/50, Train Loss: 0.4767, Val Loss: 0.3659
Epoch 48/50, Train Loss: 0.4765, Val Loss: 0.3348
Epoch 49/50, Train Loss: 0.4763, Val Loss: 0.3564
Epoch 50/50, Train Loss: 0.4759, Val Loss: 0.3675
Total training time: 1036.1934s

Confusion Matrix:
[[177615  15071   2283]
 [  7738  34738  11116]
 [   128    631   2380]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.69      0.65      0.67     53592
           2       0.15      0.76      0.25      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.77      0.62    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8531
Total evaluation time: 3.0936s
Test Loss: 0.3690
Testing configuration: batch_size=512, num_epochs=50, learning_rate=0.001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/50, Train Loss: 0.5744, Val Loss: 0.3948
Epoch 2/50, Train Loss: 0.5175, Val Loss: 0.3676
Epoch 3/50, Train Loss: 0.4991, Val Loss: 0.3970
Epoch 4/50, Train Loss: 0.4900, Val Loss: 0.3741
Epoch 5/50, Train Loss: 0.4832, Val Loss: 0.3510
Epoch 6/50, Train Loss: 0.4780, Val Loss: 0.3480
Epoch 7/50, Train Loss: 0.4741, Val Loss: 0.3732
Epoch 8/50, Train Loss: 0.4709, Val Loss: 0.3514
Epoch 9/50, Train Loss: 0.4689, Val Loss: 0.3859
Epoch 10/50, Train Loss: 0.4662, Val Loss: 0.3651
Epoch 11/50, Train Loss: 0.4641, Val Loss: 0.3499
Epoch 12/50, Train Loss: 0.4623, Val Loss: 0.3431
Epoch 13/50, Train Loss: 0.4607, Val Loss: 0.3844
Epoch 14/50, Train Loss: 0.4589, Val Loss: 0.3521
Epoch 15/50, Train Loss: 0.4575, Val Loss: 0.3514
Epoch 16/50, Train Loss: 0.4564, Val Loss: 0.3496
Epoch 17/50, Train Loss: 0.4554, Val Loss: 0.3688
Epoch 18/50, Train Loss: 0.4540, Val Loss: 0.3342
Epoch 19/50, Train Loss: 0.4531, Val Loss: 0.3404
Epoch 20/50, Train Loss: 0.4516, Val Loss: 0.3522
Epoch 21/50, Train Loss: 0.4504, Val Loss: 0.3210
Epoch 22/50, Train Loss: 0.4499, Val Loss: 0.3449
Epoch 23/50, Train Loss: 0.4485, Val Loss: 0.3389
Epoch 24/50, Train Loss: 0.4475, Val Loss: 0.3528
Epoch 25/50, Train Loss: 0.4476, Val Loss: 0.3433
Epoch 26/50, Train Loss: 0.4467, Val Loss: 0.3336
Epoch 27/50, Train Loss: 0.4457, Val Loss: 0.3799
Epoch 28/50, Train Loss: 0.4454, Val Loss: 0.3283
Epoch 29/50, Train Loss: 0.4447, Val Loss: 0.3664
Epoch 30/50, Train Loss: 0.4438, Val Loss: 0.3521
Epoch 31/50, Train Loss: 0.4435, Val Loss: 0.3603
Epoch 32/50, Train Loss: 0.4431, Val Loss: 0.3433
Epoch 33/50, Train Loss: 0.4422, Val Loss: 0.3529
Epoch 34/50, Train Loss: 0.4415, Val Loss: 0.3349
Epoch 35/50, Train Loss: 0.4418, Val Loss: 0.3543
Epoch 36/50, Train Loss: 0.4409, Val Loss: 0.3487
Epoch 37/50, Train Loss: 0.4403, Val Loss: 0.3518
Epoch 38/50, Train Loss: 0.4401, Val Loss: 0.3573
Epoch 39/50, Train Loss: 0.4390, Val Loss: 0.3458
Epoch 40/50, Train Loss: 0.4388, Val Loss: 0.3181
Epoch 41/50, Train Loss: 0.4380, Val Loss: 0.3508
Epoch 42/50, Train Loss: 0.4382, Val Loss: 0.3433
Epoch 43/50, Train Loss: 0.4372, Val Loss: 0.3291
Epoch 44/50, Train Loss: 0.4370, Val Loss: 0.3421
Epoch 45/50, Train Loss: 0.4363, Val Loss: 0.3530
Epoch 46/50, Train Loss: 0.4364, Val Loss: 0.3537
Epoch 47/50, Train Loss: 0.4357, Val Loss: 0.3229
Epoch 48/50, Train Loss: 0.4355, Val Loss: 0.3359
Epoch 49/50, Train Loss: 0.4349, Val Loss: 0.3361
Epoch 50/50, Train Loss: 0.4343, Val Loss: 0.3447
Total training time: 1055.5404s

Confusion Matrix:
[[178387  14009   2573]
 [  7855  36192   9545]
 [   123    691   2325]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.94    194969
           1       0.71      0.68      0.69     53592
           2       0.16      0.74      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.78      0.63    251700
weighted avg       0.89      0.86      0.88    251700


Global Accuracy: 0.8618
Total evaluation time: 3.1252s
Test Loss: 0.3462
Testing configuration: batch_size=512, num_epochs=50, learning_rate=0.0001, dropout=0.5, hidden_size=[128, 64, 32]
Epoch 1/50, Train Loss: 0.7646, Val Loss: 0.4936
Epoch 2/50, Train Loss: 0.6589, Val Loss: 0.4730
Epoch 3/50, Train Loss: 0.6345, Val Loss: 0.4602
Epoch 4/50, Train Loss: 0.6190, Val Loss: 0.4520
Epoch 5/50, Train Loss: 0.6079, Val Loss: 0.4407
Epoch 6/50, Train Loss: 0.5999, Val Loss: 0.4319
Epoch 7/50, Train Loss: 0.5927, Val Loss: 0.4251
Epoch 8/50, Train Loss: 0.5867, Val Loss: 0.4207
Epoch 9/50, Train Loss: 0.5810, Val Loss: 0.4100
Epoch 10/50, Train Loss: 0.5760, Val Loss: 0.4011
Epoch 11/50, Train Loss: 0.5711, Val Loss: 0.3969
Epoch 12/50, Train Loss: 0.5665, Val Loss: 0.3952
Epoch 13/50, Train Loss: 0.5629, Val Loss: 0.3985
Epoch 14/50, Train Loss: 0.5592, Val Loss: 0.3966
Epoch 15/50, Train Loss: 0.5554, Val Loss: 0.3905
Epoch 16/50, Train Loss: 0.5528, Val Loss: 0.3940
Epoch 17/50, Train Loss: 0.5504, Val Loss: 0.3772
Epoch 18/50, Train Loss: 0.5482, Val Loss: 0.3795
Epoch 19/50, Train Loss: 0.5465, Val Loss: 0.3836
Epoch 20/50, Train Loss: 0.5449, Val Loss: 0.3748
Epoch 21/50, Train Loss: 0.5432, Val Loss: 0.3851
Epoch 22/50, Train Loss: 0.5422, Val Loss: 0.3947
Epoch 23/50, Train Loss: 0.5407, Val Loss: 0.3777
Epoch 24/50, Train Loss: 0.5394, Val Loss: 0.3804
Epoch 25/50, Train Loss: 0.5383, Val Loss: 0.3840
Epoch 26/50, Train Loss: 0.5372, Val Loss: 0.3761
Epoch 27/50, Train Loss: 0.5350, Val Loss: 0.3831
Epoch 28/50, Train Loss: 0.5340, Val Loss: 0.3891
Epoch 29/50, Train Loss: 0.5328, Val Loss: 0.3751
Epoch 30/50, Train Loss: 0.5320, Val Loss: 0.3774
Epoch 31/50, Train Loss: 0.5312, Val Loss: 0.3735
Epoch 32/50, Train Loss: 0.5305, Val Loss: 0.3605
Epoch 33/50, Train Loss: 0.5288, Val Loss: 0.3765
Epoch 34/50, Train Loss: 0.5285, Val Loss: 0.3674
Epoch 35/50, Train Loss: 0.5283, Val Loss: 0.3664
Epoch 36/50, Train Loss: 0.5271, Val Loss: 0.3581
Epoch 37/50, Train Loss: 0.5265, Val Loss: 0.3754
Epoch 38/50, Train Loss: 0.5261, Val Loss: 0.3702
Epoch 39/50, Train Loss: 0.5255, Val Loss: 0.3997
Epoch 40/50, Train Loss: 0.5252, Val Loss: 0.3866
Epoch 41/50, Train Loss: 0.5249, Val Loss: 0.3740
Epoch 42/50, Train Loss: 0.5244, Val Loss: 0.3702
Epoch 43/50, Train Loss: 0.5239, Val Loss: 0.3629
Epoch 44/50, Train Loss: 0.5237, Val Loss: 0.3664
Epoch 45/50, Train Loss: 0.5228, Val Loss: 0.3710
Epoch 46/50, Train Loss: 0.5229, Val Loss: 0.3707
Epoch 47/50, Train Loss: 0.5229, Val Loss: 0.3695
Epoch 48/50, Train Loss: 0.5223, Val Loss: 0.3628
Epoch 49/50, Train Loss: 0.5224, Val Loss: 0.3594
Epoch 50/50, Train Loss: 0.5218, Val Loss: 0.3761
Total training time: 1045.0558s

Confusion Matrix:
[[177999  14852   2118]
 [  7887  33627  12078]
 [   131    625   2383]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.91      0.93    194969
           1       0.68      0.63      0.65     53592
           2       0.14      0.76      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.77      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8503
Total evaluation time: 3.0962s
Test Loss: 0.3779
Testing configuration: batch_size=512, num_epochs=50, learning_rate=0.0001, dropout=0.5, hidden_size=[256, 128, 64]
Epoch 1/50, Train Loss: 0.7115, Val Loss: 0.4675
Epoch 2/50, Train Loss: 0.6220, Val Loss: 0.4537
Epoch 3/50, Train Loss: 0.5996, Val Loss: 0.4431
Epoch 4/50, Train Loss: 0.5857, Val Loss: 0.4335
Epoch 5/50, Train Loss: 0.5750, Val Loss: 0.4230
Epoch 6/50, Train Loss: 0.5656, Val Loss: 0.4104
Epoch 7/50, Train Loss: 0.5576, Val Loss: 0.4192
Epoch 8/50, Train Loss: 0.5502, Val Loss: 0.3984
Epoch 9/50, Train Loss: 0.5448, Val Loss: 0.4076
Epoch 10/50, Train Loss: 0.5393, Val Loss: 0.3934
Epoch 11/50, Train Loss: 0.5349, Val Loss: 0.3898
Epoch 12/50, Train Loss: 0.5306, Val Loss: 0.3812
Epoch 13/50, Train Loss: 0.5270, Val Loss: 0.3747
Epoch 14/50, Train Loss: 0.5241, Val Loss: 0.3949
Epoch 15/50, Train Loss: 0.5212, Val Loss: 0.3769
Epoch 16/50, Train Loss: 0.5187, Val Loss: 0.3780
Epoch 17/50, Train Loss: 0.5165, Val Loss: 0.3689
Epoch 18/50, Train Loss: 0.5144, Val Loss: 0.3710
Epoch 19/50, Train Loss: 0.5121, Val Loss: 0.3592
Epoch 20/50, Train Loss: 0.5104, Val Loss: 0.3643
Epoch 21/50, Train Loss: 0.5089, Val Loss: 0.3711
Epoch 22/50, Train Loss: 0.5071, Val Loss: 0.3910
Epoch 23/50, Train Loss: 0.5056, Val Loss: 0.3679
Epoch 24/50, Train Loss: 0.5037, Val Loss: 0.3582
Epoch 25/50, Train Loss: 0.5023, Val Loss: 0.3777
Epoch 26/50, Train Loss: 0.5008, Val Loss: 0.3635
Epoch 27/50, Train Loss: 0.5001, Val Loss: 0.3587
Epoch 28/50, Train Loss: 0.4989, Val Loss: 0.3680
Epoch 29/50, Train Loss: 0.4978, Val Loss: 0.3732
Epoch 30/50, Train Loss: 0.4965, Val Loss: 0.3590
Epoch 31/50, Train Loss: 0.4956, Val Loss: 0.3714
Epoch 32/50, Train Loss: 0.4950, Val Loss: 0.3637
Epoch 33/50, Train Loss: 0.4939, Val Loss: 0.3542
Epoch 34/50, Train Loss: 0.4934, Val Loss: 0.3542
Epoch 35/50, Train Loss: 0.4926, Val Loss: 0.3694
Epoch 36/50, Train Loss: 0.4920, Val Loss: 0.3565
Epoch 37/50, Train Loss: 0.4916, Val Loss: 0.3632
Epoch 38/50, Train Loss: 0.4906, Val Loss: 0.3577
Epoch 39/50, Train Loss: 0.4905, Val Loss: 0.3520
Epoch 40/50, Train Loss: 0.4897, Val Loss: 0.3632
Epoch 41/50, Train Loss: 0.4892, Val Loss: 0.3599
Epoch 42/50, Train Loss: 0.4886, Val Loss: 0.3628
Epoch 43/50, Train Loss: 0.4881, Val Loss: 0.3554
Epoch 44/50, Train Loss: 0.4878, Val Loss: 0.3541
Epoch 45/50, Train Loss: 0.4876, Val Loss: 0.3542
Epoch 46/50, Train Loss: 0.4872, Val Loss: 0.3585
Epoch 47/50, Train Loss: 0.4868, Val Loss: 0.3464
Epoch 48/50, Train Loss: 0.4861, Val Loss: 0.3512
Epoch 49/50, Train Loss: 0.4860, Val Loss: 0.3568
Epoch 50/50, Train Loss: 0.4851, Val Loss: 0.3609
Total training time: 1034.4172s

Confusion Matrix:
[[178447  14098   2424]
 [  7977  33639  11976]
 [   123    606   2410]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.70      0.63      0.66     53592
           2       0.14      0.77      0.24      3139

    accuracy                           0.85    251700
   macro avg       0.60      0.77      0.61    251700
weighted avg       0.89      0.85      0.87    251700


Global Accuracy: 0.8522
Total evaluation time: 3.1044s
Test Loss: 0.3623
Testing configuration: batch_size=512, num_epochs=50, learning_rate=0.0001, dropout=0.5, hidden_size=[512, 256, 128]
Epoch 1/50, Train Loss: 0.6646, Val Loss: 0.4576
Epoch 2/50, Train Loss: 0.5910, Val Loss: 0.4400
Epoch 3/50, Train Loss: 0.5701, Val Loss: 0.4230
Epoch 4/50, Train Loss: 0.5556, Val Loss: 0.4153
Epoch 5/50, Train Loss: 0.5438, Val Loss: 0.4092
Epoch 6/50, Train Loss: 0.5339, Val Loss: 0.4015
Epoch 7/50, Train Loss: 0.5261, Val Loss: 0.4049
Epoch 8/50, Train Loss: 0.5191, Val Loss: 0.3929
Epoch 9/50, Train Loss: 0.5132, Val Loss: 0.3820
Epoch 10/50, Train Loss: 0.5077, Val Loss: 0.3902
Epoch 11/50, Train Loss: 0.5025, Val Loss: 0.3638
Epoch 12/50, Train Loss: 0.4979, Val Loss: 0.3730
Epoch 13/50, Train Loss: 0.4935, Val Loss: 0.3695
Epoch 14/50, Train Loss: 0.4898, Val Loss: 0.3667
Epoch 15/50, Train Loss: 0.4856, Val Loss: 0.3712
Epoch 16/50, Train Loss: 0.4824, Val Loss: 0.3522
Epoch 17/50, Train Loss: 0.4786, Val Loss: 0.3696
Epoch 18/50, Train Loss: 0.4761, Val Loss: 0.3562
Epoch 19/50, Train Loss: 0.4733, Val Loss: 0.3635
Epoch 20/50, Train Loss: 0.4709, Val Loss: 0.3542
Epoch 21/50, Train Loss: 0.4686, Val Loss: 0.3588
Epoch 22/50, Train Loss: 0.4666, Val Loss: 0.3722
Epoch 23/50, Train Loss: 0.4645, Val Loss: 0.3583
Epoch 24/50, Train Loss: 0.4630, Val Loss: 0.3557
Epoch 25/50, Train Loss: 0.4613, Val Loss: 0.3566
Epoch 26/50, Train Loss: 0.4600, Val Loss: 0.3614
Epoch 27/50, Train Loss: 0.4585, Val Loss: 0.3490
Epoch 28/50, Train Loss: 0.4573, Val Loss: 0.3453
Epoch 29/50, Train Loss: 0.4565, Val Loss: 0.3543
Epoch 30/50, Train Loss: 0.4547, Val Loss: 0.3504
Epoch 31/50, Train Loss: 0.4544, Val Loss: 0.3535
Epoch 32/50, Train Loss: 0.4529, Val Loss: 0.3490
Epoch 33/50, Train Loss: 0.4519, Val Loss: 0.3503
Epoch 34/50, Train Loss: 0.4511, Val Loss: 0.3528
Epoch 35/50, Train Loss: 0.4506, Val Loss: 0.3390
Epoch 36/50, Train Loss: 0.4497, Val Loss: 0.3524
Epoch 37/50, Train Loss: 0.4490, Val Loss: 0.3411
Epoch 38/50, Train Loss: 0.4485, Val Loss: 0.3591
Epoch 39/50, Train Loss: 0.4471, Val Loss: 0.3469
Epoch 40/50, Train Loss: 0.4468, Val Loss: 0.3484
Epoch 41/50, Train Loss: 0.4460, Val Loss: 0.3546
Epoch 42/50, Train Loss: 0.4459, Val Loss: 0.3459
Epoch 43/50, Train Loss: 0.4451, Val Loss: 0.3462
Epoch 44/50, Train Loss: 0.4444, Val Loss: 0.3466
Epoch 45/50, Train Loss: 0.4439, Val Loss: 0.3499
Epoch 46/50, Train Loss: 0.4431, Val Loss: 0.3508
Epoch 47/50, Train Loss: 0.4433, Val Loss: 0.3508
Epoch 48/50, Train Loss: 0.4422, Val Loss: 0.3411
Epoch 49/50, Train Loss: 0.4420, Val Loss: 0.3465
Epoch 50/50, Train Loss: 0.4414, Val Loss: 0.3395
Total training time: 1042.5394s

Confusion Matrix:
[[179241  13583   2145]
 [  8115  35467  10010]
 [   125    690   2324]]

Classification Report:
              precision    recall  f1-score   support

           0       0.96      0.92      0.94    194969
           1       0.71      0.66      0.69     53592
           2       0.16      0.74      0.26      3139

    accuracy                           0.86    251700
   macro avg       0.61      0.77      0.63    251700
weighted avg       0.89      0.86      0.88    251700


Global Accuracy: 0.8623
Total evaluation time: 3.0756s
Test Loss: 0.3407
Best configuration: {'num_epochs': 50, 'learning_rate': 0.001, 'hidden_sizes': [128, 64, 32], 'dropout': 0.5, 'batch_size': 512} with accuracy: 0.8645
